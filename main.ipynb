{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 943,
     "status": "ok",
     "timestamp": 1729996600732,
     "user": {
      "displayName": "佐藤信吾",
      "userId": "11983907688732050177"
     },
     "user_tz": -540
    },
    "id": "DvzwKEcGKOw_"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend. Please refer to https://wandb.me/wandb-core for more information.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33muu13234\u001b[0m (\u001b[33muu13234-none\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import gc\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import scipy.io as sio\n",
    "from scipy.signal import resample\n",
    "import warnings\n",
    "\n",
    "# Weights and Biases related imports\n",
    "#import wandb\n",
    "#from wandb.integration.keras import WandbMetricsLogger\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "\n",
    "# 警告を無視する設定\n",
    "warnings.simplefilter(\"ignore\")\n",
    "\n",
    "# Pandasの表示設定\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "# Jupyter Notebookでのグラフ表示を有効にする\n",
    "#%matplotlib inline\n",
    "\n",
    "# Weights and Biasesにログイン\n",
    "#wandb.login()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "前処理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 筋電図データの整流化\n",
    "def rectify_signal(emg_data):\n",
    "    \"\"\"EMGデータを整流化（負の値を正に変換）\"\"\"\n",
    "    return np.abs(emg_data)\n",
    "\n",
    "# 筋電位データの対数変換関数\n",
    "def log_transform_emg(emg_data, epsilon=1e-6):\n",
    "    \"\"\"整流化されたEMGデータに対して対数変換を適用\"\"\"\n",
    "    return np.log(emg_data + epsilon)\n",
    "\n",
    "# x方向が常に正または負のデータを抽出\n",
    "def extract_positive_x_trials(velocity_x):\n",
    "    positive_x_trials = []\n",
    "    for i in range(velocity_x.shape[0]):\n",
    "        if np.all(velocity_x[i] > 0) or np.all(velocity_x[i] < 0):\n",
    "            positive_x_trials.append(i)\n",
    "    return positive_x_trials\n",
    "\n",
    "# 筋電位データの左右を反転して学習データに追加\n",
    "def add_reversed_emg_data(trial_user, x_velocity, emg_data, y_data):\n",
    "    added_user_list = []\n",
    "    reversed_emg_data = []\n",
    "    y_add_list = []\n",
    "    \n",
    "    # 各ユーザーごとに処理\n",
    "    user_trial_ranges = np.cumsum([0] + trial_user)\n",
    "    right_leg_muscles = [1, 3, 5, 7, 9, 11, 13, 15]\n",
    "    left_leg_muscles = [0, 2, 4, 6, 8, 10, 12, 14]\n",
    "\n",
    "    for user_idx, (start, end) in enumerate(zip(user_trial_ranges[:-1], user_trial_ranges[1:])):\n",
    "        user_velocity_x = x_velocity[start:end]\n",
    "        user_emg_data = emg_data[start:end]\n",
    "        user_y_data = y_data[start:end]\n",
    "\n",
    "        positive_x_trials = extract_positive_x_trials(user_velocity_x)\n",
    "\n",
    "        for i in positive_x_trials:\n",
    "            trial_emg = user_emg_data[i].copy()\n",
    "            y_add = user_y_data[i].copy()\n",
    "\n",
    "            # 筋電位データの左右を反転\n",
    "            trial_emg[:, right_leg_muscles], trial_emg[:, left_leg_muscles] = trial_emg[:, left_leg_muscles], trial_emg[:, right_leg_muscles]\n",
    "            \n",
    "            reversed_emg_data.append(trial_emg)\n",
    "            y_add_list.append(y_add)\n",
    "            added_user_list.append(f'00{user_idx + 1}')  # ユーザーIDを追加\n",
    "\n",
    "    reversed_emg_data = np.array(reversed_emg_data)\n",
    "    y_add_data = np.array(y_add_list)\n",
    "\n",
    "    new_emg_data = np.concatenate([emg_data, reversed_emg_data], axis=0)\n",
    "    new_y_data = np.concatenate([y_data, y_add_data], axis=0)\n",
    "\n",
    "    return new_emg_data, added_user_list, new_y_data\n",
    "\n",
    "# 学習用データの取得\n",
    "def get_train_data(train_path, user_ids, trial_user):\n",
    "    train_data = sio.loadmat(train_path)\n",
    "    X_list, y_list, user_id_list = [], [], []\n",
    "    user_id_encoder = OneHotEncoder(sparse_output=False)\n",
    "    user_id_encoder.fit(user_ids.reshape(-1, 1))\n",
    "\n",
    "    for user_id in user_ids:\n",
    "        x_array = train_data[user_id][0][0][0].transpose(0, 2, 1)\n",
    "        y_array = train_data[user_id][0][0][1].transpose(0, 2, 1)\n",
    "        num_trials = x_array.shape[0]\n",
    "        \n",
    "        user_id_encoded = user_id_encoder.transform(np.array([[user_id]] * num_trials))\n",
    "        user_id_list.extend([[user_id]] * num_trials)\n",
    "\n",
    "        for trial in range(num_trials):\n",
    "            rectified_x = rectify_signal(x_array[trial])\n",
    "            log_transformed_x = log_transform_emg(rectified_x)\n",
    "            new_x_array = np.hstack([log_transformed_x, np.repeat(user_id_encoded[trial][np.newaxis, :], 1000, axis=0)])\n",
    "            X_list.append(new_x_array[np.newaxis, :])\n",
    "\n",
    "        y_list.append(y_array)\n",
    "        del x_array, y_array\n",
    "        gc.collect()\n",
    "\n",
    "    X = np.concatenate(X_list, axis=0)\n",
    "    y = np.concatenate(y_list, axis=0)\n",
    "\n",
    "    print(X.shape)\n",
    "\n",
    "    # 標準化\n",
    "    X_scaled, scaler_list = standardize_by_user(X, trial_user)\n",
    "    x_velocity = y[:,:,0]\n",
    "    new_emg_data, added_user_list, y_add_data = add_reversed_emg_data(trial_user, x_velocity, X_scaled, y)\n",
    "\n",
    "    # user_id_listに追加されたデータのuser_idを追加\n",
    "    user_id_list_flat = [str(item[0]) if isinstance(item, np.ndarray) else str(item) for sublist in user_id_list for item in sublist]\n",
    "    user_id_list_flat.extend(added_user_list)\n",
    "    user_id_list_array = np.array(user_id_list_flat)\n",
    "\n",
    "    return new_emg_data, y_add_data, user_id_list_array, scaler_list\n",
    "\n",
    "# ユーザーごとの標準化\n",
    "def standardize_by_user(emg_data, trial_user):\n",
    "    scaler_list = []\n",
    "    start = 0\n",
    "    for num_trials in trial_user:\n",
    "        end = start + num_trials# * 1000\n",
    "        scaler = StandardScaler()\n",
    "        emg_data[start:end, :, :16] = scaler.fit_transform(emg_data[start:end, :, :16].reshape(-1, 16)).reshape(num_trials, 1000, 16)\n",
    "        scaler_list.append(scaler)\n",
    "        start = end\n",
    "    return emg_data[:, :-10], scaler_list\n",
    "\n",
    "# 評価用データの取得\n",
    "def get_test_data(test_path, user_ids, trial_user, scaler_list):\n",
    "    test_data = sio.loadmat(test_path)\n",
    "    X_list, user_id_list = [], []\n",
    "    user_id_encoder = OneHotEncoder(sparse_output=False)\n",
    "    user_id_encoder.fit(user_ids.reshape(-1, 1))\n",
    "\n",
    "    for user_id in user_ids:\n",
    "        x_array = test_data[user_id][0][0][0].transpose(0, 2, 1)\n",
    "        num_trials = x_array.shape[0]\n",
    "        \n",
    "        user_id_encoded = user_id_encoder.transform(np.array([[user_id]] * num_trials))\n",
    "        user_id_list.extend([[user_id]] * num_trials)\n",
    "\n",
    "        for trial in range(num_trials):\n",
    "            rectified_x = rectify_signal(x_array[trial])\n",
    "            log_transformed_x = log_transform_emg(rectified_x)\n",
    "            new_x_array = np.hstack([log_transformed_x, np.repeat(user_id_encoded[trial][np.newaxis, :], 1000, axis=0)])\n",
    "            X_list.append(new_x_array[np.newaxis, :])\n",
    "\n",
    "        del x_array\n",
    "        gc.collect()\n",
    "\n",
    "    X = np.concatenate(X_list, axis=0)\n",
    "\n",
    "    # ユーザーごとに標準化\n",
    "    X_scaled = np.zeros_like(X)\n",
    "    start = 0\n",
    "    for user_idx, num_trials in enumerate(trial_user):\n",
    "        end = start + num_trials\n",
    "        X_scaled[start:end, :, :16] = scaler_list[user_idx].transform(X[start:end, :, :16].reshape(-1, 16)).reshape(num_trials, 1000, 16)\n",
    "        start = end\n",
    "\n",
    "    return X_scaled[:, :-10]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1259, 1000, 20)\n"
     ]
    }
   ],
   "source": [
    "train_path = r'C:\\Users\\sato\\Desktop\\python\\SIGNATE\\スケートボードの挙動予測\\input/train.mat'\n",
    "test_path = r'C:\\Users\\sato\\Desktop\\python\\SIGNATE\\スケートボードの挙動予測\\input/test.mat'\n",
    "user_ids = np.array([\"0001\", \"0002\", \"0003\", \"0004\"])\n",
    "trial_user = [319, 300, 320, 320] \n",
    "\n",
    "train_X, y, user_id_list, scaler_list = get_train_data(train_path, user_ids, trial_user)\n",
    "test_X = get_test_data(test_path, user_ids, trial_user, scaler_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "学習"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Conv1D, LSTM, Dense, Dropout, Bidirectional, Input, TimeDistributed, Attention, AveragePooling1D, BatchNormalization, MaxPooling1D\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras import backend as K\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import root_mean_squared_error\n",
    "#import wandb\n",
    "#from wandb.integration.keras import WandbMetricsLogger\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model():\n",
    "    # モデル定義\n",
    "    input_layer = Input(shape=(990, 20))\n",
    "\n",
    "    # 畳み込み層\n",
    "    x = Conv1D(filters=224, kernel_size=50, activation='relu', padding='same')(input_layer)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = AveragePooling1D(pool_size=4)(x)\n",
    "    x = Conv1D(filters=128, kernel_size=10, activation='relu', padding='same')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = AveragePooling1D(pool_size=4)(x)\n",
    "    x = MaxPooling1D(pool_size=2)(x)\n",
    "\n",
    "    # LSTM + Attention層\n",
    "    x = Bidirectional(LSTM(96, return_sequences=True))(x)\n",
    "    x = Dropout(rate=0.3)(x)\n",
    "\n",
    "    # Attention層\n",
    "    attention_out = Attention()([x, x]) \n",
    "\n",
    "    # LSTM層と出力層\n",
    "    x = Bidirectional(LSTM(64, return_sequences=True))(attention_out)\n",
    "    x = Dropout(rate=0.2)(x)\n",
    "\n",
    "    # 出力層\n",
    "    output_layer = TimeDistributed(Dense(3))(x)\n",
    "\n",
    "    # モデルの構築\n",
    "    model = Model(inputs=input_layer, outputs=output_layer)\n",
    "\n",
    "    return model\n",
    "\n",
    "def rmse_3d_loss(y_true, y_pred):\n",
    "    return K.sqrt(K.sum(K.square(y_true - y_pred), axis=-1))\n",
    "\n",
    "def train_model(X_train, y_train, user_id_list, num_folds=10):\n",
    "    kf = StratifiedKFold(n_splits=num_folds, shuffle=True, random_state=0)\n",
    "    model_list = []\n",
    "  \n",
    "    for i, (train_idx, val_idx) in enumerate(kf.split(X_train, user_id_list.astype('str'))):\n",
    "        #run = wandb.init(\n",
    "        #    project = \"sgnate_skate-keras\",\n",
    "        #    name = f'test_{i}',\n",
    "        #    tags = [f'test_up']\n",
    "        #    #config = configs\n",
    "        #)\n",
    "        #wandb.define_metric('rmase_prediction', summary='mean')\n",
    "        train_X, val_X = X_train[train_idx], X_train[val_idx]\n",
    "        train_y, val_y = y_train[train_idx], y_train[val_idx]\n",
    "        \n",
    "        model = create_model()\n",
    "        model.compile(optimizer=Adam(learning_rate=0.0004926459300637485), loss=rmse_3d_loss) #過去コンペで使用したlearning_rateを使用\n",
    "        early_stopping = EarlyStopping(patience=35, restore_best_weights=True, verbose=1)\n",
    "        \n",
    "        #model.fit(train_X, train_y, validation_data=(val_X, val_y), epochs=1000, batch_size=32, callbacks=[early_stopping, WandbMetricsLogger()])\n",
    "        model.fit(train_X, train_y, validation_data=(val_X, val_y), epochs=1000, batch_size=32, callbacks=[early_stopping])\n",
    "        #model.save(f'model_fold_{i+1}.h5')\n",
    "        model_list.append(model)\n",
    "\n",
    "        pred = model.predict(val_X)\n",
    "        score = root_mean_squared_error(val_y.reshape(-1, 1), pred.reshape(-1, 1))\n",
    "        print(score)\n",
    "        #wandb.log({'rmase_prediction': score})\n",
    "        \n",
    "        #run.finish()\n",
    "\n",
    "    return model_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:z6k01utc) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "46fd3e899e6e410d80f1518dcf919501",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.004 MB of 0.004 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">test_0</strong> at: <a href='https://wandb.ai/uu13234-none/sgnate_skate-keras/runs/z6k01utc' target=\"_blank\">https://wandb.ai/uu13234-none/sgnate_skate-keras/runs/z6k01utc</a><br/> View project at: <a href='https://wandb.ai/uu13234-none/sgnate_skate-keras' target=\"_blank\">https://wandb.ai/uu13234-none/sgnate_skate-keras</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20241104_140308-z6k01utc\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Successfully finished last run (ID:z6k01utc). Initializing new run:<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.18.3"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\sato\\Desktop\\python\\SIGNATE\\スケートボードの挙動予測\\code-analysis\\wandb\\run-20241104_140355-cwqopqx1</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/uu13234-none/sgnate_skate-keras/runs/cwqopqx1' target=\"_blank\">test_0</a></strong> to <a href='https://wandb.ai/uu13234-none/sgnate_skate-keras' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/uu13234-none/sgnate_skate-keras' target=\"_blank\">https://wandb.ai/uu13234-none/sgnate_skate-keras</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/uu13234-none/sgnate_skate-keras/runs/cwqopqx1' target=\"_blank\">https://wandb.ai/uu13234-none/sgnate_skate-keras/runs/cwqopqx1</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "61/61 [==============================] - 19s 61ms/step - loss: 1.5296 - val_loss: 1.1694\n",
      "Epoch 2/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 1.0341 - val_loss: 1.1232\n",
      "Epoch 3/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.9081 - val_loss: 0.8897\n",
      "Epoch 4/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.8104 - val_loss: 0.8202\n",
      "Epoch 5/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.7648 - val_loss: 0.7528\n",
      "Epoch 6/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.7391 - val_loss: 0.7014\n",
      "Epoch 7/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.6890 - val_loss: 0.7189\n",
      "Epoch 8/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.6999 - val_loss: 0.6854\n",
      "Epoch 9/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.6599 - val_loss: 0.7015\n",
      "Epoch 10/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.6623 - val_loss: 0.7473\n",
      "Epoch 11/1000\n",
      "61/61 [==============================] - 2s 28ms/step - loss: 0.6303 - val_loss: 0.6293\n",
      "Epoch 12/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.5808 - val_loss: 0.6821\n",
      "Epoch 13/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.5598 - val_loss: 0.5476\n",
      "Epoch 14/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.5384 - val_loss: 0.5347\n",
      "Epoch 15/1000\n",
      "61/61 [==============================] - 2s 28ms/step - loss: 0.5179 - val_loss: 0.5307\n",
      "Epoch 16/1000\n",
      "61/61 [==============================] - 2s 28ms/step - loss: 0.5057 - val_loss: 0.5350\n",
      "Epoch 17/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.5233 - val_loss: 0.5610\n",
      "Epoch 18/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.5461 - val_loss: 0.5736\n",
      "Epoch 19/1000\n",
      "61/61 [==============================] - 2s 28ms/step - loss: 0.4875 - val_loss: 0.5503\n",
      "Epoch 20/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.4727 - val_loss: 0.5273\n",
      "Epoch 21/1000\n",
      "61/61 [==============================] - 2s 28ms/step - loss: 0.4592 - val_loss: 0.6002\n",
      "Epoch 22/1000\n",
      "61/61 [==============================] - 2s 28ms/step - loss: 0.5131 - val_loss: 0.5124\n",
      "Epoch 23/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.4662 - val_loss: 0.5407\n",
      "Epoch 24/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.4449 - val_loss: 0.4994\n",
      "Epoch 25/1000\n",
      "61/61 [==============================] - 2s 28ms/step - loss: 0.4579 - val_loss: 0.5502\n",
      "Epoch 26/1000\n",
      "61/61 [==============================] - 2s 28ms/step - loss: 0.4317 - val_loss: 0.4752\n",
      "Epoch 27/1000\n",
      "61/61 [==============================] - 2s 28ms/step - loss: 0.4090 - val_loss: 0.4747\n",
      "Epoch 28/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.4011 - val_loss: 0.4498\n",
      "Epoch 29/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.3928 - val_loss: 0.4522\n",
      "Epoch 30/1000\n",
      "61/61 [==============================] - 2s 28ms/step - loss: 0.3819 - val_loss: 0.4411\n",
      "Epoch 31/1000\n",
      "61/61 [==============================] - 2s 28ms/step - loss: 0.3721 - val_loss: 0.4436\n",
      "Epoch 32/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.3752 - val_loss: 0.4623\n",
      "Epoch 33/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.3673 - val_loss: 0.4298\n",
      "Epoch 34/1000\n",
      "61/61 [==============================] - 2s 28ms/step - loss: 0.3593 - val_loss: 0.4256\n",
      "Epoch 35/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.3699 - val_loss: 0.4517\n",
      "Epoch 36/1000\n",
      "61/61 [==============================] - 2s 28ms/step - loss: 0.3746 - val_loss: 0.4529\n",
      "Epoch 37/1000\n",
      "61/61 [==============================] - 2s 28ms/step - loss: 0.3791 - val_loss: 0.4373\n",
      "Epoch 38/1000\n",
      "61/61 [==============================] - 2s 28ms/step - loss: 0.3613 - val_loss: 0.4270\n",
      "Epoch 39/1000\n",
      "61/61 [==============================] - 2s 28ms/step - loss: 0.3484 - val_loss: 0.4194\n",
      "Epoch 40/1000\n",
      "61/61 [==============================] - 2s 28ms/step - loss: 0.3358 - val_loss: 0.4063\n",
      "Epoch 41/1000\n",
      "61/61 [==============================] - 2s 28ms/step - loss: 0.3276 - val_loss: 0.4092\n",
      "Epoch 42/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.3288 - val_loss: 0.4063\n",
      "Epoch 43/1000\n",
      "61/61 [==============================] - 2s 28ms/step - loss: 0.3219 - val_loss: 0.4050\n",
      "Epoch 44/1000\n",
      "61/61 [==============================] - 2s 28ms/step - loss: 0.3169 - val_loss: 0.4097\n",
      "Epoch 45/1000\n",
      "61/61 [==============================] - 2s 28ms/step - loss: 0.3375 - val_loss: 0.4742\n",
      "Epoch 46/1000\n",
      "61/61 [==============================] - 2s 28ms/step - loss: 0.3523 - val_loss: 0.4387\n",
      "Epoch 47/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.3206 - val_loss: 0.4048\n",
      "Epoch 48/1000\n",
      "61/61 [==============================] - 2s 28ms/step - loss: 0.3222 - val_loss: 0.4035\n",
      "Epoch 49/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.3110 - val_loss: 0.4159\n",
      "Epoch 50/1000\n",
      "61/61 [==============================] - 2s 28ms/step - loss: 0.3038 - val_loss: 0.4131\n",
      "Epoch 51/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.2990 - val_loss: 0.3885\n",
      "Epoch 52/1000\n",
      "61/61 [==============================] - 2s 28ms/step - loss: 0.2952 - val_loss: 0.3945\n",
      "Epoch 53/1000\n",
      "61/61 [==============================] - 2s 28ms/step - loss: 0.2953 - val_loss: 0.4399\n",
      "Epoch 54/1000\n",
      "61/61 [==============================] - 2s 28ms/step - loss: 0.3386 - val_loss: 0.4780\n",
      "Epoch 55/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.3341 - val_loss: 0.3977\n",
      "Epoch 56/1000\n",
      "61/61 [==============================] - 2s 28ms/step - loss: 0.3132 - val_loss: 0.4052\n",
      "Epoch 57/1000\n",
      "61/61 [==============================] - 2s 28ms/step - loss: 0.2996 - val_loss: 0.3839\n",
      "Epoch 58/1000\n",
      "61/61 [==============================] - 2s 28ms/step - loss: 0.2872 - val_loss: 0.3608\n",
      "Epoch 59/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.2813 - val_loss: 0.3686\n",
      "Epoch 60/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.2810 - val_loss: 0.3762\n",
      "Epoch 61/1000\n",
      "61/61 [==============================] - 2s 28ms/step - loss: 0.2812 - val_loss: 0.3715\n",
      "Epoch 62/1000\n",
      "61/61 [==============================] - 2s 28ms/step - loss: 0.2786 - val_loss: 0.3545\n",
      "Epoch 63/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.2786 - val_loss: 0.3598\n",
      "Epoch 64/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.2747 - val_loss: 0.3577\n",
      "Epoch 65/1000\n",
      "61/61 [==============================] - 2s 28ms/step - loss: 0.2713 - val_loss: 0.3607\n",
      "Epoch 66/1000\n",
      "61/61 [==============================] - 2s 28ms/step - loss: 0.2700 - val_loss: 0.3584\n",
      "Epoch 67/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.2706 - val_loss: 0.3546\n",
      "Epoch 68/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.2687 - val_loss: 0.3494\n",
      "Epoch 69/1000\n",
      "61/61 [==============================] - 2s 28ms/step - loss: 0.2678 - val_loss: 0.3407\n",
      "Epoch 70/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.2691 - val_loss: 0.3469\n",
      "Epoch 71/1000\n",
      "61/61 [==============================] - 2s 28ms/step - loss: 0.2670 - val_loss: 0.3518\n",
      "Epoch 72/1000\n",
      "61/61 [==============================] - 2s 28ms/step - loss: 0.2606 - val_loss: 0.3436\n",
      "Epoch 73/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.2606 - val_loss: 0.3422\n",
      "Epoch 74/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.2615 - val_loss: 0.3453\n",
      "Epoch 75/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.2580 - val_loss: 0.3632\n",
      "Epoch 76/1000\n",
      "61/61 [==============================] - 2s 28ms/step - loss: 0.2568 - val_loss: 0.3552\n",
      "Epoch 77/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.2559 - val_loss: 0.3516\n",
      "Epoch 78/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.2571 - val_loss: 0.3532\n",
      "Epoch 79/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.2557 - val_loss: 0.3481\n",
      "Epoch 80/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.2533 - val_loss: 0.3403\n",
      "Epoch 81/1000\n",
      "61/61 [==============================] - 2s 31ms/step - loss: 0.2553 - val_loss: 0.3586\n",
      "Epoch 82/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.2521 - val_loss: 0.3348\n",
      "Epoch 83/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.2510 - val_loss: 0.3233\n",
      "Epoch 84/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.2512 - val_loss: 0.3402\n",
      "Epoch 85/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.2727 - val_loss: 0.4177\n",
      "Epoch 86/1000\n",
      "61/61 [==============================] - 2s 28ms/step - loss: 0.2774 - val_loss: 0.3699\n",
      "Epoch 87/1000\n",
      "61/61 [==============================] - 2s 28ms/step - loss: 0.3519 - val_loss: 0.5089\n",
      "Epoch 88/1000\n",
      "61/61 [==============================] - 2s 28ms/step - loss: 0.3394 - val_loss: 0.3856\n",
      "Epoch 89/1000\n",
      "61/61 [==============================] - 2s 28ms/step - loss: 0.3082 - val_loss: 0.4764\n",
      "Epoch 90/1000\n",
      "61/61 [==============================] - 2s 28ms/step - loss: 0.3974 - val_loss: 0.5632\n",
      "Epoch 91/1000\n",
      "61/61 [==============================] - 2s 28ms/step - loss: 0.4543 - val_loss: 0.4614\n",
      "Epoch 92/1000\n",
      "61/61 [==============================] - 2s 28ms/step - loss: 0.3409 - val_loss: 0.3845\n",
      "Epoch 93/1000\n",
      "61/61 [==============================] - 2s 28ms/step - loss: 0.3072 - val_loss: 0.3885\n",
      "Epoch 94/1000\n",
      "61/61 [==============================] - 2s 28ms/step - loss: 0.2926 - val_loss: 0.3542\n",
      "Epoch 95/1000\n",
      "61/61 [==============================] - 2s 28ms/step - loss: 0.2674 - val_loss: 0.3606\n",
      "Epoch 96/1000\n",
      "61/61 [==============================] - 2s 28ms/step - loss: 0.2597 - val_loss: 0.3409\n",
      "Epoch 97/1000\n",
      "61/61 [==============================] - 2s 28ms/step - loss: 0.2547 - val_loss: 0.3337\n",
      "Epoch 98/1000\n",
      "61/61 [==============================] - 2s 28ms/step - loss: 0.2533 - val_loss: 0.3402\n",
      "Epoch 99/1000\n",
      "61/61 [==============================] - 2s 28ms/step - loss: 0.2496 - val_loss: 0.3334\n",
      "Epoch 100/1000\n",
      "61/61 [==============================] - 2s 28ms/step - loss: 0.2452 - val_loss: 0.3322\n",
      "Epoch 101/1000\n",
      "61/61 [==============================] - 2s 28ms/step - loss: 0.2452 - val_loss: 0.3316\n",
      "Epoch 102/1000\n",
      "61/61 [==============================] - 2s 28ms/step - loss: 0.2426 - val_loss: 0.3243\n",
      "Epoch 103/1000\n",
      "61/61 [==============================] - 2s 27ms/step - loss: 0.2414 - val_loss: 0.3242\n",
      "Epoch 104/1000\n",
      "61/61 [==============================] - 2s 27ms/step - loss: 0.2382 - val_loss: 0.3220\n",
      "Epoch 105/1000\n",
      "61/61 [==============================] - 2s 28ms/step - loss: 0.2392 - val_loss: 0.3235\n",
      "Epoch 106/1000\n",
      "61/61 [==============================] - 2s 28ms/step - loss: 0.2381 - val_loss: 0.3304\n",
      "Epoch 107/1000\n",
      "61/61 [==============================] - 2s 28ms/step - loss: 0.2405 - val_loss: 0.3279\n",
      "Epoch 108/1000\n",
      "61/61 [==============================] - 2s 28ms/step - loss: 0.2343 - val_loss: 0.3084\n",
      "Epoch 109/1000\n",
      "61/61 [==============================] - 2s 28ms/step - loss: 0.2354 - val_loss: 0.3204\n",
      "Epoch 110/1000\n",
      "61/61 [==============================] - 2s 28ms/step - loss: 0.2334 - val_loss: 0.3065\n",
      "Epoch 111/1000\n",
      "61/61 [==============================] - 2s 28ms/step - loss: 0.2322 - val_loss: 0.3088\n",
      "Epoch 112/1000\n",
      "61/61 [==============================] - 2s 28ms/step - loss: 0.2302 - val_loss: 0.3178\n",
      "Epoch 113/1000\n",
      "61/61 [==============================] - 2s 28ms/step - loss: 0.2317 - val_loss: 0.3069\n",
      "Epoch 114/1000\n",
      "61/61 [==============================] - 2s 28ms/step - loss: 0.2299 - val_loss: 0.3170\n",
      "Epoch 115/1000\n",
      "61/61 [==============================] - 2s 28ms/step - loss: 0.2285 - val_loss: 0.3036\n",
      "Epoch 116/1000\n",
      "61/61 [==============================] - 2s 28ms/step - loss: 0.2299 - val_loss: 0.3093\n",
      "Epoch 117/1000\n",
      "61/61 [==============================] - 2s 28ms/step - loss: 0.2294 - val_loss: 0.3159\n",
      "Epoch 118/1000\n",
      "61/61 [==============================] - 2s 28ms/step - loss: 0.2271 - val_loss: 0.3097\n",
      "Epoch 119/1000\n",
      "61/61 [==============================] - 2s 27ms/step - loss: 0.2276 - val_loss: 0.3024\n",
      "Epoch 120/1000\n",
      "61/61 [==============================] - 2s 27ms/step - loss: 0.2279 - val_loss: 0.2960\n",
      "Epoch 121/1000\n",
      "61/61 [==============================] - 2s 26ms/step - loss: 0.2254 - val_loss: 0.3006\n",
      "Epoch 122/1000\n",
      "61/61 [==============================] - 2s 27ms/step - loss: 0.2270 - val_loss: 0.3110\n",
      "Epoch 123/1000\n",
      "61/61 [==============================] - 2s 27ms/step - loss: 0.2268 - val_loss: 0.3182\n",
      "Epoch 124/1000\n",
      "61/61 [==============================] - 2s 27ms/step - loss: 0.2248 - val_loss: 0.3184\n",
      "Epoch 125/1000\n",
      "61/61 [==============================] - 2s 28ms/step - loss: 0.2239 - val_loss: 0.3097\n",
      "Epoch 126/1000\n",
      "61/61 [==============================] - 2s 28ms/step - loss: 0.2230 - val_loss: 0.3171\n",
      "Epoch 127/1000\n",
      "61/61 [==============================] - 2s 28ms/step - loss: 0.2254 - val_loss: 0.3120\n",
      "Epoch 128/1000\n",
      "61/61 [==============================] - 2s 28ms/step - loss: 0.2230 - val_loss: 0.2993\n",
      "Epoch 129/1000\n",
      "61/61 [==============================] - 2s 28ms/step - loss: 0.2225 - val_loss: 0.2917\n",
      "Epoch 130/1000\n",
      "61/61 [==============================] - 2s 27ms/step - loss: 0.2235 - val_loss: 0.2971\n",
      "Epoch 131/1000\n",
      "61/61 [==============================] - 2s 27ms/step - loss: 0.2222 - val_loss: 0.3003\n",
      "Epoch 132/1000\n",
      "61/61 [==============================] - 2s 27ms/step - loss: 0.2232 - val_loss: 0.2901\n",
      "Epoch 133/1000\n",
      "61/61 [==============================] - 2s 27ms/step - loss: 0.2206 - val_loss: 0.2947\n",
      "Epoch 134/1000\n",
      "61/61 [==============================] - 2s 28ms/step - loss: 0.2205 - val_loss: 0.2883\n",
      "Epoch 135/1000\n",
      "61/61 [==============================] - 2s 27ms/step - loss: 0.2206 - val_loss: 0.2935\n",
      "Epoch 136/1000\n",
      "61/61 [==============================] - 2s 27ms/step - loss: 0.2180 - val_loss: 0.2964\n",
      "Epoch 137/1000\n",
      "61/61 [==============================] - 2s 28ms/step - loss: 0.2215 - val_loss: 0.3045\n",
      "Epoch 138/1000\n",
      "61/61 [==============================] - 2s 27ms/step - loss: 0.2198 - val_loss: 0.3002\n",
      "Epoch 139/1000\n",
      "61/61 [==============================] - 2s 28ms/step - loss: 0.2209 - val_loss: 0.2878\n",
      "Epoch 140/1000\n",
      "61/61 [==============================] - 2s 28ms/step - loss: 0.2197 - val_loss: 0.2859\n",
      "Epoch 141/1000\n",
      "61/61 [==============================] - 2s 27ms/step - loss: 0.2179 - val_loss: 0.2908\n",
      "Epoch 142/1000\n",
      "61/61 [==============================] - 2s 27ms/step - loss: 0.2167 - val_loss: 0.2882\n",
      "Epoch 143/1000\n",
      "61/61 [==============================] - 2s 27ms/step - loss: 0.2154 - val_loss: 0.2837\n",
      "Epoch 144/1000\n",
      "61/61 [==============================] - 2s 27ms/step - loss: 0.2145 - val_loss: 0.2839\n",
      "Epoch 145/1000\n",
      "61/61 [==============================] - 2s 28ms/step - loss: 0.2135 - val_loss: 0.2776\n",
      "Epoch 146/1000\n",
      "61/61 [==============================] - 2s 27ms/step - loss: 0.2137 - val_loss: 0.2966\n",
      "Epoch 147/1000\n",
      "61/61 [==============================] - 2s 28ms/step - loss: 0.2134 - val_loss: 0.2831\n",
      "Epoch 148/1000\n",
      "61/61 [==============================] - 2s 28ms/step - loss: 0.2142 - val_loss: 0.2875\n",
      "Epoch 149/1000\n",
      "61/61 [==============================] - 2s 27ms/step - loss: 0.2149 - val_loss: 0.2813\n",
      "Epoch 150/1000\n",
      "61/61 [==============================] - 2s 27ms/step - loss: 0.2175 - val_loss: 0.2960\n",
      "Epoch 151/1000\n",
      "61/61 [==============================] - 2s 27ms/step - loss: 0.2137 - val_loss: 0.2857\n",
      "Epoch 152/1000\n",
      "61/61 [==============================] - 2s 28ms/step - loss: 0.2122 - val_loss: 0.2792\n",
      "Epoch 153/1000\n",
      "61/61 [==============================] - 2s 28ms/step - loss: 0.2130 - val_loss: 0.2794\n",
      "Epoch 154/1000\n",
      "61/61 [==============================] - 2s 28ms/step - loss: 0.2130 - val_loss: 0.2755\n",
      "Epoch 155/1000\n",
      "61/61 [==============================] - 2s 28ms/step - loss: 0.2127 - val_loss: 0.2854\n",
      "Epoch 156/1000\n",
      "61/61 [==============================] - 2s 27ms/step - loss: 0.2117 - val_loss: 0.2772\n",
      "Epoch 157/1000\n",
      "61/61 [==============================] - 2s 27ms/step - loss: 0.2100 - val_loss: 0.2825\n",
      "Epoch 158/1000\n",
      "61/61 [==============================] - 2s 27ms/step - loss: 0.2126 - val_loss: 0.2782\n",
      "Epoch 159/1000\n",
      "61/61 [==============================] - 2s 27ms/step - loss: 0.2121 - val_loss: 0.2778\n",
      "Epoch 160/1000\n",
      "61/61 [==============================] - 2s 28ms/step - loss: 0.2123 - val_loss: 0.2758\n",
      "Epoch 161/1000\n",
      "61/61 [==============================] - 2s 28ms/step - loss: 0.2098 - val_loss: 0.2844\n",
      "Epoch 162/1000\n",
      "61/61 [==============================] - 2s 28ms/step - loss: 0.2102 - val_loss: 0.2788\n",
      "Epoch 163/1000\n",
      "61/61 [==============================] - 2s 28ms/step - loss: 0.2111 - val_loss: 0.2753\n",
      "Epoch 164/1000\n",
      "61/61 [==============================] - 2s 28ms/step - loss: 0.2095 - val_loss: 0.2891\n",
      "Epoch 165/1000\n",
      "61/61 [==============================] - 2s 28ms/step - loss: 0.2093 - val_loss: 0.2712\n",
      "Epoch 166/1000\n",
      "61/61 [==============================] - 2s 27ms/step - loss: 0.2072 - val_loss: 0.2728\n",
      "Epoch 167/1000\n",
      "61/61 [==============================] - 2s 28ms/step - loss: 0.2091 - val_loss: 0.2722\n",
      "Epoch 168/1000\n",
      "61/61 [==============================] - 2s 28ms/step - loss: 0.2104 - val_loss: 0.2851\n",
      "Epoch 169/1000\n",
      "61/61 [==============================] - 2s 28ms/step - loss: 0.2087 - val_loss: 0.2622\n",
      "Epoch 170/1000\n",
      "61/61 [==============================] - 2s 27ms/step - loss: 0.2098 - val_loss: 0.2717\n",
      "Epoch 171/1000\n",
      "61/61 [==============================] - 2s 28ms/step - loss: 0.2106 - val_loss: 0.2643\n",
      "Epoch 172/1000\n",
      "61/61 [==============================] - 2s 27ms/step - loss: 0.2083 - val_loss: 0.2638\n",
      "Epoch 173/1000\n",
      "61/61 [==============================] - 2s 28ms/step - loss: 0.2062 - val_loss: 0.2645\n",
      "Epoch 174/1000\n",
      "61/61 [==============================] - 2s 27ms/step - loss: 0.2052 - val_loss: 0.2738\n",
      "Epoch 175/1000\n",
      "61/61 [==============================] - 2s 28ms/step - loss: 0.2065 - val_loss: 0.2772\n",
      "Epoch 176/1000\n",
      "61/61 [==============================] - 2s 27ms/step - loss: 0.2084 - val_loss: 0.2643\n",
      "Epoch 177/1000\n",
      "61/61 [==============================] - 2s 28ms/step - loss: 0.2085 - val_loss: 0.2862\n",
      "Epoch 178/1000\n",
      "61/61 [==============================] - 2s 28ms/step - loss: 0.2074 - val_loss: 0.2692\n",
      "Epoch 179/1000\n",
      "61/61 [==============================] - 2s 27ms/step - loss: 0.2066 - val_loss: 0.2822\n",
      "Epoch 180/1000\n",
      "61/61 [==============================] - 2s 28ms/step - loss: 0.2049 - val_loss: 0.2770\n",
      "Epoch 181/1000\n",
      "61/61 [==============================] - 2s 27ms/step - loss: 0.2036 - val_loss: 0.2777\n",
      "Epoch 182/1000\n",
      "61/61 [==============================] - 2s 28ms/step - loss: 0.2025 - val_loss: 0.2641\n",
      "Epoch 183/1000\n",
      "61/61 [==============================] - 2s 27ms/step - loss: 0.2045 - val_loss: 0.2600\n",
      "Epoch 184/1000\n",
      "61/61 [==============================] - 2s 28ms/step - loss: 0.2041 - val_loss: 0.2658\n",
      "Epoch 185/1000\n",
      "61/61 [==============================] - 2s 28ms/step - loss: 0.2049 - val_loss: 0.2779\n",
      "Epoch 186/1000\n",
      "61/61 [==============================] - 2s 28ms/step - loss: 0.2032 - val_loss: 0.2658\n",
      "Epoch 187/1000\n",
      "61/61 [==============================] - 2s 28ms/step - loss: 0.2018 - val_loss: 0.2623\n",
      "Epoch 188/1000\n",
      "61/61 [==============================] - 2s 28ms/step - loss: 0.2022 - val_loss: 0.2548\n",
      "Epoch 189/1000\n",
      "61/61 [==============================] - 2s 28ms/step - loss: 0.2020 - val_loss: 0.2678\n",
      "Epoch 190/1000\n",
      "61/61 [==============================] - 2s 28ms/step - loss: 0.2000 - val_loss: 0.2739\n",
      "Epoch 191/1000\n",
      "61/61 [==============================] - 2s 28ms/step - loss: 0.2026 - val_loss: 0.2672\n",
      "Epoch 192/1000\n",
      "61/61 [==============================] - 2s 28ms/step - loss: 0.2019 - val_loss: 0.2662\n",
      "Epoch 193/1000\n",
      "61/61 [==============================] - 2s 28ms/step - loss: 0.2001 - val_loss: 0.2599\n",
      "Epoch 194/1000\n",
      "61/61 [==============================] - 2s 28ms/step - loss: 0.2008 - val_loss: 0.2918\n",
      "Epoch 195/1000\n",
      "61/61 [==============================] - 2s 28ms/step - loss: 0.2034 - val_loss: 0.2657\n",
      "Epoch 196/1000\n",
      "61/61 [==============================] - 2s 28ms/step - loss: 0.2019 - val_loss: 0.2595\n",
      "Epoch 197/1000\n",
      "61/61 [==============================] - 2s 27ms/step - loss: 0.2009 - val_loss: 0.2566\n",
      "Epoch 198/1000\n",
      "61/61 [==============================] - 2s 28ms/step - loss: 0.2003 - val_loss: 0.2653\n",
      "Epoch 199/1000\n",
      "61/61 [==============================] - 2s 27ms/step - loss: 0.1986 - val_loss: 0.2649\n",
      "Epoch 200/1000\n",
      "61/61 [==============================] - 2s 27ms/step - loss: 0.1994 - val_loss: 0.2571\n",
      "Epoch 201/1000\n",
      "61/61 [==============================] - 2s 27ms/step - loss: 0.1988 - val_loss: 0.2501\n",
      "Epoch 202/1000\n",
      "61/61 [==============================] - 2s 27ms/step - loss: 0.1985 - val_loss: 0.2606\n",
      "Epoch 203/1000\n",
      "61/61 [==============================] - 2s 27ms/step - loss: 0.1966 - val_loss: 0.2624\n",
      "Epoch 204/1000\n",
      "61/61 [==============================] - 2s 27ms/step - loss: 0.1977 - val_loss: 0.2586\n",
      "Epoch 205/1000\n",
      "61/61 [==============================] - 2s 28ms/step - loss: 0.1978 - val_loss: 0.2497\n",
      "Epoch 206/1000\n",
      "61/61 [==============================] - 2s 28ms/step - loss: 0.1971 - val_loss: 0.2559\n",
      "Epoch 207/1000\n",
      "61/61 [==============================] - 2s 27ms/step - loss: 0.1981 - val_loss: 0.2826\n",
      "Epoch 208/1000\n",
      "61/61 [==============================] - 2s 27ms/step - loss: 0.2211 - val_loss: 0.2941\n",
      "Epoch 209/1000\n",
      "61/61 [==============================] - 2s 28ms/step - loss: 0.2768 - val_loss: 0.3455\n",
      "Epoch 210/1000\n",
      "61/61 [==============================] - 2s 27ms/step - loss: 0.2678 - val_loss: 0.3391\n",
      "Epoch 211/1000\n",
      "61/61 [==============================] - 2s 27ms/step - loss: 0.3898 - val_loss: 0.5478\n",
      "Epoch 212/1000\n",
      "61/61 [==============================] - 2s 28ms/step - loss: 0.3440 - val_loss: 0.4122\n",
      "Epoch 213/1000\n",
      "61/61 [==============================] - 2s 28ms/step - loss: 0.2891 - val_loss: 0.3409\n",
      "Epoch 214/1000\n",
      "61/61 [==============================] - 2s 28ms/step - loss: 0.2420 - val_loss: 0.3135\n",
      "Epoch 215/1000\n",
      "61/61 [==============================] - 2s 28ms/step - loss: 0.2330 - val_loss: 0.3524\n",
      "Epoch 216/1000\n",
      "61/61 [==============================] - 2s 28ms/step - loss: 0.2341 - val_loss: 0.2852\n",
      "Epoch 217/1000\n",
      "61/61 [==============================] - 2s 28ms/step - loss: 0.2291 - val_loss: 0.2908\n",
      "Epoch 218/1000\n",
      "61/61 [==============================] - 2s 28ms/step - loss: 0.2201 - val_loss: 0.2831\n",
      "Epoch 219/1000\n",
      "61/61 [==============================] - 2s 28ms/step - loss: 0.2113 - val_loss: 0.2779\n",
      "Epoch 220/1000\n",
      "61/61 [==============================] - 2s 27ms/step - loss: 0.2088 - val_loss: 0.2778\n",
      "Epoch 221/1000\n",
      "61/61 [==============================] - 2s 27ms/step - loss: 0.2066 - val_loss: 0.2668\n",
      "Epoch 222/1000\n",
      "61/61 [==============================] - 2s 28ms/step - loss: 0.2052 - val_loss: 0.2699\n",
      "Epoch 223/1000\n",
      "61/61 [==============================] - 2s 27ms/step - loss: 0.2021 - val_loss: 0.2602\n",
      "Epoch 224/1000\n",
      "61/61 [==============================] - 2s 27ms/step - loss: 0.2030 - val_loss: 0.2590\n",
      "Epoch 225/1000\n",
      "61/61 [==============================] - 2s 27ms/step - loss: 0.2023 - val_loss: 0.2674\n",
      "Epoch 226/1000\n",
      "61/61 [==============================] - 2s 27ms/step - loss: 0.2002 - val_loss: 0.2588\n",
      "Epoch 227/1000\n",
      "61/61 [==============================] - 2s 27ms/step - loss: 0.1997 - val_loss: 0.2630\n",
      "Epoch 228/1000\n",
      "61/61 [==============================] - 2s 27ms/step - loss: 0.1977 - val_loss: 0.2586\n",
      "Epoch 229/1000\n",
      "61/61 [==============================] - 2s 27ms/step - loss: 0.1980 - val_loss: 0.2592\n",
      "Epoch 230/1000\n",
      "61/61 [==============================] - 2s 27ms/step - loss: 0.1955 - val_loss: 0.2579\n",
      "Epoch 231/1000\n",
      "61/61 [==============================] - 2s 27ms/step - loss: 0.1975 - val_loss: 0.2591\n",
      "Epoch 232/1000\n",
      "61/61 [==============================] - 2s 28ms/step - loss: 0.1961 - val_loss: 0.2573\n",
      "Epoch 233/1000\n",
      "61/61 [==============================] - 2s 27ms/step - loss: 0.1955 - val_loss: 0.2545\n",
      "Epoch 234/1000\n",
      "61/61 [==============================] - 2s 27ms/step - loss: 0.1954 - val_loss: 0.2578\n",
      "Epoch 235/1000\n",
      "61/61 [==============================] - 2s 27ms/step - loss: 0.1933 - val_loss: 0.2630\n",
      "Epoch 236/1000\n",
      "61/61 [==============================] - 2s 26ms/step - loss: 0.1940 - val_loss: 0.2580\n",
      "Epoch 237/1000\n",
      "61/61 [==============================] - 2s 27ms/step - loss: 0.1935 - val_loss: 0.2537\n",
      "Epoch 238/1000\n",
      "61/61 [==============================] - 2s 27ms/step - loss: 0.1935 - val_loss: 0.2567\n",
      "Epoch 239/1000\n",
      "61/61 [==============================] - 2s 28ms/step - loss: 0.1924 - val_loss: 0.2489\n",
      "Epoch 240/1000\n",
      "61/61 [==============================] - 2s 27ms/step - loss: 0.1935 - val_loss: 0.2446\n",
      "Epoch 241/1000\n",
      "61/61 [==============================] - 2s 28ms/step - loss: 0.1928 - val_loss: 0.2449\n",
      "Epoch 242/1000\n",
      "61/61 [==============================] - 2s 28ms/step - loss: 0.1927 - val_loss: 0.2469\n",
      "Epoch 243/1000\n",
      "61/61 [==============================] - 2s 28ms/step - loss: 0.1921 - val_loss: 0.2453\n",
      "Epoch 244/1000\n",
      "61/61 [==============================] - 2s 28ms/step - loss: 0.1923 - val_loss: 0.2447\n",
      "Epoch 245/1000\n",
      "61/61 [==============================] - 2s 28ms/step - loss: 0.1907 - val_loss: 0.2365\n",
      "Epoch 246/1000\n",
      "61/61 [==============================] - 2s 28ms/step - loss: 0.1917 - val_loss: 0.2486\n",
      "Epoch 247/1000\n",
      "61/61 [==============================] - 2s 28ms/step - loss: 0.1916 - val_loss: 0.2394\n",
      "Epoch 248/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.1909 - val_loss: 0.2424\n",
      "Epoch 249/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.1891 - val_loss: 0.2402\n",
      "Epoch 250/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.1903 - val_loss: 0.2413\n",
      "Epoch 251/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.1896 - val_loss: 0.2418\n",
      "Epoch 252/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.1905 - val_loss: 0.2454\n",
      "Epoch 253/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.1904 - val_loss: 0.2368\n",
      "Epoch 254/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.1903 - val_loss: 0.2360\n",
      "Epoch 255/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.1909 - val_loss: 0.2461\n",
      "Epoch 256/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.1905 - val_loss: 0.2418\n",
      "Epoch 257/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.1902 - val_loss: 0.2406\n",
      "Epoch 258/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.1893 - val_loss: 0.2364\n",
      "Epoch 259/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.1885 - val_loss: 0.2365\n",
      "Epoch 260/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.1883 - val_loss: 0.2355\n",
      "Epoch 261/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.1887 - val_loss: 0.2387\n",
      "Epoch 262/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.1889 - val_loss: 0.2437\n",
      "Epoch 263/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.1890 - val_loss: 0.2435\n",
      "Epoch 264/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.1881 - val_loss: 0.2439\n",
      "Epoch 265/1000\n",
      "61/61 [==============================] - 2s 32ms/step - loss: 0.1885 - val_loss: 0.2385\n",
      "Epoch 266/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.1885 - val_loss: 0.2416\n",
      "Epoch 267/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.1883 - val_loss: 0.2352\n",
      "Epoch 268/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.1874 - val_loss: 0.2335\n",
      "Epoch 269/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.1877 - val_loss: 0.2380\n",
      "Epoch 270/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.1871 - val_loss: 0.2327\n",
      "Epoch 271/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.1876 - val_loss: 0.2365\n",
      "Epoch 272/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.1883 - val_loss: 0.2382\n",
      "Epoch 273/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.1886 - val_loss: 0.2288\n",
      "Epoch 274/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.1873 - val_loss: 0.2407\n",
      "Epoch 275/1000\n",
      "61/61 [==============================] - 2s 31ms/step - loss: 0.1874 - val_loss: 0.2312\n",
      "Epoch 276/1000\n",
      "61/61 [==============================] - 2s 31ms/step - loss: 0.1897 - val_loss: 0.2386\n",
      "Epoch 277/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.1885 - val_loss: 0.2314\n",
      "Epoch 278/1000\n",
      "61/61 [==============================] - 2s 31ms/step - loss: 0.1900 - val_loss: 0.2367\n",
      "Epoch 279/1000\n",
      "61/61 [==============================] - 2s 31ms/step - loss: 0.1900 - val_loss: 0.2339\n",
      "Epoch 280/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.1875 - val_loss: 0.2354\n",
      "Epoch 281/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.1856 - val_loss: 0.2294\n",
      "Epoch 282/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.1867 - val_loss: 0.2264\n",
      "Epoch 283/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.1884 - val_loss: 0.2415\n",
      "Epoch 284/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.1874 - val_loss: 0.2229\n",
      "Epoch 285/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.1869 - val_loss: 0.2303\n",
      "Epoch 286/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.1887 - val_loss: 0.2351\n",
      "Epoch 287/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.1872 - val_loss: 0.2345\n",
      "Epoch 288/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.1866 - val_loss: 0.2208\n",
      "Epoch 289/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.1856 - val_loss: 0.2339\n",
      "Epoch 290/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.1866 - val_loss: 0.2214\n",
      "Epoch 291/1000\n",
      "61/61 [==============================] - 2s 31ms/step - loss: 0.1855 - val_loss: 0.2326\n",
      "Epoch 292/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.1854 - val_loss: 0.2302\n",
      "Epoch 293/1000\n",
      "61/61 [==============================] - 2s 32ms/step - loss: 0.1851 - val_loss: 0.2395\n",
      "Epoch 294/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.1858 - val_loss: 0.2403\n",
      "Epoch 295/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.1867 - val_loss: 0.2356\n",
      "Epoch 296/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.1870 - val_loss: 0.2205\n",
      "Epoch 297/1000\n",
      "61/61 [==============================] - 2s 31ms/step - loss: 0.1849 - val_loss: 0.2266\n",
      "Epoch 298/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.1843 - val_loss: 0.2288\n",
      "Epoch 299/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.1847 - val_loss: 0.2301\n",
      "Epoch 300/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.1846 - val_loss: 0.2264\n",
      "Epoch 301/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.1834 - val_loss: 0.2267\n",
      "Epoch 302/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.1836 - val_loss: 0.2245\n",
      "Epoch 303/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.1834 - val_loss: 0.2339\n",
      "Epoch 304/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.1857 - val_loss: 0.2271\n",
      "Epoch 305/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.1860 - val_loss: 0.2271\n",
      "Epoch 306/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.1851 - val_loss: 0.2272\n",
      "Epoch 307/1000\n",
      "61/61 [==============================] - 2s 31ms/step - loss: 0.1846 - val_loss: 0.2263\n",
      "Epoch 308/1000\n",
      "61/61 [==============================] - 2s 33ms/step - loss: 0.1830 - val_loss: 0.2217\n",
      "Epoch 309/1000\n",
      "61/61 [==============================] - 2s 32ms/step - loss: 0.2028 - val_loss: 0.3500\n",
      "Epoch 310/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.3012 - val_loss: 0.3723\n",
      "Epoch 311/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.2460 - val_loss: 0.2724\n",
      "Epoch 312/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.2193 - val_loss: 0.2637\n",
      "Epoch 313/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.2177 - val_loss: 0.2546\n",
      "Epoch 314/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.2005 - val_loss: 0.2364\n",
      "Epoch 315/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.1939 - val_loss: 0.2290\n",
      "Epoch 316/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.1914 - val_loss: 0.2282\n",
      "Epoch 317/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.1906 - val_loss: 0.2255\n",
      "Epoch 318/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.1882 - val_loss: 0.2240\n",
      "Epoch 319/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.1868 - val_loss: 0.2209\n",
      "Epoch 320/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.1868 - val_loss: 0.2193\n",
      "Epoch 321/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.1864 - val_loss: 0.2248\n",
      "Epoch 322/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.1844 - val_loss: 0.2222\n",
      "Epoch 323/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.1836 - val_loss: 0.2198\n",
      "Epoch 324/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.1828 - val_loss: 0.2239\n",
      "Epoch 325/1000\n",
      "61/61 [==============================] - 2s 28ms/step - loss: 0.1832 - val_loss: 0.2235\n",
      "Epoch 326/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.1829 - val_loss: 0.2147\n",
      "Epoch 327/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.1823 - val_loss: 0.2148\n",
      "Epoch 328/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.1820 - val_loss: 0.2192\n",
      "Epoch 329/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.1822 - val_loss: 0.2167\n",
      "Epoch 330/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.1821 - val_loss: 0.2138\n",
      "Epoch 331/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.1810 - val_loss: 0.2189\n",
      "Epoch 332/1000\n",
      "61/61 [==============================] - 2s 28ms/step - loss: 0.1812 - val_loss: 0.2176\n",
      "Epoch 333/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.1814 - val_loss: 0.2168\n",
      "Epoch 334/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.1817 - val_loss: 0.2112\n",
      "Epoch 335/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.1805 - val_loss: 0.2082\n",
      "Epoch 336/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.1812 - val_loss: 0.2149\n",
      "Epoch 337/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.1803 - val_loss: 0.2207\n",
      "Epoch 338/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.1806 - val_loss: 0.2186\n",
      "Epoch 339/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.1814 - val_loss: 0.2138\n",
      "Epoch 340/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.1807 - val_loss: 0.2238\n",
      "Epoch 341/1000\n",
      "61/61 [==============================] - 2s 31ms/step - loss: 0.1794 - val_loss: 0.2211\n",
      "Epoch 342/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.1805 - val_loss: 0.2149\n",
      "Epoch 343/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.1807 - val_loss: 0.2153\n",
      "Epoch 344/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.1805 - val_loss: 0.2104\n",
      "Epoch 345/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.1792 - val_loss: 0.2186\n",
      "Epoch 346/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.1805 - val_loss: 0.2157\n",
      "Epoch 347/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.1789 - val_loss: 0.2148\n",
      "Epoch 348/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.1797 - val_loss: 0.2156\n",
      "Epoch 349/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.1792 - val_loss: 0.2135\n",
      "Epoch 350/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.1804 - val_loss: 0.2147\n",
      "Epoch 351/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.1794 - val_loss: 0.2227\n",
      "Epoch 352/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.1797 - val_loss: 0.2164\n",
      "Epoch 353/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.1793 - val_loss: 0.2194\n",
      "Epoch 354/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.1786 - val_loss: 0.2100\n",
      "Epoch 355/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.1799 - val_loss: 0.2206\n",
      "Epoch 356/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.1792 - val_loss: 0.2156\n",
      "Epoch 357/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.1800 - val_loss: 0.2155\n",
      "Epoch 358/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.1792 - val_loss: 0.2192\n",
      "Epoch 359/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.1795 - val_loss: 0.2194\n",
      "Epoch 360/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.1779 - val_loss: 0.2218\n",
      "Epoch 361/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.1785 - val_loss: 0.2178\n",
      "Epoch 362/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.1781 - val_loss: 0.2164\n",
      "Epoch 363/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.1798 - val_loss: 0.2133\n",
      "Epoch 364/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.1783 - val_loss: 0.2129\n",
      "Epoch 365/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.1783 - val_loss: 0.2170\n",
      "Epoch 366/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.1792 - val_loss: 0.2130\n",
      "Epoch 367/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.1793 - val_loss: 0.2197\n",
      "Epoch 368/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.1790 - val_loss: 0.2067\n",
      "Epoch 369/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.1787 - val_loss: 0.2151\n",
      "Epoch 370/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.1778 - val_loss: 0.2223\n",
      "Epoch 371/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.1778 - val_loss: 0.2114\n",
      "Epoch 372/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.1780 - val_loss: 0.2084\n",
      "Epoch 373/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.1774 - val_loss: 0.2124\n",
      "Epoch 374/1000\n",
      "61/61 [==============================] - 2s 31ms/step - loss: 0.1796 - val_loss: 0.2171\n",
      "Epoch 375/1000\n",
      "61/61 [==============================] - 2s 31ms/step - loss: 0.1797 - val_loss: 0.2323\n",
      "Epoch 376/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.1809 - val_loss: 0.2137\n",
      "Epoch 377/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.1792 - val_loss: 0.2146\n",
      "Epoch 378/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.1780 - val_loss: 0.2215\n",
      "Epoch 379/1000\n",
      "61/61 [==============================] - 2s 31ms/step - loss: 0.1782 - val_loss: 0.2126\n",
      "Epoch 380/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.1787 - val_loss: 0.2268\n",
      "Epoch 381/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.1781 - val_loss: 0.2253\n",
      "Epoch 382/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.1772 - val_loss: 0.2292\n",
      "Epoch 383/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.1786 - val_loss: 0.2308\n",
      "Epoch 384/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.1783 - val_loss: 0.2240\n",
      "Epoch 385/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.1772 - val_loss: 0.2125\n",
      "Epoch 386/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.1771 - val_loss: 0.2150\n",
      "Epoch 387/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.1774 - val_loss: 0.2160\n",
      "Epoch 388/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.1766 - val_loss: 0.2181\n",
      "Epoch 389/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.1766 - val_loss: 0.2087\n",
      "Epoch 390/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.1773 - val_loss: 0.2161\n",
      "Epoch 391/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.1768 - val_loss: 0.2270\n",
      "Epoch 392/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.1769 - val_loss: 0.2188\n",
      "Epoch 393/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.1770 - val_loss: 0.2282\n",
      "Epoch 394/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.1767 - val_loss: 0.2167\n",
      "Epoch 395/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.1765 - val_loss: 0.2197\n",
      "Epoch 396/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.1769 - val_loss: 0.2180\n",
      "Epoch 397/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.1764 - val_loss: 0.2100\n",
      "Epoch 398/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.1765 - val_loss: 0.2227\n",
      "Epoch 399/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.1749 - val_loss: 0.2101\n",
      "Epoch 400/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.1758 - val_loss: 0.2070\n",
      "Epoch 401/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.1754 - val_loss: 0.2137\n",
      "Epoch 402/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.1754 - val_loss: 0.2171\n",
      "Epoch 403/1000\n",
      "61/61 [==============================] - ETA: 0s - loss: 0.1755Restoring model weights from the end of the best epoch: 368.\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.1755 - val_loss: 0.2145\n",
      "Epoch 403: early stopping\n",
      "7/7 [==============================] - 1s 10ms/step\n",
      "0.18813946919570584\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f5955dfa8a0b481bba61b910ebef61af",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.060 MB of 0.060 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch/epoch</td><td>▁▁▁▁▂▂▂▂▃▃▃▃▃▃▃▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▆▇▇▇▇▇███</td></tr><tr><td>epoch/learning_rate</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>epoch/loss</td><td>█▆▄▃▃▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>epoch/val_loss</td><td>█▅▅▅▄▄▄▄▃▃▃▂▂▂▂▂▃▄▃▂▂▂▂▂▂▁▁▄▄▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>rmase_prediction</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch/epoch</td><td>402</td></tr><tr><td>epoch/learning_rate</td><td>0.00049</td></tr><tr><td>epoch/loss</td><td>0.17549</td></tr><tr><td>epoch/val_loss</td><td>0.21453</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">test_0</strong> at: <a href='https://wandb.ai/uu13234-none/sgnate_skate-keras/runs/cwqopqx1' target=\"_blank\">https://wandb.ai/uu13234-none/sgnate_skate-keras/runs/cwqopqx1</a><br/> View project at: <a href='https://wandb.ai/uu13234-none/sgnate_skate-keras' target=\"_blank\">https://wandb.ai/uu13234-none/sgnate_skate-keras</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20241104_140355-cwqopqx1\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.18.3"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\sato\\Desktop\\python\\SIGNATE\\スケートボードの挙動予測\\code-analysis\\wandb\\run-20241104_141605-jq65ie6v</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/uu13234-none/sgnate_skate-keras/runs/jq65ie6v' target=\"_blank\">test_1</a></strong> to <a href='https://wandb.ai/uu13234-none/sgnate_skate-keras' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/uu13234-none/sgnate_skate-keras' target=\"_blank\">https://wandb.ai/uu13234-none/sgnate_skate-keras</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/uu13234-none/sgnate_skate-keras/runs/jq65ie6v' target=\"_blank\">https://wandb.ai/uu13234-none/sgnate_skate-keras/runs/jq65ie6v</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      " 5/61 [=>............................] - ETA: 1s - loss: 2.3724 WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0199s vs `on_train_batch_end` time: 0.0350s). Check your callbacks.\n",
      "61/61 [==============================] - 9s 55ms/step - loss: 1.5251 - val_loss: 1.2643\n",
      "Epoch 2/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 1.0653 - val_loss: 1.0209\n",
      "Epoch 3/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.8878 - val_loss: 0.8463\n",
      "Epoch 4/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.8436 - val_loss: 0.7623\n",
      "Epoch 5/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.8061 - val_loss: 0.8489\n",
      "Epoch 6/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.7940 - val_loss: 0.8229\n",
      "Epoch 7/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.7508 - val_loss: 0.7095\n",
      "Epoch 8/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.6582 - val_loss: 0.6666\n",
      "Epoch 9/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.6212 - val_loss: 0.6249\n",
      "Epoch 10/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.6254 - val_loss: 0.6427\n",
      "Epoch 11/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.5968 - val_loss: 0.6393\n",
      "Epoch 12/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.5675 - val_loss: 0.6101\n",
      "Epoch 13/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.5906 - val_loss: 0.5930\n",
      "Epoch 14/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.5634 - val_loss: 0.6215\n",
      "Epoch 15/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.5345 - val_loss: 0.6042\n",
      "Epoch 16/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.5685 - val_loss: 0.5777\n",
      "Epoch 17/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.5091 - val_loss: 0.5398\n",
      "Epoch 18/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.4954 - val_loss: 0.5597\n",
      "Epoch 19/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.4899 - val_loss: 0.5502\n",
      "Epoch 20/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.4763 - val_loss: 0.5755\n",
      "Epoch 21/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.4686 - val_loss: 0.5234\n",
      "Epoch 22/1000\n",
      "61/61 [==============================] - 2s 28ms/step - loss: 0.4443 - val_loss: 0.5484\n",
      "Epoch 23/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.4638 - val_loss: 0.5555\n",
      "Epoch 24/1000\n",
      "61/61 [==============================] - 2s 28ms/step - loss: 0.5179 - val_loss: 0.6203\n",
      "Epoch 25/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.4938 - val_loss: 0.6092\n",
      "Epoch 26/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.5167 - val_loss: 0.5543\n",
      "Epoch 27/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.4579 - val_loss: 0.5369\n",
      "Epoch 28/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.5191 - val_loss: 0.5818\n",
      "Epoch 29/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.4921 - val_loss: 0.5682\n",
      "Epoch 30/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.4663 - val_loss: 0.5321\n",
      "Epoch 31/1000\n",
      "61/61 [==============================] - 2s 31ms/step - loss: 0.4232 - val_loss: 0.4782\n",
      "Epoch 32/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.3945 - val_loss: 0.4766\n",
      "Epoch 33/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.4053 - val_loss: 0.4808\n",
      "Epoch 34/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.3768 - val_loss: 0.4766\n",
      "Epoch 35/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.3756 - val_loss: 0.4759\n",
      "Epoch 36/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.3655 - val_loss: 0.4563\n",
      "Epoch 37/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.3584 - val_loss: 0.4586\n",
      "Epoch 38/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.3535 - val_loss: 0.4507\n",
      "Epoch 39/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.3464 - val_loss: 0.4448\n",
      "Epoch 40/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.3475 - val_loss: 0.4450\n",
      "Epoch 41/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.3402 - val_loss: 0.4184\n",
      "Epoch 42/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.3711 - val_loss: 0.4658\n",
      "Epoch 43/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.3467 - val_loss: 0.4550\n",
      "Epoch 44/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.3326 - val_loss: 0.4331\n",
      "Epoch 45/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.3384 - val_loss: 0.4407\n",
      "Epoch 46/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.3271 - val_loss: 0.4411\n",
      "Epoch 47/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.3205 - val_loss: 0.4258\n",
      "Epoch 48/1000\n",
      "61/61 [==============================] - 2s 31ms/step - loss: 0.3194 - val_loss: 0.4258\n",
      "Epoch 49/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.3567 - val_loss: 0.4458\n",
      "Epoch 50/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.3296 - val_loss: 0.4357\n",
      "Epoch 51/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.3220 - val_loss: 0.4223\n",
      "Epoch 52/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.3375 - val_loss: 0.4182\n",
      "Epoch 53/1000\n",
      "61/61 [==============================] - 2s 31ms/step - loss: 0.3136 - val_loss: 0.4027\n",
      "Epoch 54/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.3041 - val_loss: 0.4051\n",
      "Epoch 55/1000\n",
      "61/61 [==============================] - 2s 31ms/step - loss: 0.2980 - val_loss: 0.3929\n",
      "Epoch 56/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.2967 - val_loss: 0.3962\n",
      "Epoch 57/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.2939 - val_loss: 0.3850\n",
      "Epoch 58/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.2884 - val_loss: 0.3884\n",
      "Epoch 59/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.2868 - val_loss: 0.3806\n",
      "Epoch 60/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.2853 - val_loss: 0.3916\n",
      "Epoch 61/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.2873 - val_loss: 0.3833\n",
      "Epoch 62/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.2839 - val_loss: 0.3884\n",
      "Epoch 63/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.2813 - val_loss: 0.3792\n",
      "Epoch 64/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.2823 - val_loss: 0.3820\n",
      "Epoch 65/1000\n",
      "61/61 [==============================] - 2s 28ms/step - loss: 0.2828 - val_loss: 0.3767\n",
      "Epoch 66/1000\n",
      "61/61 [==============================] - 2s 28ms/step - loss: 0.2752 - val_loss: 0.3647\n",
      "Epoch 67/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.2702 - val_loss: 0.3644\n",
      "Epoch 68/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.2701 - val_loss: 0.3690\n",
      "Epoch 69/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.2698 - val_loss: 0.3756\n",
      "Epoch 70/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.2691 - val_loss: 0.3570\n",
      "Epoch 71/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.3254 - val_loss: 0.4201\n",
      "Epoch 72/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.3206 - val_loss: 0.4048\n",
      "Epoch 73/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.2934 - val_loss: 0.3740\n",
      "Epoch 74/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.2760 - val_loss: 0.3878\n",
      "Epoch 75/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.2705 - val_loss: 0.3755\n",
      "Epoch 76/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.2619 - val_loss: 0.3582\n",
      "Epoch 77/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.2641 - val_loss: 0.3669\n",
      "Epoch 78/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.2657 - val_loss: 0.3587\n",
      "Epoch 79/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.2626 - val_loss: 0.3682\n",
      "Epoch 80/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.2578 - val_loss: 0.3453\n",
      "Epoch 81/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.2577 - val_loss: 0.3585\n",
      "Epoch 82/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.2907 - val_loss: 0.5195\n",
      "Epoch 83/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.3816 - val_loss: 0.5160\n",
      "Epoch 84/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.4421 - val_loss: 0.5082\n",
      "Epoch 85/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.3655 - val_loss: 0.5352\n",
      "Epoch 86/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.3237 - val_loss: 0.4070\n",
      "Epoch 87/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.2980 - val_loss: 0.3883\n",
      "Epoch 88/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.2857 - val_loss: 0.3863\n",
      "Epoch 89/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.2699 - val_loss: 0.4095\n",
      "Epoch 90/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.2670 - val_loss: 0.3728\n",
      "Epoch 91/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.2782 - val_loss: 0.4001\n",
      "Epoch 92/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.2665 - val_loss: 0.3615\n",
      "Epoch 93/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.2546 - val_loss: 0.3638\n",
      "Epoch 94/1000\n",
      "61/61 [==============================] - 2s 31ms/step - loss: 0.2503 - val_loss: 0.3491\n",
      "Epoch 95/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.2642 - val_loss: 0.3692\n",
      "Epoch 96/1000\n",
      "61/61 [==============================] - 2s 31ms/step - loss: 0.2648 - val_loss: 0.3500\n",
      "Epoch 97/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.2525 - val_loss: 0.3468\n",
      "Epoch 98/1000\n",
      "61/61 [==============================] - 2s 31ms/step - loss: 0.2479 - val_loss: 0.3437\n",
      "Epoch 99/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.2603 - val_loss: 0.3347\n",
      "Epoch 100/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.2496 - val_loss: 0.3244\n",
      "Epoch 101/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.2441 - val_loss: 0.3402\n",
      "Epoch 102/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.2417 - val_loss: 0.3346\n",
      "Epoch 103/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.2436 - val_loss: 0.3414\n",
      "Epoch 104/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.2459 - val_loss: 0.3348\n",
      "Epoch 105/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.2496 - val_loss: 0.3690\n",
      "Epoch 106/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.2475 - val_loss: 0.3379\n",
      "Epoch 107/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.2388 - val_loss: 0.3309\n",
      "Epoch 108/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.2381 - val_loss: 0.3474\n",
      "Epoch 109/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.2395 - val_loss: 0.3383\n",
      "Epoch 110/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.2363 - val_loss: 0.3215\n",
      "Epoch 111/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.2341 - val_loss: 0.3296\n",
      "Epoch 112/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.2349 - val_loss: 0.3179\n",
      "Epoch 113/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.2352 - val_loss: 0.3328\n",
      "Epoch 114/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.2327 - val_loss: 0.3246\n",
      "Epoch 115/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.2329 - val_loss: 0.3179\n",
      "Epoch 116/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.2326 - val_loss: 0.3271\n",
      "Epoch 117/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.2306 - val_loss: 0.3248\n",
      "Epoch 118/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.2302 - val_loss: 0.3245\n",
      "Epoch 119/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.2297 - val_loss: 0.3181\n",
      "Epoch 120/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.2298 - val_loss: 0.3045\n",
      "Epoch 121/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.2290 - val_loss: 0.3151\n",
      "Epoch 122/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.2292 - val_loss: 0.2996\n",
      "Epoch 123/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.2276 - val_loss: 0.3177\n",
      "Epoch 124/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.2244 - val_loss: 0.3198\n",
      "Epoch 125/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.2249 - val_loss: 0.3087\n",
      "Epoch 126/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.2243 - val_loss: 0.3218\n",
      "Epoch 127/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.2262 - val_loss: 0.3008\n",
      "Epoch 128/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.2260 - val_loss: 0.3157\n",
      "Epoch 129/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.2255 - val_loss: 0.3044\n",
      "Epoch 130/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.2255 - val_loss: 0.3083\n",
      "Epoch 131/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.2253 - val_loss: 0.3118\n",
      "Epoch 132/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.2253 - val_loss: 0.3104\n",
      "Epoch 133/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.2240 - val_loss: 0.3117\n",
      "Epoch 134/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.2227 - val_loss: 0.3173\n",
      "Epoch 135/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.2221 - val_loss: 0.3170\n",
      "Epoch 136/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.2248 - val_loss: 0.3051\n",
      "Epoch 137/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.2209 - val_loss: 0.3001\n",
      "Epoch 138/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.2216 - val_loss: 0.3052\n",
      "Epoch 139/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.2234 - val_loss: 0.3086\n",
      "Epoch 140/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.2208 - val_loss: 0.3029\n",
      "Epoch 141/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.2210 - val_loss: 0.3014\n",
      "Epoch 142/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.2218 - val_loss: 0.3071\n",
      "Epoch 143/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.2217 - val_loss: 0.3051\n",
      "Epoch 144/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.2194 - val_loss: 0.3093\n",
      "Epoch 145/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.2193 - val_loss: 0.2955\n",
      "Epoch 146/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.2205 - val_loss: 0.2924\n",
      "Epoch 147/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.2192 - val_loss: 0.2989\n",
      "Epoch 148/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.2193 - val_loss: 0.3079\n",
      "Epoch 149/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.2183 - val_loss: 0.2970\n",
      "Epoch 150/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.2158 - val_loss: 0.3010\n",
      "Epoch 151/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.2155 - val_loss: 0.2852\n",
      "Epoch 152/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.2167 - val_loss: 0.2928\n",
      "Epoch 153/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.2128 - val_loss: 0.2849\n",
      "Epoch 154/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.2162 - val_loss: 0.2886\n",
      "Epoch 155/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.2145 - val_loss: 0.2985\n",
      "Epoch 156/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.2167 - val_loss: 0.2816\n",
      "Epoch 157/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.2179 - val_loss: 0.3015\n",
      "Epoch 158/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.2127 - val_loss: 0.2946\n",
      "Epoch 159/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.2128 - val_loss: 0.2886\n",
      "Epoch 160/1000\n",
      "61/61 [==============================] - 2s 28ms/step - loss: 0.2108 - val_loss: 0.2983\n",
      "Epoch 161/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.2111 - val_loss: 0.2921\n",
      "Epoch 162/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.2129 - val_loss: 0.2885\n",
      "Epoch 163/1000\n",
      "61/61 [==============================] - 2s 31ms/step - loss: 0.2115 - val_loss: 0.2883\n",
      "Epoch 164/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.2126 - val_loss: 0.2910\n",
      "Epoch 165/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.2114 - val_loss: 0.2982\n",
      "Epoch 166/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.2109 - val_loss: 0.3008\n",
      "Epoch 167/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.2120 - val_loss: 0.2908\n",
      "Epoch 168/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.2099 - val_loss: 0.2822\n",
      "Epoch 169/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.2099 - val_loss: 0.2824\n",
      "Epoch 170/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.2092 - val_loss: 0.2791\n",
      "Epoch 171/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.2090 - val_loss: 0.2842\n",
      "Epoch 172/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.2266 - val_loss: 0.3378\n",
      "Epoch 173/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.2199 - val_loss: 0.2957\n",
      "Epoch 174/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.2102 - val_loss: 0.2961\n",
      "Epoch 175/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.2094 - val_loss: 0.2929\n",
      "Epoch 176/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.2090 - val_loss: 0.3002\n",
      "Epoch 177/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.2086 - val_loss: 0.2873\n",
      "Epoch 178/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.2075 - val_loss: 0.3027\n",
      "Epoch 179/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.2095 - val_loss: 0.2991\n",
      "Epoch 180/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.2069 - val_loss: 0.2829\n",
      "Epoch 181/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.2060 - val_loss: 0.2825\n",
      "Epoch 182/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.2062 - val_loss: 0.2796\n",
      "Epoch 183/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.2063 - val_loss: 0.2764\n",
      "Epoch 184/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.2043 - val_loss: 0.2820\n",
      "Epoch 185/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.2053 - val_loss: 0.2820\n",
      "Epoch 186/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.2039 - val_loss: 0.2765\n",
      "Epoch 187/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.2034 - val_loss: 0.2637\n",
      "Epoch 188/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.2029 - val_loss: 0.2770\n",
      "Epoch 189/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.2028 - val_loss: 0.2775\n",
      "Epoch 190/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.2036 - val_loss: 0.2782\n",
      "Epoch 191/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.2036 - val_loss: 0.2620\n",
      "Epoch 192/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.2017 - val_loss: 0.2698\n",
      "Epoch 193/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.2008 - val_loss: 0.2646\n",
      "Epoch 194/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.2007 - val_loss: 0.2661\n",
      "Epoch 195/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.1999 - val_loss: 0.2713\n",
      "Epoch 196/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.2044 - val_loss: 0.2658\n",
      "Epoch 197/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.2004 - val_loss: 0.2662\n",
      "Epoch 198/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.2009 - val_loss: 0.2784\n",
      "Epoch 199/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.2028 - val_loss: 0.2737\n",
      "Epoch 200/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.2033 - val_loss: 0.2797\n",
      "Epoch 201/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.2008 - val_loss: 0.2777\n",
      "Epoch 202/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.2003 - val_loss: 0.2636\n",
      "Epoch 203/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.2001 - val_loss: 0.2681\n",
      "Epoch 204/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.1980 - val_loss: 0.2693\n",
      "Epoch 205/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.1983 - val_loss: 0.2835\n",
      "Epoch 206/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.1984 - val_loss: 0.2580\n",
      "Epoch 207/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.1992 - val_loss: 0.2688\n",
      "Epoch 208/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.1992 - val_loss: 0.2672\n",
      "Epoch 209/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.2151 - val_loss: 0.4235\n",
      "Epoch 210/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.4197 - val_loss: 0.6326\n",
      "Epoch 211/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.4494 - val_loss: 0.4747\n",
      "Epoch 212/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.3462 - val_loss: 0.4071\n",
      "Epoch 213/1000\n",
      "61/61 [==============================] - 2s 28ms/step - loss: 0.2920 - val_loss: 0.3850\n",
      "Epoch 214/1000\n",
      "61/61 [==============================] - 2s 28ms/step - loss: 0.2682 - val_loss: 0.3453\n",
      "Epoch 215/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.2428 - val_loss: 0.3397\n",
      "Epoch 216/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.2314 - val_loss: 0.3182\n",
      "Epoch 217/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.2214 - val_loss: 0.3140\n",
      "Epoch 218/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.2190 - val_loss: 0.3130\n",
      "Epoch 219/1000\n",
      "61/61 [==============================] - 2s 28ms/step - loss: 0.2160 - val_loss: 0.3142\n",
      "Epoch 220/1000\n",
      "61/61 [==============================] - 2s 28ms/step - loss: 0.2106 - val_loss: 0.3076\n",
      "Epoch 221/1000\n",
      "61/61 [==============================] - 2s 28ms/step - loss: 0.2104 - val_loss: 0.3029\n",
      "Epoch 222/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.2108 - val_loss: 0.2988\n",
      "Epoch 223/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.2058 - val_loss: 0.2981\n",
      "Epoch 224/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.2052 - val_loss: 0.2963\n",
      "Epoch 225/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.2043 - val_loss: 0.2930\n",
      "Epoch 226/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.2052 - val_loss: 0.2917\n",
      "Epoch 227/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.2068 - val_loss: 0.3059\n",
      "Epoch 228/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.2041 - val_loss: 0.2911\n",
      "Epoch 229/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.2030 - val_loss: 0.2861\n",
      "Epoch 230/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.2001 - val_loss: 0.2808\n",
      "Epoch 231/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.2005 - val_loss: 0.2834\n",
      "Epoch 232/1000\n",
      "61/61 [==============================] - 2s 28ms/step - loss: 0.1994 - val_loss: 0.2811\n",
      "Epoch 233/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.1981 - val_loss: 0.2800\n",
      "Epoch 234/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.1965 - val_loss: 0.2747\n",
      "Epoch 235/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.1978 - val_loss: 0.2745\n",
      "Epoch 236/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.1980 - val_loss: 0.2748\n",
      "Epoch 237/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.1959 - val_loss: 0.2700\n",
      "Epoch 238/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.1962 - val_loss: 0.2837\n",
      "Epoch 239/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.1970 - val_loss: 0.2814\n",
      "Epoch 240/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.1966 - val_loss: 0.2721\n",
      "Epoch 241/1000\n",
      "61/61 [==============================] - ETA: 0s - loss: 0.1971Restoring model weights from the end of the best epoch: 206.\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.1971 - val_loss: 0.2727\n",
      "Epoch 241: early stopping\n",
      "7/7 [==============================] - 1s 10ms/step\n",
      "0.21662747142751265\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "516b0c46e87e4155acb70fd3c2043301",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.038 MB of 0.038 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch/epoch</td><td>▁▁▁▁▁▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▅▅▅▆▆▆▆▆▇▇▇███</td></tr><tr><td>epoch/learning_rate</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>epoch/loss</td><td>█▇▄▄▄▃▃▃▃▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▃▁▁▁</td></tr><tr><td>epoch/val_loss</td><td>█▄▅▄▃▃▄▃▃▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▂▁▁</td></tr><tr><td>rmase_prediction</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch/epoch</td><td>240</td></tr><tr><td>epoch/learning_rate</td><td>0.00049</td></tr><tr><td>epoch/loss</td><td>0.1971</td></tr><tr><td>epoch/val_loss</td><td>0.27272</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">test_1</strong> at: <a href='https://wandb.ai/uu13234-none/sgnate_skate-keras/runs/jq65ie6v' target=\"_blank\">https://wandb.ai/uu13234-none/sgnate_skate-keras/runs/jq65ie6v</a><br/> View project at: <a href='https://wandb.ai/uu13234-none/sgnate_skate-keras' target=\"_blank\">https://wandb.ai/uu13234-none/sgnate_skate-keras</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20241104_141605-jq65ie6v\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.18.3"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\sato\\Desktop\\python\\SIGNATE\\スケートボードの挙動予測\\code-analysis\\wandb\\run-20241104_142329-4cqjzdom</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/uu13234-none/sgnate_skate-keras/runs/4cqjzdom' target=\"_blank\">test_2</a></strong> to <a href='https://wandb.ai/uu13234-none/sgnate_skate-keras' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/uu13234-none/sgnate_skate-keras' target=\"_blank\">https://wandb.ai/uu13234-none/sgnate_skate-keras</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/uu13234-none/sgnate_skate-keras/runs/4cqjzdom' target=\"_blank\">https://wandb.ai/uu13234-none/sgnate_skate-keras/runs/4cqjzdom</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      " 6/61 [=>............................] - ETA: 1s - loss: 2.2839WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0254s vs `on_train_batch_end` time: 0.0364s). Check your callbacks.\n",
      "61/61 [==============================] - 9s 50ms/step - loss: 1.5030 - val_loss: 1.3093\n",
      "Epoch 2/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 1.0568 - val_loss: 1.1511\n",
      "Epoch 3/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.9071 - val_loss: 0.9367\n",
      "Epoch 4/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.8312 - val_loss: 0.8500\n",
      "Epoch 5/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.7719 - val_loss: 0.8069\n",
      "Epoch 6/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.7324 - val_loss: 0.6928\n",
      "Epoch 7/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.6806 - val_loss: 0.7490\n",
      "Epoch 8/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.7011 - val_loss: 0.7116\n",
      "Epoch 9/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.6721 - val_loss: 0.7140\n",
      "Epoch 10/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.6514 - val_loss: 0.6944\n",
      "Epoch 11/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.6216 - val_loss: 0.6563\n",
      "Epoch 12/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.5703 - val_loss: 0.5853\n",
      "Epoch 13/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.5442 - val_loss: 0.6186\n",
      "Epoch 14/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.5287 - val_loss: 0.6012\n",
      "Epoch 15/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.5372 - val_loss: 0.5694\n",
      "Epoch 16/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.5211 - val_loss: 0.5729\n",
      "Epoch 17/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.4883 - val_loss: 0.5652\n",
      "Epoch 18/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.4721 - val_loss: 0.5916\n",
      "Epoch 19/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.5057 - val_loss: 0.6116\n",
      "Epoch 20/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.5782 - val_loss: 0.6186\n",
      "Epoch 21/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.5275 - val_loss: 0.5655\n",
      "Epoch 22/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.4908 - val_loss: 0.5532\n",
      "Epoch 23/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.5314 - val_loss: 0.6247\n",
      "Epoch 24/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.4687 - val_loss: 0.5027\n",
      "Epoch 25/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.4549 - val_loss: 0.5138\n",
      "Epoch 26/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.4272 - val_loss: 0.5503\n",
      "Epoch 27/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.4158 - val_loss: 0.5315\n",
      "Epoch 28/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.4062 - val_loss: 0.4929\n",
      "Epoch 29/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.3908 - val_loss: 0.5101\n",
      "Epoch 30/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.3931 - val_loss: 0.5262\n",
      "Epoch 31/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.3850 - val_loss: 0.5153\n",
      "Epoch 32/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.3796 - val_loss: 0.4906\n",
      "Epoch 33/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.3758 - val_loss: 0.5096\n",
      "Epoch 34/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.3602 - val_loss: 0.5418\n",
      "Epoch 35/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.3580 - val_loss: 0.4799\n",
      "Epoch 36/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.3535 - val_loss: 0.4832\n",
      "Epoch 37/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.3581 - val_loss: 0.4804\n",
      "Epoch 38/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.3502 - val_loss: 0.4571\n",
      "Epoch 39/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.3400 - val_loss: 0.4921\n",
      "Epoch 40/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.3549 - val_loss: 0.4905\n",
      "Epoch 41/1000\n",
      "61/61 [==============================] - 2s 31ms/step - loss: 0.3604 - val_loss: 0.4857\n",
      "Epoch 42/1000\n",
      "61/61 [==============================] - 2s 31ms/step - loss: 0.3478 - val_loss: 0.5186\n",
      "Epoch 43/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.3523 - val_loss: 0.4947\n",
      "Epoch 44/1000\n",
      "61/61 [==============================] - 2s 31ms/step - loss: 0.3249 - val_loss: 0.4628\n",
      "Epoch 45/1000\n",
      "61/61 [==============================] - 2s 31ms/step - loss: 0.3285 - val_loss: 0.4506\n",
      "Epoch 46/1000\n",
      "61/61 [==============================] - 2s 31ms/step - loss: 0.3373 - val_loss: 0.4294\n",
      "Epoch 47/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.3792 - val_loss: 0.4800\n",
      "Epoch 48/1000\n",
      "61/61 [==============================] - 2s 31ms/step - loss: 0.3499 - val_loss: 0.4682\n",
      "Epoch 49/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.3232 - val_loss: 0.4671\n",
      "Epoch 50/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.3185 - val_loss: 0.4279\n",
      "Epoch 51/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.3071 - val_loss: 0.4362\n",
      "Epoch 52/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.3410 - val_loss: 0.4410\n",
      "Epoch 53/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.3101 - val_loss: 0.4313\n",
      "Epoch 54/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.3016 - val_loss: 0.4146\n",
      "Epoch 55/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.2925 - val_loss: 0.4214\n",
      "Epoch 56/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.2926 - val_loss: 0.4369\n",
      "Epoch 57/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.2924 - val_loss: 0.4106\n",
      "Epoch 58/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.2918 - val_loss: 0.4278\n",
      "Epoch 59/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.2868 - val_loss: 0.4083\n",
      "Epoch 60/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.2816 - val_loss: 0.4285\n",
      "Epoch 61/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.3587 - val_loss: 0.4961\n",
      "Epoch 62/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.3273 - val_loss: 0.4475\n",
      "Epoch 63/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.2977 - val_loss: 0.4434\n",
      "Epoch 64/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.2862 - val_loss: 0.4007\n",
      "Epoch 65/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.2763 - val_loss: 0.4134\n",
      "Epoch 66/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.2749 - val_loss: 0.4011\n",
      "Epoch 67/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.3193 - val_loss: 0.4129\n",
      "Epoch 68/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.2942 - val_loss: 0.5646\n",
      "Epoch 69/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.3072 - val_loss: 0.3935\n",
      "Epoch 70/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.2814 - val_loss: 0.4357\n",
      "Epoch 71/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.2750 - val_loss: 0.3785\n",
      "Epoch 72/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.2704 - val_loss: 0.3892\n",
      "Epoch 73/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.2710 - val_loss: 0.3725\n",
      "Epoch 74/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.2684 - val_loss: 0.3725\n",
      "Epoch 75/1000\n",
      "61/61 [==============================] - 2s 28ms/step - loss: 0.2673 - val_loss: 0.3638\n",
      "Epoch 76/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.2620 - val_loss: 0.3756\n",
      "Epoch 77/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.2634 - val_loss: 0.3703\n",
      "Epoch 78/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.2604 - val_loss: 0.3633\n",
      "Epoch 79/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.2554 - val_loss: 0.3596\n",
      "Epoch 80/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.2555 - val_loss: 0.3620\n",
      "Epoch 81/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.2539 - val_loss: 0.3679\n",
      "Epoch 82/1000\n",
      "61/61 [==============================] - 2s 31ms/step - loss: 0.2549 - val_loss: 0.3573\n",
      "Epoch 83/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.2500 - val_loss: 0.3635\n",
      "Epoch 84/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.2504 - val_loss: 0.3629\n",
      "Epoch 85/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.2590 - val_loss: 0.3923\n",
      "Epoch 86/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.2578 - val_loss: 0.3756\n",
      "Epoch 87/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.2503 - val_loss: 0.3555\n",
      "Epoch 88/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.2535 - val_loss: 0.3435\n",
      "Epoch 89/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.2496 - val_loss: 0.3313\n",
      "Epoch 90/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.2472 - val_loss: 0.3393\n",
      "Epoch 91/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.2468 - val_loss: 0.3542\n",
      "Epoch 92/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.2463 - val_loss: 0.3467\n",
      "Epoch 93/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.2439 - val_loss: 0.3412\n",
      "Epoch 94/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.2446 - val_loss: 0.3424\n",
      "Epoch 95/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.2433 - val_loss: 0.3420\n",
      "Epoch 96/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.2401 - val_loss: 0.3400\n",
      "Epoch 97/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.2363 - val_loss: 0.3328\n",
      "Epoch 98/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.2403 - val_loss: 0.3332\n",
      "Epoch 99/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.2393 - val_loss: 0.3342\n",
      "Epoch 100/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.2430 - val_loss: 0.3530\n",
      "Epoch 101/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.2424 - val_loss: 0.3297\n",
      "Epoch 102/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.2372 - val_loss: 0.3291\n",
      "Epoch 103/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.2378 - val_loss: 0.3295\n",
      "Epoch 104/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.2375 - val_loss: 0.3261\n",
      "Epoch 105/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.2341 - val_loss: 0.3298\n",
      "Epoch 106/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.2317 - val_loss: 0.3421\n",
      "Epoch 107/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.2321 - val_loss: 0.3383\n",
      "Epoch 108/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.2350 - val_loss: 0.3289\n",
      "Epoch 109/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.2352 - val_loss: 0.3184\n",
      "Epoch 110/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.2453 - val_loss: 0.5943\n",
      "Epoch 111/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.3956 - val_loss: 0.5167\n",
      "Epoch 112/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.3589 - val_loss: 0.4915\n",
      "Epoch 113/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.3151 - val_loss: 0.4985\n",
      "Epoch 114/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.2952 - val_loss: 0.3961\n",
      "Epoch 115/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.3145 - val_loss: 0.4399\n",
      "Epoch 116/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.2966 - val_loss: 0.3816\n",
      "Epoch 117/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.2626 - val_loss: 0.3575\n",
      "Epoch 118/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.2615 - val_loss: 0.3782\n",
      "Epoch 119/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.2515 - val_loss: 0.3410\n",
      "Epoch 120/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.2432 - val_loss: 0.3413\n",
      "Epoch 121/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.2393 - val_loss: 0.3242\n",
      "Epoch 122/1000\n",
      "61/61 [==============================] - 2s 28ms/step - loss: 0.2322 - val_loss: 0.3228\n",
      "Epoch 123/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.2313 - val_loss: 0.3213\n",
      "Epoch 124/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.2306 - val_loss: 0.3187\n",
      "Epoch 125/1000\n",
      "61/61 [==============================] - 2s 28ms/step - loss: 0.2290 - val_loss: 0.3181\n",
      "Epoch 126/1000\n",
      "61/61 [==============================] - 2s 28ms/step - loss: 0.2262 - val_loss: 0.3064\n",
      "Epoch 127/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.2253 - val_loss: 0.3058\n",
      "Epoch 128/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.2240 - val_loss: 0.3159\n",
      "Epoch 129/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.2230 - val_loss: 0.2984\n",
      "Epoch 130/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.2224 - val_loss: 0.3043\n",
      "Epoch 131/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.2209 - val_loss: 0.2996\n",
      "Epoch 132/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.2235 - val_loss: 0.3123\n",
      "Epoch 133/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.2207 - val_loss: 0.2983\n",
      "Epoch 134/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.2195 - val_loss: 0.2983\n",
      "Epoch 135/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.2223 - val_loss: 0.2947\n",
      "Epoch 136/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.2205 - val_loss: 0.2969\n",
      "Epoch 137/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.2193 - val_loss: 0.2993\n",
      "Epoch 138/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.2195 - val_loss: 0.3097\n",
      "Epoch 139/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.2227 - val_loss: 0.3086\n",
      "Epoch 140/1000\n",
      "61/61 [==============================] - 2s 38ms/step - loss: 0.2185 - val_loss: 0.2965\n",
      "Epoch 141/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.2183 - val_loss: 0.2947\n",
      "Epoch 142/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.2185 - val_loss: 0.3041\n",
      "Epoch 143/1000\n",
      "61/61 [==============================] - 2s 28ms/step - loss: 0.2210 - val_loss: 0.3005\n",
      "Epoch 144/1000\n",
      "61/61 [==============================] - 2s 28ms/step - loss: 0.2184 - val_loss: 0.2903\n",
      "Epoch 145/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.2168 - val_loss: 0.2900\n",
      "Epoch 146/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.2140 - val_loss: 0.2930\n",
      "Epoch 147/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.2156 - val_loss: 0.2875\n",
      "Epoch 148/1000\n",
      "61/61 [==============================] - 2s 31ms/step - loss: 0.2132 - val_loss: 0.2890\n",
      "Epoch 149/1000\n",
      "61/61 [==============================] - 2s 31ms/step - loss: 0.2165 - val_loss: 0.2859\n",
      "Epoch 150/1000\n",
      "61/61 [==============================] - 2s 31ms/step - loss: 0.2148 - val_loss: 0.2923\n",
      "Epoch 151/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.2136 - val_loss: 0.2805\n",
      "Epoch 152/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.2140 - val_loss: 0.2883\n",
      "Epoch 153/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.2134 - val_loss: 0.2767\n",
      "Epoch 154/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.2122 - val_loss: 0.2900\n",
      "Epoch 155/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.2121 - val_loss: 0.2801\n",
      "Epoch 156/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.2131 - val_loss: 0.2912\n",
      "Epoch 157/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.2124 - val_loss: 0.2911\n",
      "Epoch 158/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.2114 - val_loss: 0.2863\n",
      "Epoch 159/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.2142 - val_loss: 0.2833\n",
      "Epoch 160/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.2119 - val_loss: 0.2870\n",
      "Epoch 161/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.2125 - val_loss: 0.2735\n",
      "Epoch 162/1000\n",
      "61/61 [==============================] - 2s 33ms/step - loss: 0.2109 - val_loss: 0.2851\n",
      "Epoch 163/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.2099 - val_loss: 0.2963\n",
      "Epoch 164/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.2102 - val_loss: 0.2784\n",
      "Epoch 165/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.2106 - val_loss: 0.2799\n",
      "Epoch 166/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.2098 - val_loss: 0.2807\n",
      "Epoch 167/1000\n",
      "61/61 [==============================] - 2s 32ms/step - loss: 0.2091 - val_loss: 0.2865\n",
      "Epoch 168/1000\n",
      "61/61 [==============================] - 2s 31ms/step - loss: 0.2098 - val_loss: 0.2845\n",
      "Epoch 169/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.2091 - val_loss: 0.3045\n",
      "Epoch 170/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.2089 - val_loss: 0.2857\n",
      "Epoch 171/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.2098 - val_loss: 0.2741\n",
      "Epoch 172/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.2077 - val_loss: 0.2797\n",
      "Epoch 173/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.2091 - val_loss: 0.2811\n",
      "Epoch 174/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.2083 - val_loss: 0.2813\n",
      "Epoch 175/1000\n",
      "61/61 [==============================] - 2s 31ms/step - loss: 0.2076 - val_loss: 0.2886\n",
      "Epoch 176/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.2070 - val_loss: 0.2749\n",
      "Epoch 177/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.2076 - val_loss: 0.2758\n",
      "Epoch 178/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.2068 - val_loss: 0.2722\n",
      "Epoch 179/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.2077 - val_loss: 0.2796\n",
      "Epoch 180/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.2075 - val_loss: 0.2665\n",
      "Epoch 181/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.2052 - val_loss: 0.2762\n",
      "Epoch 182/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.2047 - val_loss: 0.2815\n",
      "Epoch 183/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.2050 - val_loss: 0.2869\n",
      "Epoch 184/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.2067 - val_loss: 0.2732\n",
      "Epoch 185/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.2054 - val_loss: 0.2761\n",
      "Epoch 186/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.2046 - val_loss: 0.2705\n",
      "Epoch 187/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.2039 - val_loss: 0.2723\n",
      "Epoch 188/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.2038 - val_loss: 0.2667\n",
      "Epoch 189/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.2033 - val_loss: 0.2619\n",
      "Epoch 190/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.2035 - val_loss: 0.2702\n",
      "Epoch 191/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.2047 - val_loss: 0.2705\n",
      "Epoch 192/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.2039 - val_loss: 0.2668\n",
      "Epoch 193/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.2039 - val_loss: 0.2656\n",
      "Epoch 194/1000\n",
      "61/61 [==============================] - 2s 31ms/step - loss: 0.2037 - val_loss: 0.2767\n",
      "Epoch 195/1000\n",
      "61/61 [==============================] - 2s 31ms/step - loss: 0.2047 - val_loss: 0.2685\n",
      "Epoch 196/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.2054 - val_loss: 0.2730\n",
      "Epoch 197/1000\n",
      "61/61 [==============================] - 2s 31ms/step - loss: 0.2048 - val_loss: 0.2822\n",
      "Epoch 198/1000\n",
      "61/61 [==============================] - 2s 31ms/step - loss: 0.2033 - val_loss: 0.2779\n",
      "Epoch 199/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.2018 - val_loss: 0.2749\n",
      "Epoch 200/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.2017 - val_loss: 0.2892\n",
      "Epoch 201/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.1989 - val_loss: 0.2902\n",
      "Epoch 202/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.2004 - val_loss: 0.2800\n",
      "Epoch 203/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.1971 - val_loss: 0.2731\n",
      "Epoch 204/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.2147 - val_loss: 0.4382\n",
      "Epoch 205/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.2398 - val_loss: 0.3179\n",
      "Epoch 206/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.2153 - val_loss: 0.2761\n",
      "Epoch 207/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.2047 - val_loss: 0.2793\n",
      "Epoch 208/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.2021 - val_loss: 0.2887\n",
      "Epoch 209/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.2292 - val_loss: 0.3110\n",
      "Epoch 210/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.2428 - val_loss: 0.3660\n",
      "Epoch 211/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.2884 - val_loss: 0.3708\n",
      "Epoch 212/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.2288 - val_loss: 0.3098\n",
      "Epoch 213/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.2107 - val_loss: 0.2936\n",
      "Epoch 214/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.2067 - val_loss: 0.2776\n",
      "Epoch 215/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.2045 - val_loss: 0.2772\n",
      "Epoch 216/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.1998 - val_loss: 0.2808\n",
      "Epoch 217/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.2005 - val_loss: 0.2653\n",
      "Epoch 218/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.2005 - val_loss: 0.2632\n",
      "Epoch 219/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.1982 - val_loss: 0.2765\n",
      "Epoch 220/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.1959 - val_loss: 0.2642\n",
      "Epoch 221/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.1976 - val_loss: 0.2772\n",
      "Epoch 222/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.2046 - val_loss: 0.2670\n",
      "Epoch 223/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.1992 - val_loss: 0.2936\n",
      "Epoch 224/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.1960 - val_loss: 0.2560\n",
      "Epoch 225/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.1949 - val_loss: 0.2560\n",
      "Epoch 226/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.1942 - val_loss: 0.2534\n",
      "Epoch 227/1000\n",
      "61/61 [==============================] - 2s 31ms/step - loss: 0.1930 - val_loss: 0.2567\n",
      "Epoch 228/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.1931 - val_loss: 0.2567\n",
      "Epoch 229/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.1950 - val_loss: 0.2565\n",
      "Epoch 230/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.1941 - val_loss: 0.2528\n",
      "Epoch 231/1000\n",
      "61/61 [==============================] - 2s 31ms/step - loss: 0.1953 - val_loss: 0.2624\n",
      "Epoch 232/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.1940 - val_loss: 0.2505\n",
      "Epoch 233/1000\n",
      "61/61 [==============================] - 2s 31ms/step - loss: 0.1932 - val_loss: 0.2561\n",
      "Epoch 234/1000\n",
      "61/61 [==============================] - 2s 31ms/step - loss: 0.1919 - val_loss: 0.2478\n",
      "Epoch 235/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.1933 - val_loss: 0.2511\n",
      "Epoch 236/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.1939 - val_loss: 0.2589\n",
      "Epoch 237/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.1926 - val_loss: 0.2569\n",
      "Epoch 238/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.1918 - val_loss: 0.2547\n",
      "Epoch 239/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.1927 - val_loss: 0.2519\n",
      "Epoch 240/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.1929 - val_loss: 0.2498\n",
      "Epoch 241/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.1929 - val_loss: 0.2507\n",
      "Epoch 242/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.1920 - val_loss: 0.2673\n",
      "Epoch 243/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.1931 - val_loss: 0.2490\n",
      "Epoch 244/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.1925 - val_loss: 0.2514\n",
      "Epoch 245/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.1910 - val_loss: 0.2520\n",
      "Epoch 246/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.1918 - val_loss: 0.2536\n",
      "Epoch 247/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.1908 - val_loss: 0.2448\n",
      "Epoch 248/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.1913 - val_loss: 0.2517\n",
      "Epoch 249/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.1904 - val_loss: 0.2610\n",
      "Epoch 250/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.1904 - val_loss: 0.2509\n",
      "Epoch 251/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.1894 - val_loss: 0.2468\n",
      "Epoch 252/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.1905 - val_loss: 0.2519\n",
      "Epoch 253/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.1903 - val_loss: 0.2518\n",
      "Epoch 254/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.1895 - val_loss: 0.2478\n",
      "Epoch 255/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.1894 - val_loss: 0.2455\n",
      "Epoch 256/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.1878 - val_loss: 0.2475\n",
      "Epoch 257/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.1898 - val_loss: 0.2483\n",
      "Epoch 258/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.1891 - val_loss: 0.2429\n",
      "Epoch 259/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.1905 - val_loss: 0.2473\n",
      "Epoch 260/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.1905 - val_loss: 0.2437\n",
      "Epoch 261/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.1886 - val_loss: 0.2484\n",
      "Epoch 262/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.1887 - val_loss: 0.2583\n",
      "Epoch 263/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.1897 - val_loss: 0.2521\n",
      "Epoch 264/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.1895 - val_loss: 0.2459\n",
      "Epoch 265/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.1890 - val_loss: 0.2519\n",
      "Epoch 266/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.1887 - val_loss: 0.2462\n",
      "Epoch 267/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.1871 - val_loss: 0.2396\n",
      "Epoch 268/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.1883 - val_loss: 0.2472\n",
      "Epoch 269/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.1879 - val_loss: 0.2583\n",
      "Epoch 270/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.1881 - val_loss: 0.2480\n",
      "Epoch 271/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.1899 - val_loss: 0.2482\n",
      "Epoch 272/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.1877 - val_loss: 0.2567\n",
      "Epoch 273/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.1891 - val_loss: 0.2526\n",
      "Epoch 274/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.1891 - val_loss: 0.2695\n",
      "Epoch 275/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.1883 - val_loss: 0.2582\n",
      "Epoch 276/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.1887 - val_loss: 0.2692\n",
      "Epoch 277/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.1878 - val_loss: 0.2537\n",
      "Epoch 278/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.1858 - val_loss: 0.2464\n",
      "Epoch 279/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.1869 - val_loss: 0.2472\n",
      "Epoch 280/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.1856 - val_loss: 0.2506\n",
      "Epoch 281/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.1862 - val_loss: 0.2481\n",
      "Epoch 282/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.1874 - val_loss: 0.2513\n",
      "Epoch 283/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.1859 - val_loss: 0.2503\n",
      "Epoch 284/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.1864 - val_loss: 0.2480\n",
      "Epoch 285/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.1864 - val_loss: 0.2592\n",
      "Epoch 286/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.1851 - val_loss: 0.2426\n",
      "Epoch 287/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.1852 - val_loss: 0.2450\n",
      "Epoch 288/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.1860 - val_loss: 0.2491\n",
      "Epoch 289/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.1853 - val_loss: 0.2483\n",
      "Epoch 290/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.1856 - val_loss: 0.2488\n",
      "Epoch 291/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.1852 - val_loss: 0.2454\n",
      "Epoch 292/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.1847 - val_loss: 0.2533\n",
      "Epoch 293/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.1859 - val_loss: 0.2451\n",
      "Epoch 294/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.1873 - val_loss: 0.2498\n",
      "Epoch 295/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.1840 - val_loss: 0.2501\n",
      "Epoch 296/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.1844 - val_loss: 0.2484\n",
      "Epoch 297/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.1847 - val_loss: 0.2540\n",
      "Epoch 298/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.1841 - val_loss: 0.2463\n",
      "Epoch 299/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.1842 - val_loss: 0.2479\n",
      "Epoch 300/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.1849 - val_loss: 0.2493\n",
      "Epoch 301/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.1829 - val_loss: 0.2571\n",
      "Epoch 302/1000\n",
      "61/61 [==============================] - ETA: 0s - loss: 0.1827Restoring model weights from the end of the best epoch: 267.\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.1827 - val_loss: 0.2445\n",
      "Epoch 302: early stopping\n",
      "7/7 [==============================] - 1s 10ms/step\n",
      "0.23538297069928937\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f5c022bfb8464cf4ae7f6f1a736756b9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.046 MB of 0.046 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch/epoch</td><td>▁▁▁▂▂▂▂▂▂▂▂▃▃▃▄▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇████</td></tr><tr><td>epoch/learning_rate</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>epoch/loss</td><td>██▆▆▆▄▄▃▃▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>epoch/val_loss</td><td>█▆▆▆▅▅▅▄▄▃▃▃▆▄▄▃▂▂▂▂▂▂▂▂▁▂▁▂▂▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>rmase_prediction</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch/epoch</td><td>301</td></tr><tr><td>epoch/learning_rate</td><td>0.00049</td></tr><tr><td>epoch/loss</td><td>0.18272</td></tr><tr><td>epoch/val_loss</td><td>0.2445</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">test_2</strong> at: <a href='https://wandb.ai/uu13234-none/sgnate_skate-keras/runs/4cqjzdom' target=\"_blank\">https://wandb.ai/uu13234-none/sgnate_skate-keras/runs/4cqjzdom</a><br/> View project at: <a href='https://wandb.ai/uu13234-none/sgnate_skate-keras' target=\"_blank\">https://wandb.ai/uu13234-none/sgnate_skate-keras</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20241104_142329-4cqjzdom\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.18.3"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\sato\\Desktop\\python\\SIGNATE\\スケートボードの挙動予測\\code-analysis\\wandb\\run-20241104_143248-wnklco54</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/uu13234-none/sgnate_skate-keras/runs/wnklco54' target=\"_blank\">test_3</a></strong> to <a href='https://wandb.ai/uu13234-none/sgnate_skate-keras' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/uu13234-none/sgnate_skate-keras' target=\"_blank\">https://wandb.ai/uu13234-none/sgnate_skate-keras</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/uu13234-none/sgnate_skate-keras/runs/wnklco54' target=\"_blank\">https://wandb.ai/uu13234-none/sgnate_skate-keras/runs/wnklco54</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      " 5/61 [=>............................] - ETA: 3s - loss: 2.3166WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0355s vs `on_train_batch_end` time: 0.0366s). Check your callbacks.\n",
      "61/61 [==============================] - 9s 52ms/step - loss: 1.5131 - val_loss: 1.4061\n",
      "Epoch 2/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 1.0479 - val_loss: 1.0407\n",
      "Epoch 3/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.9097 - val_loss: 0.9155\n",
      "Epoch 4/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.8359 - val_loss: 0.7981\n",
      "Epoch 5/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.7726 - val_loss: 0.7498\n",
      "Epoch 6/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.7625 - val_loss: 0.7403\n",
      "Epoch 7/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.7273 - val_loss: 0.6997\n",
      "Epoch 8/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.6729 - val_loss: 0.6491\n",
      "Epoch 9/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.6479 - val_loss: 0.6656\n",
      "Epoch 10/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.6168 - val_loss: 0.6099\n",
      "Epoch 11/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.5998 - val_loss: 0.6134\n",
      "Epoch 12/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.5910 - val_loss: 0.6256\n",
      "Epoch 13/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.5726 - val_loss: 0.5766\n",
      "Epoch 14/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.5789 - val_loss: 0.5901\n",
      "Epoch 15/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.5344 - val_loss: 0.5417\n",
      "Epoch 16/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.4938 - val_loss: 0.5314\n",
      "Epoch 17/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.4833 - val_loss: 0.5510\n",
      "Epoch 18/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.5119 - val_loss: 0.5632\n",
      "Epoch 19/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.4853 - val_loss: 0.5809\n",
      "Epoch 20/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.4688 - val_loss: 0.5954\n",
      "Epoch 21/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.5176 - val_loss: 0.5476\n",
      "Epoch 22/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.4758 - val_loss: 0.5529\n",
      "Epoch 23/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.4429 - val_loss: 0.5228\n",
      "Epoch 24/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.4430 - val_loss: 0.5684\n",
      "Epoch 25/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.4489 - val_loss: 0.5358\n",
      "Epoch 26/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.5103 - val_loss: 0.6190\n",
      "Epoch 27/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.5008 - val_loss: 0.5542\n",
      "Epoch 28/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.4253 - val_loss: 0.5212\n",
      "Epoch 29/1000\n",
      "61/61 [==============================] - 2s 28ms/step - loss: 0.4268 - val_loss: 0.6059\n",
      "Epoch 30/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.4421 - val_loss: 0.5216\n",
      "Epoch 31/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.3989 - val_loss: 0.4861\n",
      "Epoch 32/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.3943 - val_loss: 0.4873\n",
      "Epoch 33/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.3857 - val_loss: 0.4520\n",
      "Epoch 34/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.3622 - val_loss: 0.4470\n",
      "Epoch 35/1000\n",
      "61/61 [==============================] - 2s 31ms/step - loss: 0.3539 - val_loss: 0.4714\n",
      "Epoch 36/1000\n",
      "61/61 [==============================] - 2s 31ms/step - loss: 0.3493 - val_loss: 0.4474\n",
      "Epoch 37/1000\n",
      "61/61 [==============================] - 2s 31ms/step - loss: 0.3476 - val_loss: 0.4576\n",
      "Epoch 38/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.3371 - val_loss: 0.4354\n",
      "Epoch 39/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.3355 - val_loss: 0.4336\n",
      "Epoch 40/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.3343 - val_loss: 0.4252\n",
      "Epoch 41/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.3274 - val_loss: 0.4122\n",
      "Epoch 42/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.3286 - val_loss: 0.4172\n",
      "Epoch 43/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.3193 - val_loss: 0.4021\n",
      "Epoch 44/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.3133 - val_loss: 0.4145\n",
      "Epoch 45/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.3139 - val_loss: 0.3978\n",
      "Epoch 46/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.3085 - val_loss: 0.4138\n",
      "Epoch 47/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.4942 - val_loss: 0.5430\n",
      "Epoch 48/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.4120 - val_loss: 0.5074\n",
      "Epoch 49/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.3653 - val_loss: 0.4521\n",
      "Epoch 50/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.3538 - val_loss: 0.4524\n",
      "Epoch 51/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.3319 - val_loss: 0.4044\n",
      "Epoch 52/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.3261 - val_loss: 0.4083\n",
      "Epoch 53/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.3257 - val_loss: 0.4515\n",
      "Epoch 54/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.3072 - val_loss: 0.4392\n",
      "Epoch 55/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.2982 - val_loss: 0.4240\n",
      "Epoch 56/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.2963 - val_loss: 0.4074\n",
      "Epoch 57/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.2864 - val_loss: 0.3850\n",
      "Epoch 58/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.2905 - val_loss: 0.3816\n",
      "Epoch 59/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.2856 - val_loss: 0.4061\n",
      "Epoch 60/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.2804 - val_loss: 0.3707\n",
      "Epoch 61/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.2792 - val_loss: 0.3793\n",
      "Epoch 62/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.2770 - val_loss: 0.3907\n",
      "Epoch 63/1000\n",
      "61/61 [==============================] - 2s 31ms/step - loss: 0.2790 - val_loss: 0.3914\n",
      "Epoch 64/1000\n",
      "61/61 [==============================] - 2s 31ms/step - loss: 0.2751 - val_loss: 0.3626\n",
      "Epoch 65/1000\n",
      "61/61 [==============================] - 2s 31ms/step - loss: 0.2744 - val_loss: 0.3848\n",
      "Epoch 66/1000\n",
      "61/61 [==============================] - 2s 36ms/step - loss: 0.2764 - val_loss: 0.4013\n",
      "Epoch 67/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.2735 - val_loss: 0.3958\n",
      "Epoch 68/1000\n",
      "61/61 [==============================] - 2s 27ms/step - loss: 0.2752 - val_loss: 0.3694\n",
      "Epoch 69/1000\n",
      "61/61 [==============================] - 2s 28ms/step - loss: 0.2702 - val_loss: 0.3562\n",
      "Epoch 70/1000\n",
      "61/61 [==============================] - 2s 27ms/step - loss: 0.2672 - val_loss: 0.3716\n",
      "Epoch 71/1000\n",
      "61/61 [==============================] - 2s 28ms/step - loss: 0.2686 - val_loss: 0.3701\n",
      "Epoch 72/1000\n",
      "61/61 [==============================] - 2s 27ms/step - loss: 0.2744 - val_loss: 0.3752\n",
      "Epoch 73/1000\n",
      "61/61 [==============================] - 2s 27ms/step - loss: 0.3024 - val_loss: 0.3622\n",
      "Epoch 74/1000\n",
      "61/61 [==============================] - 2s 28ms/step - loss: 0.2792 - val_loss: 0.3530\n",
      "Epoch 75/1000\n",
      "61/61 [==============================] - 2s 28ms/step - loss: 0.2668 - val_loss: 0.3583\n",
      "Epoch 76/1000\n",
      "61/61 [==============================] - 2s 27ms/step - loss: 0.2662 - val_loss: 0.3563\n",
      "Epoch 77/1000\n",
      "61/61 [==============================] - 2s 28ms/step - loss: 0.2612 - val_loss: 0.3636\n",
      "Epoch 78/1000\n",
      "61/61 [==============================] - 2s 28ms/step - loss: 0.2608 - val_loss: 0.3533\n",
      "Epoch 79/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.2585 - val_loss: 0.3515\n",
      "Epoch 80/1000\n",
      "61/61 [==============================] - 2s 28ms/step - loss: 0.2558 - val_loss: 0.3590\n",
      "Epoch 81/1000\n",
      "61/61 [==============================] - 2s 27ms/step - loss: 0.2597 - val_loss: 0.3756\n",
      "Epoch 82/1000\n",
      "61/61 [==============================] - 2s 27ms/step - loss: 0.3379 - val_loss: 0.4525\n",
      "Epoch 83/1000\n",
      "61/61 [==============================] - 2s 27ms/step - loss: 0.3025 - val_loss: 0.3895\n",
      "Epoch 84/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.2782 - val_loss: 0.3588\n",
      "Epoch 85/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.2597 - val_loss: 0.3404\n",
      "Epoch 86/1000\n",
      "61/61 [==============================] - 2s 32ms/step - loss: 0.2584 - val_loss: 0.3349\n",
      "Epoch 87/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.2523 - val_loss: 0.3289\n",
      "Epoch 88/1000\n",
      "61/61 [==============================] - 2s 33ms/step - loss: 0.2490 - val_loss: 0.3215\n",
      "Epoch 89/1000\n",
      "61/61 [==============================] - 2s 31ms/step - loss: 0.2475 - val_loss: 0.3293\n",
      "Epoch 90/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.2498 - val_loss: 0.3311\n",
      "Epoch 91/1000\n",
      "61/61 [==============================] - 2s 28ms/step - loss: 0.2485 - val_loss: 0.3443\n",
      "Epoch 92/1000\n",
      "61/61 [==============================] - 2s 28ms/step - loss: 0.2470 - val_loss: 0.3341\n",
      "Epoch 93/1000\n",
      "61/61 [==============================] - 2s 28ms/step - loss: 0.2469 - val_loss: 0.3254\n",
      "Epoch 94/1000\n",
      "61/61 [==============================] - 2s 27ms/step - loss: 0.2450 - val_loss: 0.3143\n",
      "Epoch 95/1000\n",
      "61/61 [==============================] - 2s 28ms/step - loss: 0.2427 - val_loss: 0.3177\n",
      "Epoch 96/1000\n",
      "61/61 [==============================] - 2s 28ms/step - loss: 0.2415 - val_loss: 0.3182\n",
      "Epoch 97/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.2415 - val_loss: 0.3221\n",
      "Epoch 98/1000\n",
      "61/61 [==============================] - 2s 28ms/step - loss: 0.2402 - val_loss: 0.3299\n",
      "Epoch 99/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.2395 - val_loss: 0.3236\n",
      "Epoch 100/1000\n",
      "61/61 [==============================] - 2s 28ms/step - loss: 0.2379 - val_loss: 0.3078\n",
      "Epoch 101/1000\n",
      "61/61 [==============================] - 2s 28ms/step - loss: 0.2376 - val_loss: 0.3383\n",
      "Epoch 102/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.2366 - val_loss: 0.3169\n",
      "Epoch 103/1000\n",
      "61/61 [==============================] - 2s 28ms/step - loss: 0.2398 - val_loss: 0.3243\n",
      "Epoch 104/1000\n",
      "61/61 [==============================] - 2s 28ms/step - loss: 0.2373 - val_loss: 0.3134\n",
      "Epoch 105/1000\n",
      "61/61 [==============================] - 2s 28ms/step - loss: 0.2396 - val_loss: 0.3201\n",
      "Epoch 106/1000\n",
      "61/61 [==============================] - 2s 28ms/step - loss: 0.2413 - val_loss: 0.3174\n",
      "Epoch 107/1000\n",
      "61/61 [==============================] - 2s 34ms/step - loss: 0.2385 - val_loss: 0.3035\n",
      "Epoch 108/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.2372 - val_loss: 0.3017\n",
      "Epoch 109/1000\n",
      "61/61 [==============================] - 2s 28ms/step - loss: 0.2354 - val_loss: 0.2980\n",
      "Epoch 110/1000\n",
      "61/61 [==============================] - 2s 27ms/step - loss: 0.2339 - val_loss: 0.3041\n",
      "Epoch 111/1000\n",
      "61/61 [==============================] - 2s 31ms/step - loss: 0.2331 - val_loss: 0.3038\n",
      "Epoch 112/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.2332 - val_loss: 0.3004\n",
      "Epoch 113/1000\n",
      "61/61 [==============================] - 2s 28ms/step - loss: 0.2312 - val_loss: 0.3029\n",
      "Epoch 114/1000\n",
      "61/61 [==============================] - 2s 33ms/step - loss: 0.2385 - val_loss: 0.3212\n",
      "Epoch 115/1000\n",
      "61/61 [==============================] - 2s 32ms/step - loss: 0.2387 - val_loss: 0.3042\n",
      "Epoch 116/1000\n",
      "61/61 [==============================] - 2s 33ms/step - loss: 0.2445 - val_loss: 0.3002\n",
      "Epoch 117/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.2332 - val_loss: 0.2819\n",
      "Epoch 118/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.2305 - val_loss: 0.3135\n",
      "Epoch 119/1000\n",
      "61/61 [==============================] - 2s 32ms/step - loss: 0.2325 - val_loss: 0.3083\n",
      "Epoch 120/1000\n",
      "61/61 [==============================] - 2s 31ms/step - loss: 0.2299 - val_loss: 0.3141\n",
      "Epoch 121/1000\n",
      "61/61 [==============================] - 2s 31ms/step - loss: 0.2276 - val_loss: 0.2963\n",
      "Epoch 122/1000\n",
      "61/61 [==============================] - 2s 27ms/step - loss: 0.2302 - val_loss: 0.2913\n",
      "Epoch 123/1000\n",
      "61/61 [==============================] - 2s 32ms/step - loss: 0.2280 - val_loss: 0.2861\n",
      "Epoch 124/1000\n",
      "61/61 [==============================] - 2s 28ms/step - loss: 0.2252 - val_loss: 0.2876\n",
      "Epoch 125/1000\n",
      "61/61 [==============================] - 2s 28ms/step - loss: 0.2256 - val_loss: 0.2756\n",
      "Epoch 126/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.2232 - val_loss: 0.2750\n",
      "Epoch 127/1000\n",
      "61/61 [==============================] - 2s 31ms/step - loss: 0.2230 - val_loss: 0.2865\n",
      "Epoch 128/1000\n",
      "61/61 [==============================] - 2s 28ms/step - loss: 0.2255 - val_loss: 0.2850\n",
      "Epoch 129/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.2224 - val_loss: 0.3045\n",
      "Epoch 130/1000\n",
      "61/61 [==============================] - 2s 27ms/step - loss: 0.2204 - val_loss: 0.2784\n",
      "Epoch 131/1000\n",
      "61/61 [==============================] - 2s 28ms/step - loss: 0.2235 - val_loss: 0.2728\n",
      "Epoch 132/1000\n",
      "61/61 [==============================] - 2s 28ms/step - loss: 0.2240 - val_loss: 0.3067\n",
      "Epoch 133/1000\n",
      "61/61 [==============================] - 2s 28ms/step - loss: 0.2240 - val_loss: 0.2954\n",
      "Epoch 134/1000\n",
      "61/61 [==============================] - 2s 28ms/step - loss: 0.2271 - val_loss: 0.3013\n",
      "Epoch 135/1000\n",
      "61/61 [==============================] - 2s 28ms/step - loss: 0.2214 - val_loss: 0.2813\n",
      "Epoch 136/1000\n",
      "61/61 [==============================] - 2s 28ms/step - loss: 0.2208 - val_loss: 0.2919\n",
      "Epoch 137/1000\n",
      "61/61 [==============================] - 2s 28ms/step - loss: 0.2202 - val_loss: 0.2938\n",
      "Epoch 138/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.2175 - val_loss: 0.2727\n",
      "Epoch 139/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.2166 - val_loss: 0.2751\n",
      "Epoch 140/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.2176 - val_loss: 0.2761\n",
      "Epoch 141/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.2245 - val_loss: 0.3849\n",
      "Epoch 142/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.4883 - val_loss: 0.5073\n",
      "Epoch 143/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.4020 - val_loss: 0.4295\n",
      "Epoch 144/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.3052 - val_loss: 0.3647\n",
      "Epoch 145/1000\n",
      "61/61 [==============================] - 2s 28ms/step - loss: 0.3050 - val_loss: 0.4179\n",
      "Epoch 146/1000\n",
      "61/61 [==============================] - 2s 27ms/step - loss: 0.3117 - val_loss: 0.3887\n",
      "Epoch 147/1000\n",
      "61/61 [==============================] - 2s 28ms/step - loss: 0.2677 - val_loss: 0.3281\n",
      "Epoch 148/1000\n",
      "61/61 [==============================] - 2s 27ms/step - loss: 0.2486 - val_loss: 0.3212\n",
      "Epoch 149/1000\n",
      "61/61 [==============================] - 2s 27ms/step - loss: 0.2405 - val_loss: 0.3132\n",
      "Epoch 150/1000\n",
      "61/61 [==============================] - 2s 27ms/step - loss: 0.2334 - val_loss: 0.3079\n",
      "Epoch 151/1000\n",
      "61/61 [==============================] - 2s 27ms/step - loss: 0.2297 - val_loss: 0.3150\n",
      "Epoch 152/1000\n",
      "61/61 [==============================] - 2s 27ms/step - loss: 0.2279 - val_loss: 0.2936\n",
      "Epoch 153/1000\n",
      "61/61 [==============================] - 2s 27ms/step - loss: 0.2277 - val_loss: 0.3115\n",
      "Epoch 154/1000\n",
      "61/61 [==============================] - 2s 28ms/step - loss: 0.2345 - val_loss: 0.2992\n",
      "Epoch 155/1000\n",
      "61/61 [==============================] - 2s 28ms/step - loss: 0.2255 - val_loss: 0.3002\n",
      "Epoch 156/1000\n",
      "61/61 [==============================] - 2s 28ms/step - loss: 0.2223 - val_loss: 0.2911\n",
      "Epoch 157/1000\n",
      "61/61 [==============================] - 2s 28ms/step - loss: 0.2200 - val_loss: 0.2886\n",
      "Epoch 158/1000\n",
      "61/61 [==============================] - 2s 28ms/step - loss: 0.2219 - val_loss: 0.2864\n",
      "Epoch 159/1000\n",
      "61/61 [==============================] - 2s 28ms/step - loss: 0.2179 - val_loss: 0.2793\n",
      "Epoch 160/1000\n",
      "61/61 [==============================] - 2s 27ms/step - loss: 0.2161 - val_loss: 0.2840\n",
      "Epoch 161/1000\n",
      "61/61 [==============================] - 2s 28ms/step - loss: 0.2168 - val_loss: 0.2885\n",
      "Epoch 162/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.2164 - val_loss: 0.2919\n",
      "Epoch 163/1000\n",
      "61/61 [==============================] - 2s 28ms/step - loss: 0.2150 - val_loss: 0.2818\n",
      "Epoch 164/1000\n",
      "61/61 [==============================] - 2s 28ms/step - loss: 0.2137 - val_loss: 0.2749\n",
      "Epoch 165/1000\n",
      "61/61 [==============================] - 2s 28ms/step - loss: 0.2129 - val_loss: 0.2863\n",
      "Epoch 166/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.2149 - val_loss: 0.2881\n",
      "Epoch 167/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.2154 - val_loss: 0.2777\n",
      "Epoch 168/1000\n",
      "61/61 [==============================] - 2s 28ms/step - loss: 0.2126 - val_loss: 0.2872\n",
      "Epoch 169/1000\n",
      "61/61 [==============================] - 2s 28ms/step - loss: 0.2154 - val_loss: 0.2847\n",
      "Epoch 170/1000\n",
      "61/61 [==============================] - 2s 28ms/step - loss: 0.2133 - val_loss: 0.2801\n",
      "Epoch 171/1000\n",
      "61/61 [==============================] - 2s 28ms/step - loss: 0.2569 - val_loss: 0.3420\n",
      "Epoch 172/1000\n",
      "61/61 [==============================] - 2s 27ms/step - loss: 0.2465 - val_loss: 0.2969\n",
      "Epoch 173/1000\n",
      "61/61 [==============================] - 2s 31ms/step - loss: 0.2254 - val_loss: 0.2713\n",
      "Epoch 174/1000\n",
      "61/61 [==============================] - 2s 33ms/step - loss: 0.2170 - val_loss: 0.2589\n",
      "Epoch 175/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.2126 - val_loss: 0.2542\n",
      "Epoch 176/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.2126 - val_loss: 0.2587\n",
      "Epoch 177/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.2103 - val_loss: 0.2681\n",
      "Epoch 178/1000\n",
      "61/61 [==============================] - 2s 33ms/step - loss: 0.2117 - val_loss: 0.2538\n",
      "Epoch 179/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.2098 - val_loss: 0.2493\n",
      "Epoch 180/1000\n",
      "61/61 [==============================] - 2s 28ms/step - loss: 0.2160 - val_loss: 0.2760\n",
      "Epoch 181/1000\n",
      "61/61 [==============================] - 2s 28ms/step - loss: 0.2157 - val_loss: 0.2585\n",
      "Epoch 182/1000\n",
      "61/61 [==============================] - 2s 27ms/step - loss: 0.2101 - val_loss: 0.2530\n",
      "Epoch 183/1000\n",
      "61/61 [==============================] - 2s 28ms/step - loss: 0.2087 - val_loss: 0.2630\n",
      "Epoch 184/1000\n",
      "61/61 [==============================] - 2s 28ms/step - loss: 0.2102 - val_loss: 0.2506\n",
      "Epoch 185/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.2103 - val_loss: 0.2392\n",
      "Epoch 186/1000\n",
      "61/61 [==============================] - 2s 27ms/step - loss: 0.2091 - val_loss: 0.2542\n",
      "Epoch 187/1000\n",
      "61/61 [==============================] - 2s 28ms/step - loss: 0.2063 - val_loss: 0.2506\n",
      "Epoch 188/1000\n",
      "61/61 [==============================] - 2s 28ms/step - loss: 0.2058 - val_loss: 0.2431\n",
      "Epoch 189/1000\n",
      "61/61 [==============================] - 2s 28ms/step - loss: 0.2072 - val_loss: 0.2413\n",
      "Epoch 190/1000\n",
      "61/61 [==============================] - 2s 28ms/step - loss: 0.2060 - val_loss: 0.2422\n",
      "Epoch 191/1000\n",
      "61/61 [==============================] - 2s 27ms/step - loss: 0.2040 - val_loss: 0.2324\n",
      "Epoch 192/1000\n",
      "61/61 [==============================] - 2s 28ms/step - loss: 0.2033 - val_loss: 0.2346\n",
      "Epoch 193/1000\n",
      "61/61 [==============================] - 2s 28ms/step - loss: 0.2030 - val_loss: 0.2327\n",
      "Epoch 194/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.2027 - val_loss: 0.2375\n",
      "Epoch 195/1000\n",
      "61/61 [==============================] - 2s 28ms/step - loss: 0.2032 - val_loss: 0.2472\n",
      "Epoch 196/1000\n",
      "61/61 [==============================] - 2s 28ms/step - loss: 0.2049 - val_loss: 0.2438\n",
      "Epoch 197/1000\n",
      "61/61 [==============================] - 2s 28ms/step - loss: 0.2060 - val_loss: 0.2373\n",
      "Epoch 198/1000\n",
      "61/61 [==============================] - 2s 28ms/step - loss: 0.2027 - val_loss: 0.2353\n",
      "Epoch 199/1000\n",
      "61/61 [==============================] - 2s 28ms/step - loss: 0.2022 - val_loss: 0.2385\n",
      "Epoch 200/1000\n",
      "61/61 [==============================] - 2s 28ms/step - loss: 0.2026 - val_loss: 0.2445\n",
      "Epoch 201/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.2033 - val_loss: 0.2323\n",
      "Epoch 202/1000\n",
      "61/61 [==============================] - 2s 28ms/step - loss: 0.2024 - val_loss: 0.2313\n",
      "Epoch 203/1000\n",
      "61/61 [==============================] - 2s 28ms/step - loss: 0.2034 - val_loss: 0.2308\n",
      "Epoch 204/1000\n",
      "61/61 [==============================] - 2s 28ms/step - loss: 0.2052 - val_loss: 0.2279\n",
      "Epoch 205/1000\n",
      "61/61 [==============================] - 2s 28ms/step - loss: 0.2026 - val_loss: 0.2395\n",
      "Epoch 206/1000\n",
      "61/61 [==============================] - 2s 28ms/step - loss: 0.2010 - val_loss: 0.2318\n",
      "Epoch 207/1000\n",
      "61/61 [==============================] - 2s 28ms/step - loss: 0.2016 - val_loss: 0.2338\n",
      "Epoch 208/1000\n",
      "61/61 [==============================] - 2s 28ms/step - loss: 0.2035 - val_loss: 0.2299\n",
      "Epoch 209/1000\n",
      "61/61 [==============================] - 2s 28ms/step - loss: 0.2035 - val_loss: 0.2345\n",
      "Epoch 210/1000\n",
      "61/61 [==============================] - 2s 28ms/step - loss: 0.2015 - val_loss: 0.2285\n",
      "Epoch 211/1000\n",
      "61/61 [==============================] - 2s 27ms/step - loss: 0.2025 - val_loss: 0.2460\n",
      "Epoch 212/1000\n",
      "61/61 [==============================] - 2s 27ms/step - loss: 0.2006 - val_loss: 0.2283\n",
      "Epoch 213/1000\n",
      "61/61 [==============================] - 2s 27ms/step - loss: 0.2011 - val_loss: 0.2370\n",
      "Epoch 214/1000\n",
      "61/61 [==============================] - 2s 27ms/step - loss: 0.2003 - val_loss: 0.2427\n",
      "Epoch 215/1000\n",
      "61/61 [==============================] - 2s 27ms/step - loss: 0.1993 - val_loss: 0.2331\n",
      "Epoch 216/1000\n",
      "61/61 [==============================] - 2s 28ms/step - loss: 0.1978 - val_loss: 0.2432\n",
      "Epoch 217/1000\n",
      "61/61 [==============================] - 2s 27ms/step - loss: 0.1982 - val_loss: 0.2264\n",
      "Epoch 218/1000\n",
      "61/61 [==============================] - 2s 28ms/step - loss: 0.1986 - val_loss: 0.2348\n",
      "Epoch 219/1000\n",
      "61/61 [==============================] - 2s 28ms/step - loss: 0.2000 - val_loss: 0.2328\n",
      "Epoch 220/1000\n",
      "61/61 [==============================] - 2s 28ms/step - loss: 0.1995 - val_loss: 0.2296\n",
      "Epoch 221/1000\n",
      "61/61 [==============================] - 2s 27ms/step - loss: 0.1997 - val_loss: 0.2237\n",
      "Epoch 222/1000\n",
      "61/61 [==============================] - 2s 27ms/step - loss: 0.1993 - val_loss: 0.2361\n",
      "Epoch 223/1000\n",
      "61/61 [==============================] - 2s 27ms/step - loss: 0.2003 - val_loss: 0.2359\n",
      "Epoch 224/1000\n",
      "61/61 [==============================] - 2s 28ms/step - loss: 0.1991 - val_loss: 0.2301\n",
      "Epoch 225/1000\n",
      "61/61 [==============================] - 2s 27ms/step - loss: 0.1982 - val_loss: 0.2247\n",
      "Epoch 226/1000\n",
      "61/61 [==============================] - 2s 27ms/step - loss: 0.1974 - val_loss: 0.2253\n",
      "Epoch 227/1000\n",
      "61/61 [==============================] - 2s 27ms/step - loss: 0.1973 - val_loss: 0.2433\n",
      "Epoch 228/1000\n",
      "61/61 [==============================] - 2s 27ms/step - loss: 0.1976 - val_loss: 0.2521\n",
      "Epoch 229/1000\n",
      "61/61 [==============================] - 2s 28ms/step - loss: 0.1973 - val_loss: 0.2190\n",
      "Epoch 230/1000\n",
      "61/61 [==============================] - 2s 28ms/step - loss: 0.2421 - val_loss: 0.3461\n",
      "Epoch 231/1000\n",
      "61/61 [==============================] - 2s 28ms/step - loss: 0.2259 - val_loss: 0.2732\n",
      "Epoch 232/1000\n",
      "61/61 [==============================] - 2s 28ms/step - loss: 0.2081 - val_loss: 0.2583\n",
      "Epoch 233/1000\n",
      "61/61 [==============================] - 2s 27ms/step - loss: 0.2054 - val_loss: 0.2464\n",
      "Epoch 234/1000\n",
      "61/61 [==============================] - 2s 27ms/step - loss: 0.1990 - val_loss: 0.2447\n",
      "Epoch 235/1000\n",
      "61/61 [==============================] - 2s 28ms/step - loss: 0.1973 - val_loss: 0.2636\n",
      "Epoch 236/1000\n",
      "61/61 [==============================] - 2s 28ms/step - loss: 0.1964 - val_loss: 0.2435\n",
      "Epoch 237/1000\n",
      "61/61 [==============================] - 2s 27ms/step - loss: 0.1958 - val_loss: 0.2297\n",
      "Epoch 238/1000\n",
      "61/61 [==============================] - 2s 27ms/step - loss: 0.1995 - val_loss: 0.2222\n",
      "Epoch 239/1000\n",
      "61/61 [==============================] - 2s 28ms/step - loss: 0.1971 - val_loss: 0.2265\n",
      "Epoch 240/1000\n",
      "61/61 [==============================] - 2s 28ms/step - loss: 0.1975 - val_loss: 0.2255\n",
      "Epoch 241/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.1964 - val_loss: 0.2407\n",
      "Epoch 242/1000\n",
      "61/61 [==============================] - 2s 28ms/step - loss: 0.1956 - val_loss: 0.2334\n",
      "Epoch 243/1000\n",
      "61/61 [==============================] - 2s 28ms/step - loss: 0.1938 - val_loss: 0.2291\n",
      "Epoch 244/1000\n",
      "61/61 [==============================] - 2s 27ms/step - loss: 0.1932 - val_loss: 0.2289\n",
      "Epoch 245/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.1949 - val_loss: 0.2192\n",
      "Epoch 246/1000\n",
      "61/61 [==============================] - 2s 28ms/step - loss: 0.1939 - val_loss: 0.2460\n",
      "Epoch 247/1000\n",
      "61/61 [==============================] - 2s 27ms/step - loss: 0.1948 - val_loss: 0.2214\n",
      "Epoch 248/1000\n",
      "61/61 [==============================] - 2s 28ms/step - loss: 0.1941 - val_loss: 0.2268\n",
      "Epoch 249/1000\n",
      "61/61 [==============================] - 2s 27ms/step - loss: 0.1946 - val_loss: 0.2408\n",
      "Epoch 250/1000\n",
      "61/61 [==============================] - 2s 27ms/step - loss: 0.1941 - val_loss: 0.2346\n",
      "Epoch 251/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.1944 - val_loss: 0.2323\n",
      "Epoch 252/1000\n",
      "61/61 [==============================] - 2s 28ms/step - loss: 0.1935 - val_loss: 0.2419\n",
      "Epoch 253/1000\n",
      "61/61 [==============================] - 2s 28ms/step - loss: 0.1944 - val_loss: 0.2328\n",
      "Epoch 254/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.1937 - val_loss: 0.2357\n",
      "Epoch 255/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.1934 - val_loss: 0.2349\n",
      "Epoch 256/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.1931 - val_loss: 0.2339\n",
      "Epoch 257/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.1937 - val_loss: 0.2267\n",
      "Epoch 258/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.1930 - val_loss: 0.2285\n",
      "Epoch 259/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.1913 - val_loss: 0.2239\n",
      "Epoch 260/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.1916 - val_loss: 0.2322\n",
      "Epoch 261/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.1913 - val_loss: 0.2122\n",
      "Epoch 262/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.1914 - val_loss: 0.2152\n",
      "Epoch 263/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.1923 - val_loss: 0.2214\n",
      "Epoch 264/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.1947 - val_loss: 0.2274\n",
      "Epoch 265/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.1974 - val_loss: 0.2262\n",
      "Epoch 266/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.1918 - val_loss: 0.2201\n",
      "Epoch 267/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.1915 - val_loss: 0.2128\n",
      "Epoch 268/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.1928 - val_loss: 0.2497\n",
      "Epoch 269/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.1970 - val_loss: 0.2356\n",
      "Epoch 270/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.1930 - val_loss: 0.2156\n",
      "Epoch 271/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.1912 - val_loss: 0.2302\n",
      "Epoch 272/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.1900 - val_loss: 0.2371\n",
      "Epoch 273/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.1900 - val_loss: 0.2153\n",
      "Epoch 274/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.1903 - val_loss: 0.2238\n",
      "Epoch 275/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.1934 - val_loss: 0.2207\n",
      "Epoch 276/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.1901 - val_loss: 0.2181\n",
      "Epoch 277/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.1909 - val_loss: 0.2321\n",
      "Epoch 278/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.1894 - val_loss: 0.2237\n",
      "Epoch 279/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.1903 - val_loss: 0.2254\n",
      "Epoch 280/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.1887 - val_loss: 0.2222\n",
      "Epoch 281/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.1889 - val_loss: 0.2225\n",
      "Epoch 282/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.1884 - val_loss: 0.2210\n",
      "Epoch 283/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.1890 - val_loss: 0.2333\n",
      "Epoch 284/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.1895 - val_loss: 0.2248\n",
      "Epoch 285/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.1890 - val_loss: 0.2220\n",
      "Epoch 286/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.1901 - val_loss: 0.2345\n",
      "Epoch 287/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.1905 - val_loss: 0.2212\n",
      "Epoch 288/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.1887 - val_loss: 0.2474\n",
      "Epoch 289/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.1885 - val_loss: 0.2155\n",
      "Epoch 290/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.1882 - val_loss: 0.2179\n",
      "Epoch 291/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.1885 - val_loss: 0.2169\n",
      "Epoch 292/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.1868 - val_loss: 0.2109\n",
      "Epoch 293/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.1878 - val_loss: 0.2231\n",
      "Epoch 294/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.1875 - val_loss: 0.2109\n",
      "Epoch 295/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.1879 - val_loss: 0.2157\n",
      "Epoch 296/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.1882 - val_loss: 0.2109\n",
      "Epoch 297/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.1943 - val_loss: 0.2059\n",
      "Epoch 298/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.1900 - val_loss: 0.2102\n",
      "Epoch 299/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.1877 - val_loss: 0.2135\n",
      "Epoch 300/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.1886 - val_loss: 0.2167\n",
      "Epoch 301/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.1902 - val_loss: 0.2183\n",
      "Epoch 302/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.1867 - val_loss: 0.2057\n",
      "Epoch 303/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.1876 - val_loss: 0.2138\n",
      "Epoch 304/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.1849 - val_loss: 0.2063\n",
      "Epoch 305/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.1862 - val_loss: 0.2097\n",
      "Epoch 306/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.1869 - val_loss: 0.2024\n",
      "Epoch 307/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.1913 - val_loss: 0.2556\n",
      "Epoch 308/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.2555 - val_loss: 0.3935\n",
      "Epoch 309/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.3079 - val_loss: 0.3275\n",
      "Epoch 310/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.2318 - val_loss: 0.2789\n",
      "Epoch 311/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.2068 - val_loss: 0.2665\n",
      "Epoch 312/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.1988 - val_loss: 0.2480\n",
      "Epoch 313/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.1950 - val_loss: 0.2517\n",
      "Epoch 314/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.1928 - val_loss: 0.2414\n",
      "Epoch 315/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.1914 - val_loss: 0.2345\n",
      "Epoch 316/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.1899 - val_loss: 0.2308\n",
      "Epoch 317/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.1885 - val_loss: 0.2299\n",
      "Epoch 318/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.1890 - val_loss: 0.2242\n",
      "Epoch 319/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.1866 - val_loss: 0.2118\n",
      "Epoch 320/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.1870 - val_loss: 0.2148\n",
      "Epoch 321/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.1852 - val_loss: 0.2202\n",
      "Epoch 322/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.1853 - val_loss: 0.2223\n",
      "Epoch 323/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.1842 - val_loss: 0.2244\n",
      "Epoch 324/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.1856 - val_loss: 0.2238\n",
      "Epoch 325/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.1844 - val_loss: 0.2194\n",
      "Epoch 326/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.1831 - val_loss: 0.2155\n",
      "Epoch 327/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.1839 - val_loss: 0.2177\n",
      "Epoch 328/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.1850 - val_loss: 0.2312\n",
      "Epoch 329/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.1853 - val_loss: 0.2012\n",
      "Epoch 330/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.1834 - val_loss: 0.2044\n",
      "Epoch 331/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.1825 - val_loss: 0.2078\n",
      "Epoch 332/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.1829 - val_loss: 0.2097\n",
      "Epoch 333/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.1832 - val_loss: 0.2054\n",
      "Epoch 334/1000\n",
      "61/61 [==============================] - 2s 28ms/step - loss: 0.1826 - val_loss: 0.2095\n",
      "Epoch 335/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.1837 - val_loss: 0.2019\n",
      "Epoch 336/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.1828 - val_loss: 0.2023\n",
      "Epoch 337/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.1820 - val_loss: 0.2083\n",
      "Epoch 338/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.1827 - val_loss: 0.2039\n",
      "Epoch 339/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.1822 - val_loss: 0.2033\n",
      "Epoch 340/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.1839 - val_loss: 0.2150\n",
      "Epoch 341/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.1842 - val_loss: 0.2008\n",
      "Epoch 342/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.1818 - val_loss: 0.2036\n",
      "Epoch 343/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.1862 - val_loss: 0.2806\n",
      "Epoch 344/1000\n",
      "61/61 [==============================] - 2s 28ms/step - loss: 0.2422 - val_loss: 0.2934\n",
      "Epoch 345/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.2191 - val_loss: 0.2727\n",
      "Epoch 346/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.2043 - val_loss: 0.2368\n",
      "Epoch 347/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.1907 - val_loss: 0.2252\n",
      "Epoch 348/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.1883 - val_loss: 0.2138\n",
      "Epoch 349/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.1912 - val_loss: 0.2130\n",
      "Epoch 350/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.1865 - val_loss: 0.2124\n",
      "Epoch 351/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.1844 - val_loss: 0.2088\n",
      "Epoch 352/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.1844 - val_loss: 0.2030\n",
      "Epoch 353/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.1830 - val_loss: 0.2069\n",
      "Epoch 354/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.1842 - val_loss: 0.2098\n",
      "Epoch 355/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.1832 - val_loss: 0.2015\n",
      "Epoch 356/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.1823 - val_loss: 0.2124\n",
      "Epoch 357/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.1821 - val_loss: 0.2033\n",
      "Epoch 358/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.1806 - val_loss: 0.2054\n",
      "Epoch 359/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.1815 - val_loss: 0.2028\n",
      "Epoch 360/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.1814 - val_loss: 0.1997\n",
      "Epoch 361/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.1805 - val_loss: 0.2086\n",
      "Epoch 362/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.1813 - val_loss: 0.2051\n",
      "Epoch 363/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.1808 - val_loss: 0.2110\n",
      "Epoch 364/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.1794 - val_loss: 0.2051\n",
      "Epoch 365/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.1803 - val_loss: 0.2046\n",
      "Epoch 366/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.1802 - val_loss: 0.1972\n",
      "Epoch 367/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.1792 - val_loss: 0.1996\n",
      "Epoch 368/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.1814 - val_loss: 0.2059\n",
      "Epoch 369/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.1797 - val_loss: 0.2048\n",
      "Epoch 370/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.1801 - val_loss: 0.2022\n",
      "Epoch 371/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.1807 - val_loss: 0.1910\n",
      "Epoch 372/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.1794 - val_loss: 0.1936\n",
      "Epoch 373/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.1801 - val_loss: 0.2028\n",
      "Epoch 374/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.1795 - val_loss: 0.1982\n",
      "Epoch 375/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.1800 - val_loss: 0.2041\n",
      "Epoch 376/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.1793 - val_loss: 0.2000\n",
      "Epoch 377/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.1790 - val_loss: 0.1995\n",
      "Epoch 378/1000\n",
      "61/61 [==============================] - 2s 31ms/step - loss: 0.1787 - val_loss: 0.1900\n",
      "Epoch 379/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.1799 - val_loss: 0.1942\n",
      "Epoch 380/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.1803 - val_loss: 0.1996\n",
      "Epoch 381/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.1805 - val_loss: 0.1962\n",
      "Epoch 382/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.1805 - val_loss: 0.1941\n",
      "Epoch 383/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.1806 - val_loss: 0.1993\n",
      "Epoch 384/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.1788 - val_loss: 0.1959\n",
      "Epoch 385/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.1786 - val_loss: 0.1946\n",
      "Epoch 386/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.1782 - val_loss: 0.1895\n",
      "Epoch 387/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.1784 - val_loss: 0.1933\n",
      "Epoch 388/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.1783 - val_loss: 0.1966\n",
      "Epoch 389/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.1794 - val_loss: 0.1899\n",
      "Epoch 390/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.1783 - val_loss: 0.2007\n",
      "Epoch 391/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.1785 - val_loss: 0.1963\n",
      "Epoch 392/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.1795 - val_loss: 0.2015\n",
      "Epoch 393/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.1783 - val_loss: 0.1887\n",
      "Epoch 394/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.1790 - val_loss: 0.2034\n",
      "Epoch 395/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.1790 - val_loss: 0.1953\n",
      "Epoch 396/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.1782 - val_loss: 0.1986\n",
      "Epoch 397/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.1780 - val_loss: 0.1988\n",
      "Epoch 398/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.1769 - val_loss: 0.2008\n",
      "Epoch 399/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.1778 - val_loss: 0.1996\n",
      "Epoch 400/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.1769 - val_loss: 0.1892\n",
      "Epoch 401/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.1778 - val_loss: 0.1989\n",
      "Epoch 402/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.1777 - val_loss: 0.2001\n",
      "Epoch 403/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.1788 - val_loss: 0.1910\n",
      "Epoch 404/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.1780 - val_loss: 0.1936\n",
      "Epoch 405/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.1791 - val_loss: 0.1915\n",
      "Epoch 406/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.1773 - val_loss: 0.1902\n",
      "Epoch 407/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.1781 - val_loss: 0.2009\n",
      "Epoch 408/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.1786 - val_loss: 0.2136\n",
      "Epoch 409/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.1774 - val_loss: 0.2016\n",
      "Epoch 410/1000\n",
      "61/61 [==============================] - 2s 31ms/step - loss: 0.1778 - val_loss: 0.1994\n",
      "Epoch 411/1000\n",
      "61/61 [==============================] - 2s 31ms/step - loss: 0.1780 - val_loss: 0.1952\n",
      "Epoch 412/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.1784 - val_loss: 0.2069\n",
      "Epoch 413/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.1775 - val_loss: 0.2029\n",
      "Epoch 414/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.1781 - val_loss: 0.1957\n",
      "Epoch 415/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.1780 - val_loss: 0.2029\n",
      "Epoch 416/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.1775 - val_loss: 0.1911\n",
      "Epoch 417/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.1775 - val_loss: 0.1925\n",
      "Epoch 418/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.1797 - val_loss: 0.1997\n",
      "Epoch 419/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.1784 - val_loss: 0.1987\n",
      "Epoch 420/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.1774 - val_loss: 0.1981\n",
      "Epoch 421/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.1767 - val_loss: 0.1957\n",
      "Epoch 422/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.1768 - val_loss: 0.1978\n",
      "Epoch 423/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.1769 - val_loss: 0.1871\n",
      "Epoch 424/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.1755 - val_loss: 0.1934\n",
      "Epoch 425/1000\n",
      "61/61 [==============================] - 2s 28ms/step - loss: 0.1788 - val_loss: 0.2102\n",
      "Epoch 426/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.1811 - val_loss: 0.2460\n",
      "Epoch 427/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.1867 - val_loss: 0.2025\n",
      "Epoch 428/1000\n",
      "61/61 [==============================] - 2s 28ms/step - loss: 0.1795 - val_loss: 0.2080\n",
      "Epoch 429/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.1781 - val_loss: 0.2053\n",
      "Epoch 430/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.1769 - val_loss: 0.1987\n",
      "Epoch 431/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.1762 - val_loss: 0.1961\n",
      "Epoch 432/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.1764 - val_loss: 0.1995\n",
      "Epoch 433/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.1764 - val_loss: 0.1999\n",
      "Epoch 434/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.1772 - val_loss: 0.1979\n",
      "Epoch 435/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.1764 - val_loss: 0.1966\n",
      "Epoch 436/1000\n",
      "61/61 [==============================] - 2s 28ms/step - loss: 0.1766 - val_loss: 0.1929\n",
      "Epoch 437/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.1767 - val_loss: 0.2000\n",
      "Epoch 438/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.1759 - val_loss: 0.1914\n",
      "Epoch 439/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.1754 - val_loss: 0.1912\n",
      "Epoch 440/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.1758 - val_loss: 0.1942\n",
      "Epoch 441/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.1757 - val_loss: 0.1952\n",
      "Epoch 442/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.1748 - val_loss: 0.1953\n",
      "Epoch 443/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.1749 - val_loss: 0.1887\n",
      "Epoch 444/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.1753 - val_loss: 0.1890\n",
      "Epoch 445/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.1754 - val_loss: 0.1913\n",
      "Epoch 446/1000\n",
      "61/61 [==============================] - 2s 28ms/step - loss: 0.1750 - val_loss: 0.1937\n",
      "Epoch 447/1000\n",
      "61/61 [==============================] - 2s 28ms/step - loss: 0.1747 - val_loss: 0.1900\n",
      "Epoch 448/1000\n",
      "61/61 [==============================] - 2s 32ms/step - loss: 0.1748 - val_loss: 0.1895\n",
      "Epoch 449/1000\n",
      "61/61 [==============================] - 2s 33ms/step - loss: 0.1740 - val_loss: 0.1962\n",
      "Epoch 450/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.1745 - val_loss: 0.1879\n",
      "Epoch 451/1000\n",
      "61/61 [==============================] - 2s 31ms/step - loss: 0.1739 - val_loss: 0.2066\n",
      "Epoch 452/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.1738 - val_loss: 0.1982\n",
      "Epoch 453/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.1754 - val_loss: 0.1894\n",
      "Epoch 454/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.1755 - val_loss: 0.1940\n",
      "Epoch 455/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.1749 - val_loss: 0.1925\n",
      "Epoch 456/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.1749 - val_loss: 0.1912\n",
      "Epoch 457/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.1740 - val_loss: 0.1951\n",
      "Epoch 458/1000\n",
      "61/61 [==============================] - ETA: 0s - loss: 0.1747Restoring model weights from the end of the best epoch: 423.\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.1747 - val_loss: 0.1962\n",
      "Epoch 458: early stopping\n",
      "7/7 [==============================] - 2s 24ms/step\n",
      "0.1712296743255747\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3c939d9c00fb432ca7dc2a23a05ad94e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.067 MB of 0.067 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch/epoch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▃▃▃▄▄▄▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>epoch/learning_rate</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>epoch/loss</td><td>█▃▂▂▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>epoch/val_loss</td><td>█▄▄▄▄▃▃▃▂▂▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>rmase_prediction</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch/epoch</td><td>457</td></tr><tr><td>epoch/learning_rate</td><td>0.00049</td></tr><tr><td>epoch/loss</td><td>0.17471</td></tr><tr><td>epoch/val_loss</td><td>0.19617</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">test_3</strong> at: <a href='https://wandb.ai/uu13234-none/sgnate_skate-keras/runs/wnklco54' target=\"_blank\">https://wandb.ai/uu13234-none/sgnate_skate-keras/runs/wnklco54</a><br/> View project at: <a href='https://wandb.ai/uu13234-none/sgnate_skate-keras' target=\"_blank\">https://wandb.ai/uu13234-none/sgnate_skate-keras</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20241104_143248-wnklco54\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.18.3"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\sato\\Desktop\\python\\SIGNATE\\スケートボードの挙動予測\\code-analysis\\wandb\\run-20241104_144631-e9gziq6y</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/uu13234-none/sgnate_skate-keras/runs/e9gziq6y' target=\"_blank\">test_4</a></strong> to <a href='https://wandb.ai/uu13234-none/sgnate_skate-keras' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/uu13234-none/sgnate_skate-keras' target=\"_blank\">https://wandb.ai/uu13234-none/sgnate_skate-keras</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/uu13234-none/sgnate_skate-keras/runs/e9gziq6y' target=\"_blank\">https://wandb.ai/uu13234-none/sgnate_skate-keras/runs/e9gziq6y</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      " 5/61 [=>............................] - ETA: 1s - loss: 2.2739 WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0229s vs `on_train_batch_end` time: 0.0361s). Check your callbacks.\n",
      "61/61 [==============================] - 9s 50ms/step - loss: 1.5053 - val_loss: 1.2624\n",
      "Epoch 2/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 1.0831 - val_loss: 0.9784\n",
      "Epoch 3/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.9137 - val_loss: 0.8539\n",
      "Epoch 4/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.8401 - val_loss: 0.7632\n",
      "Epoch 5/1000\n",
      "61/61 [==============================] - 2s 31ms/step - loss: 0.7829 - val_loss: 0.7547\n",
      "Epoch 6/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.7148 - val_loss: 0.7935\n",
      "Epoch 7/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.6817 - val_loss: 0.7279\n",
      "Epoch 8/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.6834 - val_loss: 0.6508\n",
      "Epoch 9/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.6591 - val_loss: 0.7091\n",
      "Epoch 10/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.6185 - val_loss: 0.7310\n",
      "Epoch 11/1000\n",
      "61/61 [==============================] - 2s 31ms/step - loss: 0.6062 - val_loss: 0.6562\n",
      "Epoch 12/1000\n",
      "61/61 [==============================] - 2s 31ms/step - loss: 0.5788 - val_loss: 0.6520\n",
      "Epoch 13/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.5724 - val_loss: 0.6775\n",
      "Epoch 14/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.5429 - val_loss: 0.6540\n",
      "Epoch 15/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.5405 - val_loss: 0.6252\n",
      "Epoch 16/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.5335 - val_loss: 0.5622\n",
      "Epoch 17/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.5127 - val_loss: 0.5650\n",
      "Epoch 18/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.5259 - val_loss: 0.6025\n",
      "Epoch 19/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.4958 - val_loss: 0.5428\n",
      "Epoch 20/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.4577 - val_loss: 0.5254\n",
      "Epoch 21/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.4874 - val_loss: 0.5725\n",
      "Epoch 22/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.5311 - val_loss: 0.5455\n",
      "Epoch 23/1000\n",
      "61/61 [==============================] - 2s 31ms/step - loss: 0.4783 - val_loss: 0.5738\n",
      "Epoch 24/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.4497 - val_loss: 0.5252\n",
      "Epoch 25/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.4232 - val_loss: 0.5037\n",
      "Epoch 26/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.4100 - val_loss: 0.4901\n",
      "Epoch 27/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.4231 - val_loss: 0.5305\n",
      "Epoch 28/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.4128 - val_loss: 0.4989\n",
      "Epoch 29/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.4060 - val_loss: 0.5201\n",
      "Epoch 30/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.3940 - val_loss: 0.5287\n",
      "Epoch 31/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.3892 - val_loss: 0.4575\n",
      "Epoch 32/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.3698 - val_loss: 0.4363\n",
      "Epoch 33/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.3581 - val_loss: 0.4328\n",
      "Epoch 34/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.3566 - val_loss: 0.4528\n",
      "Epoch 35/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.4079 - val_loss: 0.4731\n",
      "Epoch 36/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.3839 - val_loss: 0.4764\n",
      "Epoch 37/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.3639 - val_loss: 0.4969\n",
      "Epoch 38/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.3911 - val_loss: 0.4507\n",
      "Epoch 39/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.3483 - val_loss: 0.4390\n",
      "Epoch 40/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.3433 - val_loss: 0.4220\n",
      "Epoch 41/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.3303 - val_loss: 0.4199\n",
      "Epoch 42/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.3264 - val_loss: 0.4139\n",
      "Epoch 43/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.3246 - val_loss: 0.4165\n",
      "Epoch 44/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.3143 - val_loss: 0.4030\n",
      "Epoch 45/1000\n",
      "61/61 [==============================] - 2s 31ms/step - loss: 0.3098 - val_loss: 0.4061\n",
      "Epoch 46/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.3115 - val_loss: 0.4271\n",
      "Epoch 47/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.3078 - val_loss: 0.3966\n",
      "Epoch 48/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.3784 - val_loss: 0.6496\n",
      "Epoch 49/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.4880 - val_loss: 0.6246\n",
      "Epoch 50/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.4189 - val_loss: 0.4639\n",
      "Epoch 51/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.3608 - val_loss: 0.4197\n",
      "Epoch 52/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.3322 - val_loss: 0.4133\n",
      "Epoch 53/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.3159 - val_loss: 0.4110\n",
      "Epoch 54/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.3059 - val_loss: 0.4129\n",
      "Epoch 55/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.2996 - val_loss: 0.3951\n",
      "Epoch 56/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.3854 - val_loss: 0.4923\n",
      "Epoch 57/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.4260 - val_loss: 0.5135\n",
      "Epoch 58/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.3639 - val_loss: 0.4602\n",
      "Epoch 59/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.3236 - val_loss: 0.4439\n",
      "Epoch 60/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.3121 - val_loss: 0.3995\n",
      "Epoch 61/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.3064 - val_loss: 0.3972\n",
      "Epoch 62/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.2959 - val_loss: 0.3801\n",
      "Epoch 63/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.2925 - val_loss: 0.3790\n",
      "Epoch 64/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.2803 - val_loss: 0.3828\n",
      "Epoch 65/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.2835 - val_loss: 0.3812\n",
      "Epoch 66/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.3301 - val_loss: 0.4052\n",
      "Epoch 67/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.2914 - val_loss: 0.3911\n",
      "Epoch 68/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.2882 - val_loss: 0.3797\n",
      "Epoch 69/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.2784 - val_loss: 0.3775\n",
      "Epoch 70/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.2763 - val_loss: 0.3673\n",
      "Epoch 71/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.2732 - val_loss: 0.3634\n",
      "Epoch 72/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.2688 - val_loss: 0.3555\n",
      "Epoch 73/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.2730 - val_loss: 0.3593\n",
      "Epoch 74/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.2672 - val_loss: 0.3449\n",
      "Epoch 75/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.2681 - val_loss: 0.3611\n",
      "Epoch 76/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.2779 - val_loss: 0.3601\n",
      "Epoch 77/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.2665 - val_loss: 0.3516\n",
      "Epoch 78/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.2604 - val_loss: 0.3529\n",
      "Epoch 79/1000\n",
      "61/61 [==============================] - 2s 31ms/step - loss: 0.2621 - val_loss: 0.3508\n",
      "Epoch 80/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.2588 - val_loss: 0.3567\n",
      "Epoch 81/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.2564 - val_loss: 0.3534\n",
      "Epoch 82/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.2578 - val_loss: 0.3520\n",
      "Epoch 83/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.2874 - val_loss: 0.3565\n",
      "Epoch 84/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.2682 - val_loss: 0.3862\n",
      "Epoch 85/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.3197 - val_loss: 0.4540\n",
      "Epoch 86/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.3805 - val_loss: 0.5143\n",
      "Epoch 87/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.3443 - val_loss: 0.3995\n",
      "Epoch 88/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.2978 - val_loss: 0.3914\n",
      "Epoch 89/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.2785 - val_loss: 0.3604\n",
      "Epoch 90/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.2653 - val_loss: 0.3701\n",
      "Epoch 91/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.2620 - val_loss: 0.3493\n",
      "Epoch 92/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.2844 - val_loss: 0.3748\n",
      "Epoch 93/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.2635 - val_loss: 0.3546\n",
      "Epoch 94/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.2607 - val_loss: 0.3537\n",
      "Epoch 95/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.2560 - val_loss: 0.3379\n",
      "Epoch 96/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.2501 - val_loss: 0.3356\n",
      "Epoch 97/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.2494 - val_loss: 0.3310\n",
      "Epoch 98/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.2487 - val_loss: 0.3309\n",
      "Epoch 99/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.2449 - val_loss: 0.3298\n",
      "Epoch 100/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.2448 - val_loss: 0.3241\n",
      "Epoch 101/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.2443 - val_loss: 0.3190\n",
      "Epoch 102/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.2418 - val_loss: 0.3203\n",
      "Epoch 103/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.2396 - val_loss: 0.3211\n",
      "Epoch 104/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.2381 - val_loss: 0.3260\n",
      "Epoch 105/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.2384 - val_loss: 0.3252\n",
      "Epoch 106/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.2372 - val_loss: 0.3239\n",
      "Epoch 107/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.2391 - val_loss: 0.3329\n",
      "Epoch 108/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.2391 - val_loss: 0.3165\n",
      "Epoch 109/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.2371 - val_loss: 0.3085\n",
      "Epoch 110/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.2388 - val_loss: 0.3206\n",
      "Epoch 111/1000\n",
      "61/61 [==============================] - 2s 31ms/step - loss: 0.2336 - val_loss: 0.3092\n",
      "Epoch 112/1000\n",
      "61/61 [==============================] - 2s 31ms/step - loss: 0.2353 - val_loss: 0.3083\n",
      "Epoch 113/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.2323 - val_loss: 0.3149\n",
      "Epoch 114/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.2309 - val_loss: 0.3102\n",
      "Epoch 115/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.2313 - val_loss: 0.3148\n",
      "Epoch 116/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.2332 - val_loss: 0.3111\n",
      "Epoch 117/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.2340 - val_loss: 0.3066\n",
      "Epoch 118/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.2305 - val_loss: 0.3154\n",
      "Epoch 119/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.2312 - val_loss: 0.3024\n",
      "Epoch 120/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.2322 - val_loss: 0.3002\n",
      "Epoch 121/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.2288 - val_loss: 0.2920\n",
      "Epoch 122/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.2303 - val_loss: 0.2960\n",
      "Epoch 123/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.2309 - val_loss: 0.3031\n",
      "Epoch 124/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.2305 - val_loss: 0.2834\n",
      "Epoch 125/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.2296 - val_loss: 0.2968\n",
      "Epoch 126/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.2529 - val_loss: 0.3242\n",
      "Epoch 127/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.2490 - val_loss: 0.3924\n",
      "Epoch 128/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.2719 - val_loss: 0.3392\n",
      "Epoch 129/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.3875 - val_loss: 0.5779\n",
      "Epoch 130/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.3271 - val_loss: 0.4451\n",
      "Epoch 131/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.3171 - val_loss: 0.4457\n",
      "Epoch 132/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.2822 - val_loss: 0.3790\n",
      "Epoch 133/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.2664 - val_loss: 0.3873\n",
      "Epoch 134/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.2665 - val_loss: 0.3417\n",
      "Epoch 135/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.2520 - val_loss: 0.3188\n",
      "Epoch 136/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.2396 - val_loss: 0.3146\n",
      "Epoch 137/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.2344 - val_loss: 0.3084\n",
      "Epoch 138/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.2323 - val_loss: 0.3075\n",
      "Epoch 139/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.2287 - val_loss: 0.3182\n",
      "Epoch 140/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.2263 - val_loss: 0.3174\n",
      "Epoch 141/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.2300 - val_loss: 0.3047\n",
      "Epoch 142/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.2271 - val_loss: 0.3028\n",
      "Epoch 143/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.2260 - val_loss: 0.2988\n",
      "Epoch 144/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.2244 - val_loss: 0.2991\n",
      "Epoch 145/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.2212 - val_loss: 0.2984\n",
      "Epoch 146/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.2212 - val_loss: 0.2984\n",
      "Epoch 147/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.2211 - val_loss: 0.2932\n",
      "Epoch 148/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.2194 - val_loss: 0.2894\n",
      "Epoch 149/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.2190 - val_loss: 0.2908\n",
      "Epoch 150/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.2179 - val_loss: 0.2823\n",
      "Epoch 151/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.2181 - val_loss: 0.2934\n",
      "Epoch 152/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.2173 - val_loss: 0.2793\n",
      "Epoch 153/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.2183 - val_loss: 0.2819\n",
      "Epoch 154/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.2157 - val_loss: 0.2867\n",
      "Epoch 155/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.2169 - val_loss: 0.2903\n",
      "Epoch 156/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.2145 - val_loss: 0.2830\n",
      "Epoch 157/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.2140 - val_loss: 0.2729\n",
      "Epoch 158/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.2140 - val_loss: 0.2831\n",
      "Epoch 159/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.2169 - val_loss: 0.3035\n",
      "Epoch 160/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.2155 - val_loss: 0.2757\n",
      "Epoch 161/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.2138 - val_loss: 0.2803\n",
      "Epoch 162/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.2135 - val_loss: 0.2749\n",
      "Epoch 163/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.2125 - val_loss: 0.2836\n",
      "Epoch 164/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.2133 - val_loss: 0.2830\n",
      "Epoch 165/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.2116 - val_loss: 0.2736\n",
      "Epoch 166/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.2129 - val_loss: 0.2759\n",
      "Epoch 167/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.2118 - val_loss: 0.2798\n",
      "Epoch 168/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.2117 - val_loss: 0.2735\n",
      "Epoch 169/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.2101 - val_loss: 0.2752\n",
      "Epoch 170/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.2099 - val_loss: 0.2753\n",
      "Epoch 171/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.2100 - val_loss: 0.2759\n",
      "Epoch 172/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.2094 - val_loss: 0.2838\n",
      "Epoch 173/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.2090 - val_loss: 0.2763\n",
      "Epoch 174/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.2104 - val_loss: 0.2703\n",
      "Epoch 175/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.2138 - val_loss: 0.2769\n",
      "Epoch 176/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.3115 - val_loss: 0.3720\n",
      "Epoch 177/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.2968 - val_loss: 0.4387\n",
      "Epoch 178/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.3790 - val_loss: 0.4276\n",
      "Epoch 179/1000\n",
      "61/61 [==============================] - 2s 31ms/step - loss: 0.3167 - val_loss: 0.3991\n",
      "Epoch 180/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.2733 - val_loss: 0.3347\n",
      "Epoch 181/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.2419 - val_loss: 0.3089\n",
      "Epoch 182/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.2304 - val_loss: 0.2907\n",
      "Epoch 183/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.2271 - val_loss: 0.2875\n",
      "Epoch 184/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.2181 - val_loss: 0.2864\n",
      "Epoch 185/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.2183 - val_loss: 0.2869\n",
      "Epoch 186/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.2181 - val_loss: 0.2774\n",
      "Epoch 187/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.2148 - val_loss: 0.2762\n",
      "Epoch 188/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.2137 - val_loss: 0.2726\n",
      "Epoch 189/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.2117 - val_loss: 0.2736\n",
      "Epoch 190/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.2106 - val_loss: 0.2681\n",
      "Epoch 191/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.2077 - val_loss: 0.2736\n",
      "Epoch 192/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.2097 - val_loss: 0.2633\n",
      "Epoch 193/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.2106 - val_loss: 0.2625\n",
      "Epoch 194/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.2084 - val_loss: 0.2676\n",
      "Epoch 195/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.2089 - val_loss: 0.2638\n",
      "Epoch 196/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.2090 - val_loss: 0.2710\n",
      "Epoch 197/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.2082 - val_loss: 0.2767\n",
      "Epoch 198/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.2063 - val_loss: 0.2667\n",
      "Epoch 199/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.2061 - val_loss: 0.2687\n",
      "Epoch 200/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.2063 - val_loss: 0.2708\n",
      "Epoch 201/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.2047 - val_loss: 0.2604\n",
      "Epoch 202/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.2048 - val_loss: 0.2598\n",
      "Epoch 203/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.2037 - val_loss: 0.2591\n",
      "Epoch 204/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.2033 - val_loss: 0.2587\n",
      "Epoch 205/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.2040 - val_loss: 0.2610\n",
      "Epoch 206/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.2030 - val_loss: 0.2577\n",
      "Epoch 207/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.2030 - val_loss: 0.2538\n",
      "Epoch 208/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.2018 - val_loss: 0.2521\n",
      "Epoch 209/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.2024 - val_loss: 0.2638\n",
      "Epoch 210/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.2026 - val_loss: 0.2556\n",
      "Epoch 211/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.2011 - val_loss: 0.2550\n",
      "Epoch 212/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.2014 - val_loss: 0.2500\n",
      "Epoch 213/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.2010 - val_loss: 0.2527\n",
      "Epoch 214/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.2018 - val_loss: 0.2496\n",
      "Epoch 215/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.2030 - val_loss: 0.2540\n",
      "Epoch 216/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.2087 - val_loss: 0.2590\n",
      "Epoch 217/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.2098 - val_loss: 0.2930\n",
      "Epoch 218/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.2086 - val_loss: 0.2736\n",
      "Epoch 219/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.2033 - val_loss: 0.2731\n",
      "Epoch 220/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.2000 - val_loss: 0.2746\n",
      "Epoch 221/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.2012 - val_loss: 0.2533\n",
      "Epoch 222/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.1983 - val_loss: 0.2644\n",
      "Epoch 223/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.2007 - val_loss: 0.2484\n",
      "Epoch 224/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.1993 - val_loss: 0.2498\n",
      "Epoch 225/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.2003 - val_loss: 0.2601\n",
      "Epoch 226/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.1985 - val_loss: 0.2520\n",
      "Epoch 227/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.1988 - val_loss: 0.2436\n",
      "Epoch 228/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.1996 - val_loss: 0.2665\n",
      "Epoch 229/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.2023 - val_loss: 0.2495\n",
      "Epoch 230/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.1983 - val_loss: 0.2455\n",
      "Epoch 231/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.1981 - val_loss: 0.2561\n",
      "Epoch 232/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.1989 - val_loss: 0.2435\n",
      "Epoch 233/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.1996 - val_loss: 0.2502\n",
      "Epoch 234/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.2008 - val_loss: 0.2501\n",
      "Epoch 235/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.1983 - val_loss: 0.2449\n",
      "Epoch 236/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.1976 - val_loss: 0.2406\n",
      "Epoch 237/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.1965 - val_loss: 0.2432\n",
      "Epoch 238/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.1971 - val_loss: 0.2410\n",
      "Epoch 239/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.1957 - val_loss: 0.2412\n",
      "Epoch 240/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.1979 - val_loss: 0.2434\n",
      "Epoch 241/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.1959 - val_loss: 0.2448\n",
      "Epoch 242/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.1950 - val_loss: 0.2373\n",
      "Epoch 243/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.1958 - val_loss: 0.2452\n",
      "Epoch 244/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.1967 - val_loss: 0.2474\n",
      "Epoch 245/1000\n",
      "61/61 [==============================] - 2s 31ms/step - loss: 0.1967 - val_loss: 0.2480\n",
      "Epoch 246/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.1944 - val_loss: 0.2393\n",
      "Epoch 247/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.1974 - val_loss: 0.2468\n",
      "Epoch 248/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.1947 - val_loss: 0.2378\n",
      "Epoch 249/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.1944 - val_loss: 0.2448\n",
      "Epoch 250/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.1945 - val_loss: 0.2369\n",
      "Epoch 251/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.1941 - val_loss: 0.2312\n",
      "Epoch 252/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.1954 - val_loss: 0.2380\n",
      "Epoch 253/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.1940 - val_loss: 0.2365\n",
      "Epoch 254/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.1956 - val_loss: 0.2427\n",
      "Epoch 255/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.1991 - val_loss: 0.2897\n",
      "Epoch 256/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.2092 - val_loss: 0.2465\n",
      "Epoch 257/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.1991 - val_loss: 0.2526\n",
      "Epoch 258/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.1962 - val_loss: 0.2492\n",
      "Epoch 259/1000\n",
      "61/61 [==============================] - 2s 28ms/step - loss: 0.1939 - val_loss: 0.2405\n",
      "Epoch 260/1000\n",
      "61/61 [==============================] - 2s 28ms/step - loss: 0.1934 - val_loss: 0.2434\n",
      "Epoch 261/1000\n",
      "61/61 [==============================] - 2s 28ms/step - loss: 0.1925 - val_loss: 0.2376\n",
      "Epoch 262/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.1912 - val_loss: 0.2346\n",
      "Epoch 263/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.1960 - val_loss: 0.2423\n",
      "Epoch 264/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.1955 - val_loss: 0.2343\n",
      "Epoch 265/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.1914 - val_loss: 0.2361\n",
      "Epoch 266/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.1915 - val_loss: 0.2318\n",
      "Epoch 267/1000\n",
      "61/61 [==============================] - 2s 28ms/step - loss: 0.1914 - val_loss: 0.2369\n",
      "Epoch 268/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.1913 - val_loss: 0.2318\n",
      "Epoch 269/1000\n",
      "61/61 [==============================] - 2s 28ms/step - loss: 0.1927 - val_loss: 0.2458\n",
      "Epoch 270/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.1915 - val_loss: 0.2371\n",
      "Epoch 271/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.1900 - val_loss: 0.2320\n",
      "Epoch 272/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.1908 - val_loss: 0.2300\n",
      "Epoch 273/1000\n",
      "61/61 [==============================] - 2s 28ms/step - loss: 0.1902 - val_loss: 0.2348\n",
      "Epoch 274/1000\n",
      "61/61 [==============================] - 2s 28ms/step - loss: 0.1897 - val_loss: 0.2355\n",
      "Epoch 275/1000\n",
      "61/61 [==============================] - 2s 28ms/step - loss: 0.1909 - val_loss: 0.2365\n",
      "Epoch 276/1000\n",
      "61/61 [==============================] - 2s 28ms/step - loss: 0.1904 - val_loss: 0.2258\n",
      "Epoch 277/1000\n",
      "61/61 [==============================] - 2s 28ms/step - loss: 0.1894 - val_loss: 0.2302\n",
      "Epoch 278/1000\n",
      "61/61 [==============================] - 2s 28ms/step - loss: 0.1907 - val_loss: 0.2245\n",
      "Epoch 279/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.1998 - val_loss: 0.3328\n",
      "Epoch 280/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.2252 - val_loss: 0.2684\n",
      "Epoch 281/1000\n",
      "61/61 [==============================] - 2s 28ms/step - loss: 0.2125 - val_loss: 0.2785\n",
      "Epoch 282/1000\n",
      "61/61 [==============================] - 2s 28ms/step - loss: 0.2013 - val_loss: 0.2550\n",
      "Epoch 283/1000\n",
      "61/61 [==============================] - 2s 28ms/step - loss: 0.1980 - val_loss: 0.2515\n",
      "Epoch 284/1000\n",
      "61/61 [==============================] - 2s 28ms/step - loss: 0.1942 - val_loss: 0.2396\n",
      "Epoch 285/1000\n",
      "61/61 [==============================] - 2s 28ms/step - loss: 0.1919 - val_loss: 0.2383\n",
      "Epoch 286/1000\n",
      "61/61 [==============================] - 2s 28ms/step - loss: 0.1897 - val_loss: 0.2332\n",
      "Epoch 287/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.1890 - val_loss: 0.2325\n",
      "Epoch 288/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.1896 - val_loss: 0.2339\n",
      "Epoch 289/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.1895 - val_loss: 0.2289\n",
      "Epoch 290/1000\n",
      "61/61 [==============================] - 2s 28ms/step - loss: 0.1884 - val_loss: 0.2309\n",
      "Epoch 291/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.1907 - val_loss: 0.2280\n",
      "Epoch 292/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.1895 - val_loss: 0.2298\n",
      "Epoch 293/1000\n",
      "61/61 [==============================] - 2s 28ms/step - loss: 0.1897 - val_loss: 0.2318\n",
      "Epoch 294/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.1886 - val_loss: 0.2271\n",
      "Epoch 295/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.1886 - val_loss: 0.2282\n",
      "Epoch 296/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.1878 - val_loss: 0.2293\n",
      "Epoch 297/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.1862 - val_loss: 0.2249\n",
      "Epoch 298/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.1871 - val_loss: 0.2231\n",
      "Epoch 299/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.1867 - val_loss: 0.2234\n",
      "Epoch 300/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.1872 - val_loss: 0.2258\n",
      "Epoch 301/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.1850 - val_loss: 0.2245\n",
      "Epoch 302/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.1862 - val_loss: 0.2282\n",
      "Epoch 303/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.1877 - val_loss: 0.2292\n",
      "Epoch 304/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.1870 - val_loss: 0.2352\n",
      "Epoch 305/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.1862 - val_loss: 0.2259\n",
      "Epoch 306/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.1858 - val_loss: 0.2276\n",
      "Epoch 307/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.1851 - val_loss: 0.2252\n",
      "Epoch 308/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.1858 - val_loss: 0.2172\n",
      "Epoch 309/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.2134 - val_loss: 0.3341\n",
      "Epoch 310/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.2782 - val_loss: 0.4204\n",
      "Epoch 311/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.2550 - val_loss: 0.3081\n",
      "Epoch 312/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.2104 - val_loss: 0.2651\n",
      "Epoch 313/1000\n",
      "61/61 [==============================] - 2s 31ms/step - loss: 0.1980 - val_loss: 0.2620\n",
      "Epoch 314/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.1942 - val_loss: 0.2430\n",
      "Epoch 315/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.1917 - val_loss: 0.2467\n",
      "Epoch 316/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.1902 - val_loss: 0.2362\n",
      "Epoch 317/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.1886 - val_loss: 0.2336\n",
      "Epoch 318/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.1883 - val_loss: 0.2381\n",
      "Epoch 319/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.1887 - val_loss: 0.2297\n",
      "Epoch 320/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.1871 - val_loss: 0.2338\n",
      "Epoch 321/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.1865 - val_loss: 0.2339\n",
      "Epoch 322/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.1855 - val_loss: 0.2333\n",
      "Epoch 323/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.1854 - val_loss: 0.2334\n",
      "Epoch 324/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.1846 - val_loss: 0.2296\n",
      "Epoch 325/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.1853 - val_loss: 0.2251\n",
      "Epoch 326/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.1840 - val_loss: 0.2254\n",
      "Epoch 327/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.1834 - val_loss: 0.2205\n",
      "Epoch 328/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.1848 - val_loss: 0.2310\n",
      "Epoch 329/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.1832 - val_loss: 0.2222\n",
      "Epoch 330/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.1851 - val_loss: 0.2282\n",
      "Epoch 331/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.1833 - val_loss: 0.2263\n",
      "Epoch 332/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.1833 - val_loss: 0.2260\n",
      "Epoch 333/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.1838 - val_loss: 0.2212\n",
      "Epoch 334/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.1831 - val_loss: 0.2193\n",
      "Epoch 335/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.1830 - val_loss: 0.2231\n",
      "Epoch 336/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.1833 - val_loss: 0.2175\n",
      "Epoch 337/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.1830 - val_loss: 0.2204\n",
      "Epoch 338/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.1822 - val_loss: 0.2175\n",
      "Epoch 339/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.1811 - val_loss: 0.2158\n",
      "Epoch 340/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.1832 - val_loss: 0.2222\n",
      "Epoch 341/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.1829 - val_loss: 0.2167\n",
      "Epoch 342/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.1828 - val_loss: 0.2204\n",
      "Epoch 343/1000\n",
      "61/61 [==============================] - 2s 28ms/step - loss: 0.1828 - val_loss: 0.2223\n",
      "Epoch 344/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.1826 - val_loss: 0.2233\n",
      "Epoch 345/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.1826 - val_loss: 0.2245\n",
      "Epoch 346/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.1829 - val_loss: 0.2194\n",
      "Epoch 347/1000\n",
      "61/61 [==============================] - 2s 31ms/step - loss: 0.1821 - val_loss: 0.2218\n",
      "Epoch 348/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.1825 - val_loss: 0.2264\n",
      "Epoch 349/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.1819 - val_loss: 0.2244\n",
      "Epoch 350/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.1805 - val_loss: 0.2239\n",
      "Epoch 351/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.1821 - val_loss: 0.2098\n",
      "Epoch 352/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.1807 - val_loss: 0.2094\n",
      "Epoch 353/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.1819 - val_loss: 0.2115\n",
      "Epoch 354/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.1811 - val_loss: 0.2159\n",
      "Epoch 355/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.1816 - val_loss: 0.2098\n",
      "Epoch 356/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.1824 - val_loss: 0.2133\n",
      "Epoch 357/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.1809 - val_loss: 0.2145\n",
      "Epoch 358/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.1811 - val_loss: 0.2152\n",
      "Epoch 359/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.1809 - val_loss: 0.2129\n",
      "Epoch 360/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.1805 - val_loss: 0.2123\n",
      "Epoch 361/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.1803 - val_loss: 0.2100\n",
      "Epoch 362/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.1808 - val_loss: 0.2158\n",
      "Epoch 363/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.1796 - val_loss: 0.2128\n",
      "Epoch 364/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.1814 - val_loss: 0.2219\n",
      "Epoch 365/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.1812 - val_loss: 0.2195\n",
      "Epoch 366/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.1811 - val_loss: 0.2166\n",
      "Epoch 367/1000\n",
      "61/61 [==============================] - 2s 28ms/step - loss: 0.1813 - val_loss: 0.2248\n",
      "Epoch 368/1000\n",
      "61/61 [==============================] - 2s 28ms/step - loss: 0.1810 - val_loss: 0.2142\n",
      "Epoch 369/1000\n",
      "61/61 [==============================] - 2s 28ms/step - loss: 0.1814 - val_loss: 0.2176\n",
      "Epoch 370/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.1802 - val_loss: 0.2091\n",
      "Epoch 371/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.1804 - val_loss: 0.2270\n",
      "Epoch 372/1000\n",
      "61/61 [==============================] - 2s 28ms/step - loss: 0.1828 - val_loss: 0.2397\n",
      "Epoch 373/1000\n",
      "61/61 [==============================] - 2s 28ms/step - loss: 0.1860 - val_loss: 0.2230\n",
      "Epoch 374/1000\n",
      "61/61 [==============================] - 2s 28ms/step - loss: 0.1809 - val_loss: 0.2215\n",
      "Epoch 375/1000\n",
      "61/61 [==============================] - 2s 28ms/step - loss: 0.1801 - val_loss: 0.2214\n",
      "Epoch 376/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.1805 - val_loss: 0.2169\n",
      "Epoch 377/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.1799 - val_loss: 0.2122\n",
      "Epoch 378/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.1805 - val_loss: 0.2135\n",
      "Epoch 379/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.1793 - val_loss: 0.2134\n",
      "Epoch 380/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.1786 - val_loss: 0.2143\n",
      "Epoch 381/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.1792 - val_loss: 0.2087\n",
      "Epoch 382/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.1792 - val_loss: 0.2191\n",
      "Epoch 383/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.1799 - val_loss: 0.2178\n",
      "Epoch 384/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.1793 - val_loss: 0.2175\n",
      "Epoch 385/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.1786 - val_loss: 0.2130\n",
      "Epoch 386/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.1789 - val_loss: 0.2085\n",
      "Epoch 387/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.1788 - val_loss: 0.2082\n",
      "Epoch 388/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.1796 - val_loss: 0.2125\n",
      "Epoch 389/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.1790 - val_loss: 0.2061\n",
      "Epoch 390/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.1789 - val_loss: 0.2094\n",
      "Epoch 391/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.1793 - val_loss: 0.2088\n",
      "Epoch 392/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.1777 - val_loss: 0.2064\n",
      "Epoch 393/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.1785 - val_loss: 0.2052\n",
      "Epoch 394/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.1790 - val_loss: 0.2062\n",
      "Epoch 395/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.1785 - val_loss: 0.2114\n",
      "Epoch 396/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.1788 - val_loss: 0.2127\n",
      "Epoch 397/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.1799 - val_loss: 0.2087\n",
      "Epoch 398/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.1778 - val_loss: 0.2020\n",
      "Epoch 399/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.1787 - val_loss: 0.2113\n",
      "Epoch 400/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.1780 - val_loss: 0.2120\n",
      "Epoch 401/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.1779 - val_loss: 0.2061\n",
      "Epoch 402/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.1781 - val_loss: 0.1983\n",
      "Epoch 403/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.1779 - val_loss: 0.2028\n",
      "Epoch 404/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.1776 - val_loss: 0.2026\n",
      "Epoch 405/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.1768 - val_loss: 0.2057\n",
      "Epoch 406/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.1771 - val_loss: 0.2041\n",
      "Epoch 407/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.1777 - val_loss: 0.2027\n",
      "Epoch 408/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.1772 - val_loss: 0.2103\n",
      "Epoch 409/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.1773 - val_loss: 0.2079\n",
      "Epoch 410/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.1778 - val_loss: 0.2060\n",
      "Epoch 411/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.1763 - val_loss: 0.2055\n",
      "Epoch 412/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.1765 - val_loss: 0.2132\n",
      "Epoch 413/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.1763 - val_loss: 0.2037\n",
      "Epoch 414/1000\n",
      "61/61 [==============================] - 2s 31ms/step - loss: 0.1760 - val_loss: 0.2072\n",
      "Epoch 415/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.1785 - val_loss: 0.2086\n",
      "Epoch 416/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.1777 - val_loss: 0.2131\n",
      "Epoch 417/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.1771 - val_loss: 0.2125\n",
      "Epoch 418/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.1768 - val_loss: 0.2044\n",
      "Epoch 419/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.1756 - val_loss: 0.1965\n",
      "Epoch 420/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.1763 - val_loss: 0.2020\n",
      "Epoch 421/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.1775 - val_loss: 0.2067\n",
      "Epoch 422/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.1756 - val_loss: 0.2126\n",
      "Epoch 423/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.1765 - val_loss: 0.2076\n",
      "Epoch 424/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.1768 - val_loss: 0.2073\n",
      "Epoch 425/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.1765 - val_loss: 0.2136\n",
      "Epoch 426/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.1750 - val_loss: 0.2106\n",
      "Epoch 427/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.1759 - val_loss: 0.2086\n",
      "Epoch 428/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.1765 - val_loss: 0.2043\n",
      "Epoch 429/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.1756 - val_loss: 0.2067\n",
      "Epoch 430/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.1764 - val_loss: 0.2092\n",
      "Epoch 431/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.1751 - val_loss: 0.2012\n",
      "Epoch 432/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.1754 - val_loss: 0.2091\n",
      "Epoch 433/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.1754 - val_loss: 0.2056\n",
      "Epoch 434/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.1760 - val_loss: 0.2064\n",
      "Epoch 435/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.1755 - val_loss: 0.2096\n",
      "Epoch 436/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.1760 - val_loss: 0.2043\n",
      "Epoch 437/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.1754 - val_loss: 0.2109\n",
      "Epoch 438/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.1766 - val_loss: 0.2005\n",
      "Epoch 439/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.1760 - val_loss: 0.2034\n",
      "Epoch 440/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.1751 - val_loss: 0.2003\n",
      "Epoch 441/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.1750 - val_loss: 0.2086\n",
      "Epoch 442/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.1740 - val_loss: 0.1999\n",
      "Epoch 443/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.1741 - val_loss: 0.2000\n",
      "Epoch 444/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.1744 - val_loss: 0.2094\n",
      "Epoch 445/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.1746 - val_loss: 0.2028\n",
      "Epoch 446/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.1744 - val_loss: 0.1976\n",
      "Epoch 447/1000\n",
      "61/61 [==============================] - 2s 31ms/step - loss: 0.1737 - val_loss: 0.2033\n",
      "Epoch 448/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.1739 - val_loss: 0.2017\n",
      "Epoch 449/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.1740 - val_loss: 0.2050\n",
      "Epoch 450/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.1751 - val_loss: 0.2037\n",
      "Epoch 451/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.1750 - val_loss: 0.2142\n",
      "Epoch 452/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.1737 - val_loss: 0.2068\n",
      "Epoch 453/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.1747 - val_loss: 0.2029\n",
      "Epoch 454/1000\n",
      "61/61 [==============================] - ETA: 0s - loss: 0.1749Restoring model weights from the end of the best epoch: 419.\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.1749 - val_loss: 0.2041\n",
      "Epoch 454: early stopping\n",
      "7/7 [==============================] - 2s 22ms/step\n",
      "0.17484416890330798\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "52f86911d9514edd93f5f125d0529f88",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.067 MB of 0.067 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch/epoch</td><td>▁▁▁▁▁▂▂▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▅▅▅▅▅▅▅▆▆▆▆▆▆▆▇▇██</td></tr><tr><td>epoch/learning_rate</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>epoch/loss</td><td>█▄▄▃▃▂▂▂▂▂▁▁▁▁▁▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>epoch/val_loss</td><td>█▇▇▅▅▃▃▃▂▂▂▃▂▂▂▁▂▂▁▁▂▁▁▁▃▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>rmase_prediction</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch/epoch</td><td>453</td></tr><tr><td>epoch/learning_rate</td><td>0.00049</td></tr><tr><td>epoch/loss</td><td>0.17489</td></tr><tr><td>epoch/val_loss</td><td>0.20407</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">test_4</strong> at: <a href='https://wandb.ai/uu13234-none/sgnate_skate-keras/runs/e9gziq6y' target=\"_blank\">https://wandb.ai/uu13234-none/sgnate_skate-keras/runs/e9gziq6y</a><br/> View project at: <a href='https://wandb.ai/uu13234-none/sgnate_skate-keras' target=\"_blank\">https://wandb.ai/uu13234-none/sgnate_skate-keras</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20241104_144631-e9gziq6y\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.18.3"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\sato\\Desktop\\python\\SIGNATE\\スケートボードの挙動予測\\code-analysis\\wandb\\run-20241104_150019-bdkuzf8q</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/uu13234-none/sgnate_skate-keras/runs/bdkuzf8q' target=\"_blank\">test_5</a></strong> to <a href='https://wandb.ai/uu13234-none/sgnate_skate-keras' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/uu13234-none/sgnate_skate-keras' target=\"_blank\">https://wandb.ai/uu13234-none/sgnate_skate-keras</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/uu13234-none/sgnate_skate-keras/runs/bdkuzf8q' target=\"_blank\">https://wandb.ai/uu13234-none/sgnate_skate-keras/runs/bdkuzf8q</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      " 6/61 [=>............................] - ETA: 1s - loss: 2.1311WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0253s vs `on_train_batch_end` time: 0.0338s). Check your callbacks.\n",
      "61/61 [==============================] - 8s 49ms/step - loss: 1.4943 - val_loss: 1.1706\n",
      "Epoch 2/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 1.0383 - val_loss: 1.0339\n",
      "Epoch 3/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.8924 - val_loss: 0.8821\n",
      "Epoch 4/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.7994 - val_loss: 0.8557\n",
      "Epoch 5/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.7699 - val_loss: 0.8125\n",
      "Epoch 6/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.7127 - val_loss: 0.7740\n",
      "Epoch 7/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.6842 - val_loss: 0.7713\n",
      "Epoch 8/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.6567 - val_loss: 0.7171\n",
      "Epoch 9/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.6320 - val_loss: 0.6664\n",
      "Epoch 10/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.6048 - val_loss: 0.7258\n",
      "Epoch 11/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.5763 - val_loss: 0.6612\n",
      "Epoch 12/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.5687 - val_loss: 0.6374\n",
      "Epoch 13/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.5583 - val_loss: 0.6675\n",
      "Epoch 14/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.5398 - val_loss: 0.6275\n",
      "Epoch 15/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.5150 - val_loss: 0.6542\n",
      "Epoch 16/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.5446 - val_loss: 0.6255\n",
      "Epoch 17/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.5111 - val_loss: 0.6438\n",
      "Epoch 18/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.4731 - val_loss: 0.5954\n",
      "Epoch 19/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.4523 - val_loss: 0.5656\n",
      "Epoch 20/1000\n",
      "61/61 [==============================] - 2s 31ms/step - loss: 0.4581 - val_loss: 0.5355\n",
      "Epoch 21/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.4341 - val_loss: 0.5502\n",
      "Epoch 22/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.4315 - val_loss: 0.5332\n",
      "Epoch 23/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.4258 - val_loss: 0.5621\n",
      "Epoch 24/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.4098 - val_loss: 0.5411\n",
      "Epoch 25/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.4312 - val_loss: 0.6502\n",
      "Epoch 26/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.4692 - val_loss: 0.5532\n",
      "Epoch 27/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.4451 - val_loss: 0.5737\n",
      "Epoch 28/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.4252 - val_loss: 0.5339\n",
      "Epoch 29/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.4061 - val_loss: 0.5107\n",
      "Epoch 30/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.3774 - val_loss: 0.4885\n",
      "Epoch 31/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.3682 - val_loss: 0.4883\n",
      "Epoch 32/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.3776 - val_loss: 0.4791\n",
      "Epoch 33/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.3611 - val_loss: 0.4491\n",
      "Epoch 34/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.3755 - val_loss: 0.5224\n",
      "Epoch 35/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.4327 - val_loss: 0.5762\n",
      "Epoch 36/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.4031 - val_loss: 0.4781\n",
      "Epoch 37/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.3632 - val_loss: 0.4738\n",
      "Epoch 38/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.3492 - val_loss: 0.4499\n",
      "Epoch 39/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.3563 - val_loss: 0.5138\n",
      "Epoch 40/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.4115 - val_loss: 0.5353\n",
      "Epoch 41/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.3919 - val_loss: 0.4849\n",
      "Epoch 42/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.3509 - val_loss: 0.4413\n",
      "Epoch 43/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.3288 - val_loss: 0.4314\n",
      "Epoch 44/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.3193 - val_loss: 0.4246\n",
      "Epoch 45/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.3218 - val_loss: 0.4573\n",
      "Epoch 46/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.3136 - val_loss: 0.4214\n",
      "Epoch 47/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.3071 - val_loss: 0.4086\n",
      "Epoch 48/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.3037 - val_loss: 0.4185\n",
      "Epoch 49/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.2996 - val_loss: 0.4112\n",
      "Epoch 50/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.2952 - val_loss: 0.4079\n",
      "Epoch 51/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.2945 - val_loss: 0.4172\n",
      "Epoch 52/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.2917 - val_loss: 0.4067\n",
      "Epoch 53/1000\n",
      "61/61 [==============================] - 2s 31ms/step - loss: 0.2875 - val_loss: 0.3978\n",
      "Epoch 54/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.2896 - val_loss: 0.3899\n",
      "Epoch 55/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.2836 - val_loss: 0.4074\n",
      "Epoch 56/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.2844 - val_loss: 0.3820\n",
      "Epoch 57/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.2803 - val_loss: 0.3996\n",
      "Epoch 58/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.2821 - val_loss: 0.4275\n",
      "Epoch 59/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.2783 - val_loss: 0.3850\n",
      "Epoch 60/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.2747 - val_loss: 0.3815\n",
      "Epoch 61/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.2718 - val_loss: 0.3795\n",
      "Epoch 62/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.2713 - val_loss: 0.3889\n",
      "Epoch 63/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.2680 - val_loss: 0.3953\n",
      "Epoch 64/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.2657 - val_loss: 0.3754\n",
      "Epoch 65/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.2657 - val_loss: 0.3799\n",
      "Epoch 66/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.2676 - val_loss: 0.4002\n",
      "Epoch 67/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.2692 - val_loss: 0.3799\n",
      "Epoch 68/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.3215 - val_loss: 0.4141\n",
      "Epoch 69/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.2947 - val_loss: 0.3859\n",
      "Epoch 70/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.2705 - val_loss: 0.3746\n",
      "Epoch 71/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.2666 - val_loss: 0.3578\n",
      "Epoch 72/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.2599 - val_loss: 0.3563\n",
      "Epoch 73/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.2596 - val_loss: 0.3573\n",
      "Epoch 74/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.2572 - val_loss: 0.3556\n",
      "Epoch 75/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.2572 - val_loss: 0.3481\n",
      "Epoch 76/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.2541 - val_loss: 0.3593\n",
      "Epoch 77/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.2516 - val_loss: 0.3393\n",
      "Epoch 78/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.2526 - val_loss: 0.3466\n",
      "Epoch 79/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.2513 - val_loss: 0.3469\n",
      "Epoch 80/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.2484 - val_loss: 0.3736\n",
      "Epoch 81/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.2544 - val_loss: 0.3678\n",
      "Epoch 82/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.2514 - val_loss: 0.3376\n",
      "Epoch 83/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.2467 - val_loss: 0.3370\n",
      "Epoch 84/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.2468 - val_loss: 0.3432\n",
      "Epoch 85/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.2501 - val_loss: 0.3352\n",
      "Epoch 86/1000\n",
      "61/61 [==============================] - 2s 31ms/step - loss: 0.2447 - val_loss: 0.3360\n",
      "Epoch 87/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.2413 - val_loss: 0.3343\n",
      "Epoch 88/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.2409 - val_loss: 0.3393\n",
      "Epoch 89/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.2440 - val_loss: 0.3392\n",
      "Epoch 90/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.2388 - val_loss: 0.3451\n",
      "Epoch 91/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.2382 - val_loss: 0.3421\n",
      "Epoch 92/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.2410 - val_loss: 0.3248\n",
      "Epoch 93/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.2375 - val_loss: 0.3332\n",
      "Epoch 94/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.2405 - val_loss: 0.3299\n",
      "Epoch 95/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.2372 - val_loss: 0.3349\n",
      "Epoch 96/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.2384 - val_loss: 0.3301\n",
      "Epoch 97/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.2377 - val_loss: 0.3268\n",
      "Epoch 98/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.2383 - val_loss: 0.3499\n",
      "Epoch 99/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.4194 - val_loss: 0.5362\n",
      "Epoch 100/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.3313 - val_loss: 0.4194\n",
      "Epoch 101/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.2964 - val_loss: 0.3846\n",
      "Epoch 102/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.4234 - val_loss: 0.6611\n",
      "Epoch 103/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.4657 - val_loss: 0.5444\n",
      "Epoch 104/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.3361 - val_loss: 0.4271\n",
      "Epoch 105/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.3011 - val_loss: 0.3999\n",
      "Epoch 106/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.2785 - val_loss: 0.3704\n",
      "Epoch 107/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.2586 - val_loss: 0.3784\n",
      "Epoch 108/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.2493 - val_loss: 0.3492\n",
      "Epoch 109/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.2492 - val_loss: 0.3401\n",
      "Epoch 110/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.2475 - val_loss: 0.3441\n",
      "Epoch 111/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.2455 - val_loss: 0.3369\n",
      "Epoch 112/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.2401 - val_loss: 0.3446\n",
      "Epoch 113/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.2359 - val_loss: 0.3205\n",
      "Epoch 114/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.2350 - val_loss: 0.3222\n",
      "Epoch 115/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.2361 - val_loss: 0.3293\n",
      "Epoch 116/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.2318 - val_loss: 0.3328\n",
      "Epoch 117/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.2315 - val_loss: 0.3227\n",
      "Epoch 118/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.2295 - val_loss: 0.3253\n",
      "Epoch 119/1000\n",
      "61/61 [==============================] - 2s 31ms/step - loss: 0.2287 - val_loss: 0.3178\n",
      "Epoch 120/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.2308 - val_loss: 0.3101\n",
      "Epoch 121/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.2261 - val_loss: 0.3203\n",
      "Epoch 122/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.2236 - val_loss: 0.3089\n",
      "Epoch 123/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.2261 - val_loss: 0.3119\n",
      "Epoch 124/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.2243 - val_loss: 0.3160\n",
      "Epoch 125/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.2218 - val_loss: 0.3093\n",
      "Epoch 126/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.2215 - val_loss: 0.3032\n",
      "Epoch 127/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.2251 - val_loss: 0.3071\n",
      "Epoch 128/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.2208 - val_loss: 0.3107\n",
      "Epoch 129/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.2227 - val_loss: 0.3048\n",
      "Epoch 130/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.2238 - val_loss: 0.3102\n",
      "Epoch 131/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.2209 - val_loss: 0.3106\n",
      "Epoch 132/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.2227 - val_loss: 0.3000\n",
      "Epoch 133/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.2214 - val_loss: 0.3076\n",
      "Epoch 134/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.2177 - val_loss: 0.2986\n",
      "Epoch 135/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.2194 - val_loss: 0.2966\n",
      "Epoch 136/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.2182 - val_loss: 0.3040\n",
      "Epoch 137/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.2177 - val_loss: 0.2980\n",
      "Epoch 138/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.2178 - val_loss: 0.3010\n",
      "Epoch 139/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.2161 - val_loss: 0.2928\n",
      "Epoch 140/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.2172 - val_loss: 0.2931\n",
      "Epoch 141/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.2184 - val_loss: 0.2933\n",
      "Epoch 142/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.2164 - val_loss: 0.2971\n",
      "Epoch 143/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.2154 - val_loss: 0.2969\n",
      "Epoch 144/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.2143 - val_loss: 0.3117\n",
      "Epoch 145/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.2152 - val_loss: 0.3041\n",
      "Epoch 146/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.2141 - val_loss: 0.2868\n",
      "Epoch 147/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.2122 - val_loss: 0.2875\n",
      "Epoch 148/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.2140 - val_loss: 0.2969\n",
      "Epoch 149/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.2126 - val_loss: 0.3034\n",
      "Epoch 150/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.2145 - val_loss: 0.2962\n",
      "Epoch 151/1000\n",
      "61/61 [==============================] - 2s 28ms/step - loss: 0.2130 - val_loss: 0.3009\n",
      "Epoch 152/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.2142 - val_loss: 0.2899\n",
      "Epoch 153/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.2130 - val_loss: 0.2897\n",
      "Epoch 154/1000\n",
      "61/61 [==============================] - 2s 28ms/step - loss: 0.2118 - val_loss: 0.2889\n",
      "Epoch 155/1000\n",
      "61/61 [==============================] - 2s 28ms/step - loss: 0.2096 - val_loss: 0.2982\n",
      "Epoch 156/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.2224 - val_loss: 0.3154\n",
      "Epoch 157/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.2359 - val_loss: 0.3308\n",
      "Epoch 158/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.2202 - val_loss: 0.3017\n",
      "Epoch 159/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.2160 - val_loss: 0.3007\n",
      "Epoch 160/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.2122 - val_loss: 0.2895\n",
      "Epoch 161/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.2115 - val_loss: 0.2971\n",
      "Epoch 162/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.2119 - val_loss: 0.2848\n",
      "Epoch 163/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.2113 - val_loss: 0.2908\n",
      "Epoch 164/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.2099 - val_loss: 0.2908\n",
      "Epoch 165/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.2100 - val_loss: 0.2825\n",
      "Epoch 166/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.2093 - val_loss: 0.2834\n",
      "Epoch 167/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.2071 - val_loss: 0.2870\n",
      "Epoch 168/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.2080 - val_loss: 0.2744\n",
      "Epoch 169/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.2601 - val_loss: 0.4072\n",
      "Epoch 170/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.2511 - val_loss: 0.3126\n",
      "Epoch 171/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.2222 - val_loss: 0.2946\n",
      "Epoch 172/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.2164 - val_loss: 0.3003\n",
      "Epoch 173/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.2102 - val_loss: 0.2868\n",
      "Epoch 174/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.2073 - val_loss: 0.2894\n",
      "Epoch 175/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.2069 - val_loss: 0.2925\n",
      "Epoch 176/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.2048 - val_loss: 0.2841\n",
      "Epoch 177/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.2046 - val_loss: 0.2959\n",
      "Epoch 178/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.2054 - val_loss: 0.2806\n",
      "Epoch 179/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.2057 - val_loss: 0.2697\n",
      "Epoch 180/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.2039 - val_loss: 0.3024\n",
      "Epoch 181/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.2039 - val_loss: 0.2845\n",
      "Epoch 182/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.2034 - val_loss: 0.2942\n",
      "Epoch 183/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.2041 - val_loss: 0.2793\n",
      "Epoch 184/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.2027 - val_loss: 0.2821\n",
      "Epoch 185/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.2028 - val_loss: 0.2784\n",
      "Epoch 186/1000\n",
      "61/61 [==============================] - 2s 31ms/step - loss: 0.2012 - val_loss: 0.2842\n",
      "Epoch 187/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.2021 - val_loss: 0.2804\n",
      "Epoch 188/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.2021 - val_loss: 0.2744\n",
      "Epoch 189/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.2009 - val_loss: 0.2753\n",
      "Epoch 190/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.2014 - val_loss: 0.2847\n",
      "Epoch 191/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.2015 - val_loss: 0.2777\n",
      "Epoch 192/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.2023 - val_loss: 0.2741\n",
      "Epoch 193/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.2031 - val_loss: 0.2787\n",
      "Epoch 194/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.2029 - val_loss: 0.2769\n",
      "Epoch 195/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.2011 - val_loss: 0.2693\n",
      "Epoch 196/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.2011 - val_loss: 0.2782\n",
      "Epoch 197/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.2011 - val_loss: 0.2737\n",
      "Epoch 198/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.2028 - val_loss: 0.2797\n",
      "Epoch 199/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.2009 - val_loss: 0.2846\n",
      "Epoch 200/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.1998 - val_loss: 0.2722\n",
      "Epoch 201/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.1983 - val_loss: 0.2678\n",
      "Epoch 202/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.1986 - val_loss: 0.2777\n",
      "Epoch 203/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.1987 - val_loss: 0.2861\n",
      "Epoch 204/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.2003 - val_loss: 0.2712\n",
      "Epoch 205/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.1992 - val_loss: 0.2811\n",
      "Epoch 206/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.1974 - val_loss: 0.2661\n",
      "Epoch 207/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.1972 - val_loss: 0.2733\n",
      "Epoch 208/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.1986 - val_loss: 0.2645\n",
      "Epoch 209/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.1974 - val_loss: 0.2730\n",
      "Epoch 210/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.1976 - val_loss: 0.2815\n",
      "Epoch 211/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.1976 - val_loss: 0.2757\n",
      "Epoch 212/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.1962 - val_loss: 0.2712\n",
      "Epoch 213/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.2007 - val_loss: 0.2884\n",
      "Epoch 214/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.2014 - val_loss: 0.2755\n",
      "Epoch 215/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.1973 - val_loss: 0.2756\n",
      "Epoch 216/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.2302 - val_loss: 0.3163\n",
      "Epoch 217/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.2736 - val_loss: 0.4492\n",
      "Epoch 218/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.4117 - val_loss: 0.5348\n",
      "Epoch 219/1000\n",
      "61/61 [==============================] - 2s 31ms/step - loss: 0.3430 - val_loss: 0.5265\n",
      "Epoch 220/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.3160 - val_loss: 0.4087\n",
      "Epoch 221/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.2567 - val_loss: 0.3503\n",
      "Epoch 222/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.3656 - val_loss: 0.4553\n",
      "Epoch 223/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.2988 - val_loss: 0.3657\n",
      "Epoch 224/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.2566 - val_loss: 0.3388\n",
      "Epoch 225/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.2374 - val_loss: 0.3146\n",
      "Epoch 226/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.2290 - val_loss: 0.3048\n",
      "Epoch 227/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.2198 - val_loss: 0.3026\n",
      "Epoch 228/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.2158 - val_loss: 0.2924\n",
      "Epoch 229/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.2121 - val_loss: 0.2966\n",
      "Epoch 230/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.2117 - val_loss: 0.2879\n",
      "Epoch 231/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.2105 - val_loss: 0.2885\n",
      "Epoch 232/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.2083 - val_loss: 0.2808\n",
      "Epoch 233/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.2063 - val_loss: 0.2840\n",
      "Epoch 234/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.2044 - val_loss: 0.2799\n",
      "Epoch 235/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.2047 - val_loss: 0.2737\n",
      "Epoch 236/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.2021 - val_loss: 0.2815\n",
      "Epoch 237/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.2007 - val_loss: 0.2786\n",
      "Epoch 238/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.2015 - val_loss: 0.2757\n",
      "Epoch 239/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.2006 - val_loss: 0.2766\n",
      "Epoch 240/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.1997 - val_loss: 0.2707\n",
      "Epoch 241/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.1995 - val_loss: 0.2736\n",
      "Epoch 242/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.1981 - val_loss: 0.2712\n",
      "Epoch 243/1000\n",
      "59/61 [============================>.] - ETA: 0s - loss: 0.1991Restoring model weights from the end of the best epoch: 208.\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.1987 - val_loss: 0.2696\n",
      "Epoch 243: early stopping\n",
      "7/7 [==============================] - 1s 10ms/step\n",
      "0.22205591554231668\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "42a695b2be91412bb46d8f4678a5f2d2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.038 MB of 0.038 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch/epoch</td><td>▁▁▁▁▂▂▂▂▃▃▃▃▃▃▃▄▄▄▄▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇▇▇▇███</td></tr><tr><td>epoch/learning_rate</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>epoch/loss</td><td>█▆▆▆▆▆▆▅▅▅▆▄▃▃▂▂▇▄▃▂▂▂▂▂▂▁▁▁▁▁▂▁▁▁▁▁▁▁▂▁</td></tr><tr><td>epoch/val_loss</td><td>█▆▅▅▄▄▄▄▄▄▃▃▃▃▃█▃▄▃▃▂▂▂▂▂▁▂▂▁▁▁▁▁▁▁▂▂▁▁▁</td></tr><tr><td>rmase_prediction</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch/epoch</td><td>242</td></tr><tr><td>epoch/learning_rate</td><td>0.00049</td></tr><tr><td>epoch/loss</td><td>0.19866</td></tr><tr><td>epoch/val_loss</td><td>0.26959</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">test_5</strong> at: <a href='https://wandb.ai/uu13234-none/sgnate_skate-keras/runs/bdkuzf8q' target=\"_blank\">https://wandb.ai/uu13234-none/sgnate_skate-keras/runs/bdkuzf8q</a><br/> View project at: <a href='https://wandb.ai/uu13234-none/sgnate_skate-keras' target=\"_blank\">https://wandb.ai/uu13234-none/sgnate_skate-keras</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20241104_150019-bdkuzf8q\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.18.3"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\sato\\Desktop\\python\\SIGNATE\\スケートボードの挙動予測\\code-analysis\\wandb\\run-20241104_150748-gjnj77gw</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/uu13234-none/sgnate_skate-keras/runs/gjnj77gw' target=\"_blank\">test_6</a></strong> to <a href='https://wandb.ai/uu13234-none/sgnate_skate-keras' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/uu13234-none/sgnate_skate-keras' target=\"_blank\">https://wandb.ai/uu13234-none/sgnate_skate-keras</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/uu13234-none/sgnate_skate-keras/runs/gjnj77gw' target=\"_blank\">https://wandb.ai/uu13234-none/sgnate_skate-keras/runs/gjnj77gw</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "61/61 [==============================] - 8s 49ms/step - loss: 1.4695 - val_loss: 1.3663\n",
      "Epoch 2/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 1.0070 - val_loss: 1.0101\n",
      "Epoch 3/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.9259 - val_loss: 0.9493\n",
      "Epoch 4/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.8971 - val_loss: 0.9115\n",
      "Epoch 5/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.7768 - val_loss: 0.7936\n",
      "Epoch 6/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.7640 - val_loss: 0.7642\n",
      "Epoch 7/1000\n",
      "61/61 [==============================] - 2s 28ms/step - loss: 0.6982 - val_loss: 0.6650\n",
      "Epoch 8/1000\n",
      "61/61 [==============================] - 2s 28ms/step - loss: 0.6731 - val_loss: 0.6581\n",
      "Epoch 9/1000\n",
      "61/61 [==============================] - 2s 28ms/step - loss: 0.6348 - val_loss: 0.6224\n",
      "Epoch 10/1000\n",
      "61/61 [==============================] - 2s 28ms/step - loss: 0.6192 - val_loss: 0.6503\n",
      "Epoch 11/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.5785 - val_loss: 0.5982\n",
      "Epoch 12/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.5774 - val_loss: 0.6247\n",
      "Epoch 13/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.5642 - val_loss: 0.5907\n",
      "Epoch 14/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.5478 - val_loss: 0.6452\n",
      "Epoch 15/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.5536 - val_loss: 0.6691\n",
      "Epoch 16/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.5705 - val_loss: 0.6138\n",
      "Epoch 17/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.5216 - val_loss: 0.6495\n",
      "Epoch 18/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.5188 - val_loss: 0.5643\n",
      "Epoch 19/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.4853 - val_loss: 0.5715\n",
      "Epoch 20/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.4593 - val_loss: 0.5581\n",
      "Epoch 21/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.4431 - val_loss: 0.4958\n",
      "Epoch 22/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.4317 - val_loss: 0.5029\n",
      "Epoch 23/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.4250 - val_loss: 0.5152\n",
      "Epoch 24/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.4111 - val_loss: 0.5238\n",
      "Epoch 25/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.4289 - val_loss: 0.5735\n",
      "Epoch 26/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.4082 - val_loss: 0.5350\n",
      "Epoch 27/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.4107 - val_loss: 0.5251\n",
      "Epoch 28/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.4113 - val_loss: 0.4868\n",
      "Epoch 29/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.3874 - val_loss: 0.4803\n",
      "Epoch 30/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.3728 - val_loss: 0.5588\n",
      "Epoch 31/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.4742 - val_loss: 0.5660\n",
      "Epoch 32/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.4770 - val_loss: 0.6094\n",
      "Epoch 33/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.4658 - val_loss: 0.6049\n",
      "Epoch 34/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.4099 - val_loss: 0.4787\n",
      "Epoch 35/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.4356 - val_loss: 0.5743\n",
      "Epoch 36/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.4466 - val_loss: 0.5777\n",
      "Epoch 37/1000\n",
      "61/61 [==============================] - 2s 31ms/step - loss: 0.4688 - val_loss: 0.7237\n",
      "Epoch 38/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.4660 - val_loss: 0.5390\n",
      "Epoch 39/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.3974 - val_loss: 0.5056\n",
      "Epoch 40/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.3757 - val_loss: 0.4911\n",
      "Epoch 41/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.4166 - val_loss: 0.5742\n",
      "Epoch 42/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.3806 - val_loss: 0.5061\n",
      "Epoch 43/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.3581 - val_loss: 0.5053\n",
      "Epoch 44/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.3436 - val_loss: 0.4504\n",
      "Epoch 45/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.3326 - val_loss: 0.4442\n",
      "Epoch 46/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.3311 - val_loss: 0.4538\n",
      "Epoch 47/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.3237 - val_loss: 0.4496\n",
      "Epoch 48/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.3171 - val_loss: 0.4353\n",
      "Epoch 49/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.3162 - val_loss: 0.4423\n",
      "Epoch 50/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.3095 - val_loss: 0.4199\n",
      "Epoch 51/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.3094 - val_loss: 0.4359\n",
      "Epoch 52/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.3012 - val_loss: 0.4317\n",
      "Epoch 53/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.3024 - val_loss: 0.4130\n",
      "Epoch 54/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.2961 - val_loss: 0.4237\n",
      "Epoch 55/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.3090 - val_loss: 0.4265\n",
      "Epoch 56/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.3271 - val_loss: 0.4464\n",
      "Epoch 57/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.3105 - val_loss: 0.4414\n",
      "Epoch 58/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.3032 - val_loss: 0.4099\n",
      "Epoch 59/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.2901 - val_loss: 0.4417\n",
      "Epoch 60/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.2981 - val_loss: 0.4196\n",
      "Epoch 61/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.2815 - val_loss: 0.3987\n",
      "Epoch 62/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.2807 - val_loss: 0.4104\n",
      "Epoch 63/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.2788 - val_loss: 0.3954\n",
      "Epoch 64/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.2788 - val_loss: 0.3984\n",
      "Epoch 65/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.2744 - val_loss: 0.4032\n",
      "Epoch 66/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.2723 - val_loss: 0.4162\n",
      "Epoch 67/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.2742 - val_loss: 0.3942\n",
      "Epoch 68/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.2698 - val_loss: 0.3980\n",
      "Epoch 69/1000\n",
      "61/61 [==============================] - 2s 31ms/step - loss: 0.2684 - val_loss: 0.3984\n",
      "Epoch 70/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.2710 - val_loss: 0.3845\n",
      "Epoch 71/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.2674 - val_loss: 0.3882\n",
      "Epoch 72/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.2651 - val_loss: 0.3923\n",
      "Epoch 73/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.2747 - val_loss: 0.3825\n",
      "Epoch 74/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.2672 - val_loss: 0.3925\n",
      "Epoch 75/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.2641 - val_loss: 0.3778\n",
      "Epoch 76/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.2618 - val_loss: 0.3660\n",
      "Epoch 77/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.2613 - val_loss: 0.3805\n",
      "Epoch 78/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.2575 - val_loss: 0.3770\n",
      "Epoch 79/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.2617 - val_loss: 0.3698\n",
      "Epoch 80/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.2642 - val_loss: 0.3899\n",
      "Epoch 81/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.2607 - val_loss: 0.4005\n",
      "Epoch 82/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.2569 - val_loss: 0.3729\n",
      "Epoch 83/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.2542 - val_loss: 0.3728\n",
      "Epoch 84/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.2600 - val_loss: 0.3626\n",
      "Epoch 85/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.2579 - val_loss: 0.3753\n",
      "Epoch 86/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.2548 - val_loss: 0.3729\n",
      "Epoch 87/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.2573 - val_loss: 0.4060\n",
      "Epoch 88/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.2749 - val_loss: 0.3886\n",
      "Epoch 89/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.2708 - val_loss: 0.3870\n",
      "Epoch 90/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.2610 - val_loss: 0.3427\n",
      "Epoch 91/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.2533 - val_loss: 0.3207\n",
      "Epoch 92/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.2471 - val_loss: 0.3593\n",
      "Epoch 93/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.2488 - val_loss: 0.3288\n",
      "Epoch 94/1000\n",
      "61/61 [==============================] - 2s 28ms/step - loss: 0.2431 - val_loss: 0.3424\n",
      "Epoch 95/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.2450 - val_loss: 0.3390\n",
      "Epoch 96/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.2543 - val_loss: 0.4164\n",
      "Epoch 97/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.3119 - val_loss: 0.4029\n",
      "Epoch 98/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.3769 - val_loss: 0.6813\n",
      "Epoch 99/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.4285 - val_loss: 0.4972\n",
      "Epoch 100/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.3106 - val_loss: 0.4157\n",
      "Epoch 101/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.2760 - val_loss: 0.3801\n",
      "Epoch 102/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.2649 - val_loss: 0.3646\n",
      "Epoch 103/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.2557 - val_loss: 0.3713\n",
      "Epoch 104/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.2516 - val_loss: 0.3574\n",
      "Epoch 105/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.2471 - val_loss: 0.3932\n",
      "Epoch 106/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.2504 - val_loss: 0.3489\n",
      "Epoch 107/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.2437 - val_loss: 0.3423\n",
      "Epoch 108/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.2405 - val_loss: 0.3441\n",
      "Epoch 109/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.2396 - val_loss: 0.3517\n",
      "Epoch 110/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.2383 - val_loss: 0.3304\n",
      "Epoch 111/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.2382 - val_loss: 0.3326\n",
      "Epoch 112/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.2368 - val_loss: 0.3266\n",
      "Epoch 113/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.2350 - val_loss: 0.3169\n",
      "Epoch 114/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.2335 - val_loss: 0.3354\n",
      "Epoch 115/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.2329 - val_loss: 0.3232\n",
      "Epoch 116/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.2328 - val_loss: 0.3211\n",
      "Epoch 117/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.2308 - val_loss: 0.3392\n",
      "Epoch 118/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.2311 - val_loss: 0.3376\n",
      "Epoch 119/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.2302 - val_loss: 0.3378\n",
      "Epoch 120/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.2302 - val_loss: 0.3367\n",
      "Epoch 121/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.2304 - val_loss: 0.3489\n",
      "Epoch 122/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.2298 - val_loss: 0.3236\n",
      "Epoch 123/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.2277 - val_loss: 0.3168\n",
      "Epoch 124/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.2298 - val_loss: 0.3513\n",
      "Epoch 125/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.2316 - val_loss: 0.3156\n",
      "Epoch 126/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.2261 - val_loss: 0.3074\n",
      "Epoch 127/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.2238 - val_loss: 0.3055\n",
      "Epoch 128/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.2249 - val_loss: 0.3175\n",
      "Epoch 129/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.2264 - val_loss: 0.3166\n",
      "Epoch 130/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.2279 - val_loss: 0.3147\n",
      "Epoch 131/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.2242 - val_loss: 0.3049\n",
      "Epoch 132/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.2266 - val_loss: 0.3181\n",
      "Epoch 133/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.2243 - val_loss: 0.3139\n",
      "Epoch 134/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.2243 - val_loss: 0.3153\n",
      "Epoch 135/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.2218 - val_loss: 0.3002\n",
      "Epoch 136/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.2232 - val_loss: 0.3063\n",
      "Epoch 137/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.2277 - val_loss: 0.3161\n",
      "Epoch 138/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.2361 - val_loss: 0.3272\n",
      "Epoch 139/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.2235 - val_loss: 0.3011\n",
      "Epoch 140/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.2204 - val_loss: 0.3051\n",
      "Epoch 141/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.2202 - val_loss: 0.2860\n",
      "Epoch 142/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.2203 - val_loss: 0.2914\n",
      "Epoch 143/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.2179 - val_loss: 0.2854\n",
      "Epoch 144/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.2213 - val_loss: 0.2992\n",
      "Epoch 145/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.2195 - val_loss: 0.2846\n",
      "Epoch 146/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.2195 - val_loss: 0.2953\n",
      "Epoch 147/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.2192 - val_loss: 0.2923\n",
      "Epoch 148/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.2235 - val_loss: 0.3116\n",
      "Epoch 149/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.2212 - val_loss: 0.2987\n",
      "Epoch 150/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.2153 - val_loss: 0.2996\n",
      "Epoch 151/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.2156 - val_loss: 0.2836\n",
      "Epoch 152/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.2164 - val_loss: 0.2915\n",
      "Epoch 153/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.2156 - val_loss: 0.2895\n",
      "Epoch 154/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.2152 - val_loss: 0.2920\n",
      "Epoch 155/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.2128 - val_loss: 0.2860\n",
      "Epoch 156/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.2135 - val_loss: 0.2892\n",
      "Epoch 157/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.2139 - val_loss: 0.2847\n",
      "Epoch 158/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.2123 - val_loss: 0.2845\n",
      "Epoch 159/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.2133 - val_loss: 0.2866\n",
      "Epoch 160/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.2130 - val_loss: 0.2771\n",
      "Epoch 161/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.2138 - val_loss: 0.2775\n",
      "Epoch 162/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.2122 - val_loss: 0.2794\n",
      "Epoch 163/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.2255 - val_loss: 0.3240\n",
      "Epoch 164/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.2155 - val_loss: 0.2889\n",
      "Epoch 165/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.2145 - val_loss: 0.2975\n",
      "Epoch 166/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.2134 - val_loss: 0.2944\n",
      "Epoch 167/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.2115 - val_loss: 0.2835\n",
      "Epoch 168/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.2096 - val_loss: 0.2807\n",
      "Epoch 169/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.2100 - val_loss: 0.2944\n",
      "Epoch 170/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.2095 - val_loss: 0.2835\n",
      "Epoch 171/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.2088 - val_loss: 0.2883\n",
      "Epoch 172/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.2086 - val_loss: 0.2898\n",
      "Epoch 173/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.2086 - val_loss: 0.2953\n",
      "Epoch 174/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.2077 - val_loss: 0.2775\n",
      "Epoch 175/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.2087 - val_loss: 0.2796\n",
      "Epoch 176/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.2118 - val_loss: 0.3126\n",
      "Epoch 177/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.2161 - val_loss: 0.2997\n",
      "Epoch 178/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.2113 - val_loss: 0.2798\n",
      "Epoch 179/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.2087 - val_loss: 0.2936\n",
      "Epoch 180/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.2090 - val_loss: 0.3054\n",
      "Epoch 181/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.2074 - val_loss: 0.2832\n",
      "Epoch 182/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.2067 - val_loss: 0.2695\n",
      "Epoch 183/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.2069 - val_loss: 0.2728\n",
      "Epoch 184/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.2081 - val_loss: 0.2587\n",
      "Epoch 185/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.2048 - val_loss: 0.2621\n",
      "Epoch 186/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.2046 - val_loss: 0.2600\n",
      "Epoch 187/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.2054 - val_loss: 0.2657\n",
      "Epoch 188/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.2052 - val_loss: 0.2652\n",
      "Epoch 189/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.2032 - val_loss: 0.2654\n",
      "Epoch 190/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.2032 - val_loss: 0.2553\n",
      "Epoch 191/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.2038 - val_loss: 0.2812\n",
      "Epoch 192/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.2024 - val_loss: 0.2669\n",
      "Epoch 193/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.2031 - val_loss: 0.2747\n",
      "Epoch 194/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.2054 - val_loss: 0.2729\n",
      "Epoch 195/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.2037 - val_loss: 0.2640\n",
      "Epoch 196/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.2031 - val_loss: 0.2653\n",
      "Epoch 197/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.2021 - val_loss: 0.2600\n",
      "Epoch 198/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.2027 - val_loss: 0.2483\n",
      "Epoch 199/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.2006 - val_loss: 0.2579\n",
      "Epoch 200/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.2005 - val_loss: 0.2508\n",
      "Epoch 201/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.2009 - val_loss: 0.2559\n",
      "Epoch 202/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.2016 - val_loss: 0.2509\n",
      "Epoch 203/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.2018 - val_loss: 0.2547\n",
      "Epoch 204/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.1996 - val_loss: 0.2637\n",
      "Epoch 205/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.2003 - val_loss: 0.2693\n",
      "Epoch 206/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.2016 - val_loss: 0.2580\n",
      "Epoch 207/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.2003 - val_loss: 0.2523\n",
      "Epoch 208/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.1995 - val_loss: 0.2581\n",
      "Epoch 209/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.1985 - val_loss: 0.2517\n",
      "Epoch 210/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.1965 - val_loss: 0.2506\n",
      "Epoch 211/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.1989 - val_loss: 0.2558\n",
      "Epoch 212/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.1987 - val_loss: 0.2562\n",
      "Epoch 213/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.1977 - val_loss: 0.2497\n",
      "Epoch 214/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.1985 - val_loss: 0.2472\n",
      "Epoch 215/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.1968 - val_loss: 0.2458\n",
      "Epoch 216/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.1958 - val_loss: 0.2543\n",
      "Epoch 217/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.1960 - val_loss: 0.2432\n",
      "Epoch 218/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.1966 - val_loss: 0.2502\n",
      "Epoch 219/1000\n",
      "61/61 [==============================] - 2s 28ms/step - loss: 0.1975 - val_loss: 0.2560\n",
      "Epoch 220/1000\n",
      "61/61 [==============================] - 2s 28ms/step - loss: 0.1955 - val_loss: 0.2492\n",
      "Epoch 221/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.1974 - val_loss: 0.2436\n",
      "Epoch 222/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.1956 - val_loss: 0.2416\n",
      "Epoch 223/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.1953 - val_loss: 0.2514\n",
      "Epoch 224/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.1953 - val_loss: 0.2565\n",
      "Epoch 225/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.1956 - val_loss: 0.2480\n",
      "Epoch 226/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.1967 - val_loss: 0.2474\n",
      "Epoch 227/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.1943 - val_loss: 0.2662\n",
      "Epoch 228/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.1952 - val_loss: 0.2444\n",
      "Epoch 229/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.1943 - val_loss: 0.2472\n",
      "Epoch 230/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.1941 - val_loss: 0.2434\n",
      "Epoch 231/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.1933 - val_loss: 0.2490\n",
      "Epoch 232/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.1948 - val_loss: 0.2508\n",
      "Epoch 233/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.1939 - val_loss: 0.2393\n",
      "Epoch 234/1000\n",
      "61/61 [==============================] - 2s 28ms/step - loss: 0.2070 - val_loss: 0.4076\n",
      "Epoch 235/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.2185 - val_loss: 0.2995\n",
      "Epoch 236/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.2029 - val_loss: 0.2545\n",
      "Epoch 237/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.1962 - val_loss: 0.2481\n",
      "Epoch 238/1000\n",
      "61/61 [==============================] - 2s 28ms/step - loss: 0.1963 - val_loss: 0.2660\n",
      "Epoch 239/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.1987 - val_loss: 0.2579\n",
      "Epoch 240/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.1933 - val_loss: 0.2594\n",
      "Epoch 241/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.1909 - val_loss: 0.2411\n",
      "Epoch 242/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.1923 - val_loss: 0.2393\n",
      "Epoch 243/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.1907 - val_loss: 0.2487\n",
      "Epoch 244/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.1905 - val_loss: 0.2357\n",
      "Epoch 245/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.1920 - val_loss: 0.2389\n",
      "Epoch 246/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.1912 - val_loss: 0.2440\n",
      "Epoch 247/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.1914 - val_loss: 0.2491\n",
      "Epoch 248/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.1906 - val_loss: 0.2395\n",
      "Epoch 249/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.1897 - val_loss: 0.2435\n",
      "Epoch 250/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.1904 - val_loss: 0.2432\n",
      "Epoch 251/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.1899 - val_loss: 0.2380\n",
      "Epoch 252/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.1886 - val_loss: 0.2391\n",
      "Epoch 253/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.1887 - val_loss: 0.2443\n",
      "Epoch 254/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.1888 - val_loss: 0.2420\n",
      "Epoch 255/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.1873 - val_loss: 0.2391\n",
      "Epoch 256/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.1886 - val_loss: 0.2448\n",
      "Epoch 257/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.1880 - val_loss: 0.2378\n",
      "Epoch 258/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.1883 - val_loss: 0.2467\n",
      "Epoch 259/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.1886 - val_loss: 0.2371\n",
      "Epoch 260/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.1881 - val_loss: 0.2354\n",
      "Epoch 261/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.1878 - val_loss: 0.2413\n",
      "Epoch 262/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.1876 - val_loss: 0.2440\n",
      "Epoch 263/1000\n",
      "61/61 [==============================] - 2s 28ms/step - loss: 0.1860 - val_loss: 0.2425\n",
      "Epoch 264/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.1872 - val_loss: 0.2415\n",
      "Epoch 265/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.1875 - val_loss: 0.2386\n",
      "Epoch 266/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.1876 - val_loss: 0.2375\n",
      "Epoch 267/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.1886 - val_loss: 0.2350\n",
      "Epoch 268/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.1869 - val_loss: 0.2351\n",
      "Epoch 269/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.1892 - val_loss: 0.2495\n",
      "Epoch 270/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.1895 - val_loss: 0.2446\n",
      "Epoch 271/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.1897 - val_loss: 0.2388\n",
      "Epoch 272/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.1876 - val_loss: 0.2343\n",
      "Epoch 273/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.1888 - val_loss: 0.2305\n",
      "Epoch 274/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.1873 - val_loss: 0.2316\n",
      "Epoch 275/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.1858 - val_loss: 0.2391\n",
      "Epoch 276/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.1872 - val_loss: 0.2390\n",
      "Epoch 277/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.1873 - val_loss: 0.2354\n",
      "Epoch 278/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.1864 - val_loss: 0.2379\n",
      "Epoch 279/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.1857 - val_loss: 0.2334\n",
      "Epoch 280/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.1867 - val_loss: 0.2327\n",
      "Epoch 281/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.1853 - val_loss: 0.2245\n",
      "Epoch 282/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.1862 - val_loss: 0.2305\n",
      "Epoch 283/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.1848 - val_loss: 0.2388\n",
      "Epoch 284/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.1856 - val_loss: 0.2297\n",
      "Epoch 285/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.1867 - val_loss: 0.2319\n",
      "Epoch 286/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.1874 - val_loss: 0.2498\n",
      "Epoch 287/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.1864 - val_loss: 0.2436\n",
      "Epoch 288/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.1869 - val_loss: 0.2356\n",
      "Epoch 289/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.1845 - val_loss: 0.2280\n",
      "Epoch 290/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.1839 - val_loss: 0.2352\n",
      "Epoch 291/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.1825 - val_loss: 0.2265\n",
      "Epoch 292/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.1836 - val_loss: 0.2291\n",
      "Epoch 293/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.1841 - val_loss: 0.2297\n",
      "Epoch 294/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.1833 - val_loss: 0.2257\n",
      "Epoch 295/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.1842 - val_loss: 0.2287\n",
      "Epoch 296/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.1840 - val_loss: 0.2357\n",
      "Epoch 297/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.1829 - val_loss: 0.2305\n",
      "Epoch 298/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.1837 - val_loss: 0.2267\n",
      "Epoch 299/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.1870 - val_loss: 0.2327\n",
      "Epoch 300/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.1845 - val_loss: 0.2263\n",
      "Epoch 301/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.1852 - val_loss: 0.2215\n",
      "Epoch 302/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.1833 - val_loss: 0.2234\n",
      "Epoch 303/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.1837 - val_loss: 0.2143\n",
      "Epoch 304/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.1827 - val_loss: 0.2292\n",
      "Epoch 305/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.1843 - val_loss: 0.2905\n",
      "Epoch 306/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.2091 - val_loss: 0.2596\n",
      "Epoch 307/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.1913 - val_loss: 0.2569\n",
      "Epoch 308/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.1889 - val_loss: 0.2575\n",
      "Epoch 309/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.1852 - val_loss: 0.2232\n",
      "Epoch 310/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.1829 - val_loss: 0.2376\n",
      "Epoch 311/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.1813 - val_loss: 0.2264\n",
      "Epoch 312/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.1799 - val_loss: 0.2211\n",
      "Epoch 313/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.1812 - val_loss: 0.2260\n",
      "Epoch 314/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.1813 - val_loss: 0.2254\n",
      "Epoch 315/1000\n",
      "61/61 [==============================] - 2s 28ms/step - loss: 0.1805 - val_loss: 0.2188\n",
      "Epoch 316/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.1799 - val_loss: 0.2248\n",
      "Epoch 317/1000\n",
      "61/61 [==============================] - 2s 28ms/step - loss: 0.1807 - val_loss: 0.2163\n",
      "Epoch 318/1000\n",
      "61/61 [==============================] - 2s 28ms/step - loss: 0.1797 - val_loss: 0.2210\n",
      "Epoch 319/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.1806 - val_loss: 0.2286\n",
      "Epoch 320/1000\n",
      "61/61 [==============================] - 2s 28ms/step - loss: 0.1807 - val_loss: 0.2196\n",
      "Epoch 321/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.1812 - val_loss: 0.2238\n",
      "Epoch 322/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.1801 - val_loss: 0.2229\n",
      "Epoch 323/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.1797 - val_loss: 0.2168\n",
      "Epoch 324/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.1790 - val_loss: 0.2216\n",
      "Epoch 325/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.1801 - val_loss: 0.2181\n",
      "Epoch 326/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.2013 - val_loss: 0.2484\n",
      "Epoch 327/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.1841 - val_loss: 0.2341\n",
      "Epoch 328/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.1817 - val_loss: 0.2278\n",
      "Epoch 329/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.1830 - val_loss: 0.2169\n",
      "Epoch 330/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.1809 - val_loss: 0.2195\n",
      "Epoch 331/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.1796 - val_loss: 0.2178\n",
      "Epoch 332/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.1806 - val_loss: 0.2180\n",
      "Epoch 333/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.1806 - val_loss: 0.2114\n",
      "Epoch 334/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.1793 - val_loss: 0.2119\n",
      "Epoch 335/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.1820 - val_loss: 0.2198\n",
      "Epoch 336/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.1798 - val_loss: 0.2163\n",
      "Epoch 337/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.1791 - val_loss: 0.2143\n",
      "Epoch 338/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.1788 - val_loss: 0.2242\n",
      "Epoch 339/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.1792 - val_loss: 0.2278\n",
      "Epoch 340/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.1793 - val_loss: 0.2181\n",
      "Epoch 341/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.1780 - val_loss: 0.2171\n",
      "Epoch 342/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.1778 - val_loss: 0.2133\n",
      "Epoch 343/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.1786 - val_loss: 0.2286\n",
      "Epoch 344/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.1785 - val_loss: 0.2143\n",
      "Epoch 345/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.1783 - val_loss: 0.2193\n",
      "Epoch 346/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.1772 - val_loss: 0.2212\n",
      "Epoch 347/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.1789 - val_loss: 0.2167\n",
      "Epoch 348/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.1782 - val_loss: 0.2117\n",
      "Epoch 349/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.1782 - val_loss: 0.2139\n",
      "Epoch 350/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.1768 - val_loss: 0.2193\n",
      "Epoch 351/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.1780 - val_loss: 0.2183\n",
      "Epoch 352/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.1782 - val_loss: 0.2319\n",
      "Epoch 353/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.2011 - val_loss: 0.2538\n",
      "Epoch 354/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.2014 - val_loss: 0.2620\n",
      "Epoch 355/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.1940 - val_loss: 0.2567\n",
      "Epoch 356/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.1854 - val_loss: 0.2317\n",
      "Epoch 357/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.2581 - val_loss: 0.2830\n",
      "Epoch 358/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.2039 - val_loss: 0.2785\n",
      "Epoch 359/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.1948 - val_loss: 0.2667\n",
      "Epoch 360/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.1915 - val_loss: 0.2623\n",
      "Epoch 361/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.2014 - val_loss: 0.3169\n",
      "Epoch 362/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.2016 - val_loss: 0.2970\n",
      "Epoch 363/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.1862 - val_loss: 0.2437\n",
      "Epoch 364/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.1822 - val_loss: 0.2410\n",
      "Epoch 365/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.1815 - val_loss: 0.2342\n",
      "Epoch 366/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.1798 - val_loss: 0.2336\n",
      "Epoch 367/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.1793 - val_loss: 0.2324\n",
      "Epoch 368/1000\n",
      "61/61 [==============================] - ETA: 0s - loss: 0.1783Restoring model weights from the end of the best epoch: 333.\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.1783 - val_loss: 0.2318\n",
      "Epoch 368: early stopping\n",
      "7/7 [==============================] - 1s 10ms/step\n",
      "0.18451599734921556\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b2bb0a465fd54f4bba36e6b1e1703d08",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.055 MB of 0.055 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch/epoch</td><td>▁▁▁▁▁▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇███</td></tr><tr><td>epoch/learning_rate</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>epoch/loss</td><td>█▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>epoch/val_loss</td><td>█▄▃▃▂▂▂▂▂▂▂▂▂▂▂▂▁▂▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>rmase_prediction</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch/epoch</td><td>367</td></tr><tr><td>epoch/learning_rate</td><td>0.00049</td></tr><tr><td>epoch/loss</td><td>0.17826</td></tr><tr><td>epoch/val_loss</td><td>0.23176</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">test_6</strong> at: <a href='https://wandb.ai/uu13234-none/sgnate_skate-keras/runs/gjnj77gw' target=\"_blank\">https://wandb.ai/uu13234-none/sgnate_skate-keras/runs/gjnj77gw</a><br/> View project at: <a href='https://wandb.ai/uu13234-none/sgnate_skate-keras' target=\"_blank\">https://wandb.ai/uu13234-none/sgnate_skate-keras</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20241104_150748-gjnj77gw\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.18.3"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\sato\\Desktop\\python\\SIGNATE\\スケートボードの挙動予測\\code-analysis\\wandb\\run-20241104_151859-1ffwoq97</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/uu13234-none/sgnate_skate-keras/runs/1ffwoq97' target=\"_blank\">test_7</a></strong> to <a href='https://wandb.ai/uu13234-none/sgnate_skate-keras' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/uu13234-none/sgnate_skate-keras' target=\"_blank\">https://wandb.ai/uu13234-none/sgnate_skate-keras</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/uu13234-none/sgnate_skate-keras/runs/1ffwoq97' target=\"_blank\">https://wandb.ai/uu13234-none/sgnate_skate-keras/runs/1ffwoq97</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "61/61 [==============================] - 9s 51ms/step - loss: 1.5128 - val_loss: 1.2378\n",
      "Epoch 2/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 1.0501 - val_loss: 1.0371\n",
      "Epoch 3/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.8877 - val_loss: 0.8959\n",
      "Epoch 4/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.8275 - val_loss: 0.8134\n",
      "Epoch 5/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.7885 - val_loss: 0.7991\n",
      "Epoch 6/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.7739 - val_loss: 0.7807\n",
      "Epoch 7/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.7122 - val_loss: 0.7620\n",
      "Epoch 8/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.6635 - val_loss: 0.6775\n",
      "Epoch 9/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.6391 - val_loss: 0.6980\n",
      "Epoch 10/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.6135 - val_loss: 0.7064\n",
      "Epoch 11/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.5956 - val_loss: 0.6887\n",
      "Epoch 12/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.5691 - val_loss: 0.5995\n",
      "Epoch 13/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.5486 - val_loss: 0.6319\n",
      "Epoch 14/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.5667 - val_loss: 0.5897\n",
      "Epoch 15/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.5179 - val_loss: 0.6221\n",
      "Epoch 16/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.5261 - val_loss: 0.6181\n",
      "Epoch 17/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.5103 - val_loss: 0.5992\n",
      "Epoch 18/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.4892 - val_loss: 0.6020\n",
      "Epoch 19/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.4951 - val_loss: 0.5750\n",
      "Epoch 20/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.4678 - val_loss: 0.5409\n",
      "Epoch 21/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.4483 - val_loss: 0.5196\n",
      "Epoch 22/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.4275 - val_loss: 0.5307\n",
      "Epoch 23/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.4358 - val_loss: 0.5565\n",
      "Epoch 24/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.4591 - val_loss: 0.5707\n",
      "Epoch 25/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.4441 - val_loss: 0.6246\n",
      "Epoch 26/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.5200 - val_loss: 0.5774\n",
      "Epoch 27/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.4927 - val_loss: 0.6072\n",
      "Epoch 28/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.4547 - val_loss: 0.5920\n",
      "Epoch 29/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.4155 - val_loss: 0.6270\n",
      "Epoch 30/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.4864 - val_loss: 0.5371\n",
      "Epoch 31/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.4246 - val_loss: 0.5173\n",
      "Epoch 32/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.3929 - val_loss: 0.4784\n",
      "Epoch 33/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.3783 - val_loss: 0.4723\n",
      "Epoch 34/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.3823 - val_loss: 0.4776\n",
      "Epoch 35/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.3631 - val_loss: 0.4754\n",
      "Epoch 36/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.3677 - val_loss: 0.5187\n",
      "Epoch 37/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.4216 - val_loss: 0.4741\n",
      "Epoch 38/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.4200 - val_loss: 0.5153\n",
      "Epoch 39/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.4780 - val_loss: 0.5534\n",
      "Epoch 40/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.3911 - val_loss: 0.4762\n",
      "Epoch 41/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.3607 - val_loss: 0.4468\n",
      "Epoch 42/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.3548 - val_loss: 0.4584\n",
      "Epoch 43/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.3467 - val_loss: 0.4566\n",
      "Epoch 44/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.3387 - val_loss: 0.4390\n",
      "Epoch 45/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.3409 - val_loss: 0.4213\n",
      "Epoch 46/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.3296 - val_loss: 0.4371\n",
      "Epoch 47/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.3185 - val_loss: 0.4266\n",
      "Epoch 48/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.3188 - val_loss: 0.4268\n",
      "Epoch 49/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.3161 - val_loss: 0.4242\n",
      "Epoch 50/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.3107 - val_loss: 0.4130\n",
      "Epoch 51/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.3075 - val_loss: 0.4209\n",
      "Epoch 52/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.3052 - val_loss: 0.4233\n",
      "Epoch 53/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.2995 - val_loss: 0.3940\n",
      "Epoch 54/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.2936 - val_loss: 0.4012\n",
      "Epoch 55/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.2941 - val_loss: 0.4066\n",
      "Epoch 56/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.2973 - val_loss: 0.4009\n",
      "Epoch 57/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.2926 - val_loss: 0.4125\n",
      "Epoch 58/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.2862 - val_loss: 0.4092\n",
      "Epoch 59/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.2848 - val_loss: 0.4036\n",
      "Epoch 60/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.2834 - val_loss: 0.3999\n",
      "Epoch 61/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.2808 - val_loss: 0.3982\n",
      "Epoch 62/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.2826 - val_loss: 0.3983\n",
      "Epoch 63/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.2785 - val_loss: 0.3944\n",
      "Epoch 64/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.2961 - val_loss: 0.3713\n",
      "Epoch 65/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.2835 - val_loss: 0.3840\n",
      "Epoch 66/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.2791 - val_loss: 0.3687\n",
      "Epoch 67/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.2753 - val_loss: 0.3639\n",
      "Epoch 68/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.2730 - val_loss: 0.3647\n",
      "Epoch 69/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.2743 - val_loss: 0.4719\n",
      "Epoch 70/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.3106 - val_loss: 0.4497\n",
      "Epoch 71/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.2936 - val_loss: 0.3774\n",
      "Epoch 72/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.2772 - val_loss: 0.3866\n",
      "Epoch 73/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.2696 - val_loss: 0.3639\n",
      "Epoch 74/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.2710 - val_loss: 0.3705\n",
      "Epoch 75/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.2796 - val_loss: 0.3623\n",
      "Epoch 76/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.2790 - val_loss: 0.4207\n",
      "Epoch 77/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.3145 - val_loss: 0.4226\n",
      "Epoch 78/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.2809 - val_loss: 0.3934\n",
      "Epoch 79/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.2685 - val_loss: 0.3734\n",
      "Epoch 80/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.2618 - val_loss: 0.3878\n",
      "Epoch 81/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.2574 - val_loss: 0.3765\n",
      "Epoch 82/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.2533 - val_loss: 0.3641\n",
      "Epoch 83/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.2521 - val_loss: 0.3739\n",
      "Epoch 84/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.2520 - val_loss: 0.3756\n",
      "Epoch 85/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.2529 - val_loss: 0.3718\n",
      "Epoch 86/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.2528 - val_loss: 0.3746\n",
      "Epoch 87/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.2519 - val_loss: 0.3733\n",
      "Epoch 88/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.2520 - val_loss: 0.3641\n",
      "Epoch 89/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.2469 - val_loss: 0.3614\n",
      "Epoch 90/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.2469 - val_loss: 0.3404\n",
      "Epoch 91/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.2465 - val_loss: 0.3458\n",
      "Epoch 92/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.4868 - val_loss: 0.7320\n",
      "Epoch 93/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.5006 - val_loss: 0.5299\n",
      "Epoch 94/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.3948 - val_loss: 0.4478\n",
      "Epoch 95/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.3302 - val_loss: 0.3993\n",
      "Epoch 96/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.2966 - val_loss: 0.3736\n",
      "Epoch 97/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.2770 - val_loss: 0.3523\n",
      "Epoch 98/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.2739 - val_loss: 0.3593\n",
      "Epoch 99/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.2616 - val_loss: 0.3466\n",
      "Epoch 100/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.2596 - val_loss: 0.3424\n",
      "Epoch 101/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.2535 - val_loss: 0.3466\n",
      "Epoch 102/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.2520 - val_loss: 0.3475\n",
      "Epoch 103/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.2480 - val_loss: 0.3390\n",
      "Epoch 104/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.2450 - val_loss: 0.3507\n",
      "Epoch 105/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.2428 - val_loss: 0.3484\n",
      "Epoch 106/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.2416 - val_loss: 0.3411\n",
      "Epoch 107/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.2420 - val_loss: 0.3238\n",
      "Epoch 108/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.2398 - val_loss: 0.3223\n",
      "Epoch 109/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.2390 - val_loss: 0.3237\n",
      "Epoch 110/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.2367 - val_loss: 0.3217\n",
      "Epoch 111/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.2369 - val_loss: 0.3207\n",
      "Epoch 112/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.2375 - val_loss: 0.3195\n",
      "Epoch 113/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.2335 - val_loss: 0.3247\n",
      "Epoch 114/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.2334 - val_loss: 0.3144\n",
      "Epoch 115/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.2350 - val_loss: 0.3243\n",
      "Epoch 116/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.2333 - val_loss: 0.3021\n",
      "Epoch 117/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.2404 - val_loss: 0.3565\n",
      "Epoch 118/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.2846 - val_loss: 0.4076\n",
      "Epoch 119/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.2923 - val_loss: 0.3431\n",
      "Epoch 120/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.2506 - val_loss: 0.3121\n",
      "Epoch 121/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.2404 - val_loss: 0.3401\n",
      "Epoch 122/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.2372 - val_loss: 0.3174\n",
      "Epoch 123/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.2710 - val_loss: 0.4290\n",
      "Epoch 124/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.2594 - val_loss: 0.3587\n",
      "Epoch 125/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.2397 - val_loss: 0.3214\n",
      "Epoch 126/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.2385 - val_loss: 0.3330\n",
      "Epoch 127/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.2335 - val_loss: 0.3065\n",
      "Epoch 128/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.2296 - val_loss: 0.3050\n",
      "Epoch 129/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.2293 - val_loss: 0.3107\n",
      "Epoch 130/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.2256 - val_loss: 0.3053\n",
      "Epoch 131/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.2258 - val_loss: 0.3070\n",
      "Epoch 132/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.2242 - val_loss: 0.3056\n",
      "Epoch 133/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.2276 - val_loss: 0.3002\n",
      "Epoch 134/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.2227 - val_loss: 0.2916\n",
      "Epoch 135/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.2246 - val_loss: 0.3045\n",
      "Epoch 136/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.2237 - val_loss: 0.2981\n",
      "Epoch 137/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.2219 - val_loss: 0.2955\n",
      "Epoch 138/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.2205 - val_loss: 0.3068\n",
      "Epoch 139/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.2211 - val_loss: 0.2936\n",
      "Epoch 140/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.2217 - val_loss: 0.3058\n",
      "Epoch 141/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.2185 - val_loss: 0.3018\n",
      "Epoch 142/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.2193 - val_loss: 0.2980\n",
      "Epoch 143/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.2201 - val_loss: 0.3101\n",
      "Epoch 144/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.2244 - val_loss: 0.3015\n",
      "Epoch 145/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.2214 - val_loss: 0.2934\n",
      "Epoch 146/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.2235 - val_loss: 0.3068\n",
      "Epoch 147/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.2211 - val_loss: 0.3080\n",
      "Epoch 148/1000\n",
      "61/61 [==============================] - 2s 28ms/step - loss: 0.2202 - val_loss: 0.3033\n",
      "Epoch 149/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.2214 - val_loss: 0.2924\n",
      "Epoch 150/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.2162 - val_loss: 0.2856\n",
      "Epoch 151/1000\n",
      "61/61 [==============================] - 2s 28ms/step - loss: 0.2154 - val_loss: 0.2988\n",
      "Epoch 152/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.2140 - val_loss: 0.2926\n",
      "Epoch 153/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.2141 - val_loss: 0.2966\n",
      "Epoch 154/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.2132 - val_loss: 0.2914\n",
      "Epoch 155/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.2158 - val_loss: 0.2871\n",
      "Epoch 156/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.2128 - val_loss: 0.2928\n",
      "Epoch 157/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.2162 - val_loss: 0.2955\n",
      "Epoch 158/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.2158 - val_loss: 0.3020\n",
      "Epoch 159/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.2147 - val_loss: 0.2825\n",
      "Epoch 160/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.2128 - val_loss: 0.2812\n",
      "Epoch 161/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.2254 - val_loss: 0.3595\n",
      "Epoch 162/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.2250 - val_loss: 0.3337\n",
      "Epoch 163/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.2529 - val_loss: 0.4611\n",
      "Epoch 164/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.3123 - val_loss: 0.3715\n",
      "Epoch 165/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.2585 - val_loss: 0.3141\n",
      "Epoch 166/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.2309 - val_loss: 0.3024\n",
      "Epoch 167/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.2230 - val_loss: 0.2939\n",
      "Epoch 168/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.2198 - val_loss: 0.2839\n",
      "Epoch 169/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.2168 - val_loss: 0.2874\n",
      "Epoch 170/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.2144 - val_loss: 0.2812\n",
      "Epoch 171/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.2136 - val_loss: 0.2812\n",
      "Epoch 172/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.2125 - val_loss: 0.2836\n",
      "Epoch 173/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.2130 - val_loss: 0.2837\n",
      "Epoch 174/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.2124 - val_loss: 0.2921\n",
      "Epoch 175/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.2106 - val_loss: 0.2753\n",
      "Epoch 176/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.2077 - val_loss: 0.2761\n",
      "Epoch 177/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.2088 - val_loss: 0.2796\n",
      "Epoch 178/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.2071 - val_loss: 0.2822\n",
      "Epoch 179/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.2066 - val_loss: 0.2792\n",
      "Epoch 180/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.2060 - val_loss: 0.2779\n",
      "Epoch 181/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.2099 - val_loss: 0.2783\n",
      "Epoch 182/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.2091 - val_loss: 0.2782\n",
      "Epoch 183/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.2076 - val_loss: 0.2739\n",
      "Epoch 184/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.2063 - val_loss: 0.2670\n",
      "Epoch 185/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.2076 - val_loss: 0.2735\n",
      "Epoch 186/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.2151 - val_loss: 0.2740\n",
      "Epoch 187/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.2083 - val_loss: 0.2706\n",
      "Epoch 188/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.2051 - val_loss: 0.2710\n",
      "Epoch 189/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.2072 - val_loss: 0.2721\n",
      "Epoch 190/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.2062 - val_loss: 0.2648\n",
      "Epoch 191/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.2032 - val_loss: 0.2662\n",
      "Epoch 192/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.2060 - val_loss: 0.2725\n",
      "Epoch 193/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.2072 - val_loss: 0.2731\n",
      "Epoch 194/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.2052 - val_loss: 0.2733\n",
      "Epoch 195/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.2038 - val_loss: 0.2726\n",
      "Epoch 196/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.2034 - val_loss: 0.2689\n",
      "Epoch 197/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.2043 - val_loss: 0.2654\n",
      "Epoch 198/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.2049 - val_loss: 0.2723\n",
      "Epoch 199/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.2039 - val_loss: 0.2745\n",
      "Epoch 200/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.2026 - val_loss: 0.2674\n",
      "Epoch 201/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.2038 - val_loss: 0.2660\n",
      "Epoch 202/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.2011 - val_loss: 0.2633\n",
      "Epoch 203/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.2003 - val_loss: 0.2647\n",
      "Epoch 204/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.2021 - val_loss: 0.2568\n",
      "Epoch 205/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.2000 - val_loss: 0.2664\n",
      "Epoch 206/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.2016 - val_loss: 0.2617\n",
      "Epoch 207/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.2006 - val_loss: 0.2625\n",
      "Epoch 208/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.2007 - val_loss: 0.2631\n",
      "Epoch 209/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.2007 - val_loss: 0.2610\n",
      "Epoch 210/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.2002 - val_loss: 0.2665\n",
      "Epoch 211/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.2006 - val_loss: 0.2491\n",
      "Epoch 212/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.2006 - val_loss: 0.2614\n",
      "Epoch 213/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.1992 - val_loss: 0.2645\n",
      "Epoch 214/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.1998 - val_loss: 0.2678\n",
      "Epoch 215/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.2004 - val_loss: 0.2636\n",
      "Epoch 216/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.2010 - val_loss: 0.2682\n",
      "Epoch 217/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.2443 - val_loss: 0.2962\n",
      "Epoch 218/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.2191 - val_loss: 0.2808\n",
      "Epoch 219/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.2065 - val_loss: 0.2720\n",
      "Epoch 220/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.2034 - val_loss: 0.2847\n",
      "Epoch 221/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.2002 - val_loss: 0.2760\n",
      "Epoch 222/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.1980 - val_loss: 0.2598\n",
      "Epoch 223/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.1994 - val_loss: 0.2798\n",
      "Epoch 224/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.2019 - val_loss: 0.2740\n",
      "Epoch 225/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.2031 - val_loss: 0.2851\n",
      "Epoch 226/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.1983 - val_loss: 0.2678\n",
      "Epoch 227/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.1977 - val_loss: 0.2666\n",
      "Epoch 228/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.1975 - val_loss: 0.2659\n",
      "Epoch 229/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.1969 - val_loss: 0.2499\n",
      "Epoch 230/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.1971 - val_loss: 0.2539\n",
      "Epoch 231/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.1973 - val_loss: 0.2518\n",
      "Epoch 232/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.1960 - val_loss: 0.2733\n",
      "Epoch 233/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.1960 - val_loss: 0.2682\n",
      "Epoch 234/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.1959 - val_loss: 0.2729\n",
      "Epoch 235/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.1954 - val_loss: 0.2727\n",
      "Epoch 236/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.1956 - val_loss: 0.2639\n",
      "Epoch 237/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.1954 - val_loss: 0.2767\n",
      "Epoch 238/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.1941 - val_loss: 0.2536\n",
      "Epoch 239/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.1940 - val_loss: 0.2499\n",
      "Epoch 240/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.1934 - val_loss: 0.2600\n",
      "Epoch 241/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.1948 - val_loss: 0.2571\n",
      "Epoch 242/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.1940 - val_loss: 0.2554\n",
      "Epoch 243/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.1944 - val_loss: 0.2578\n",
      "Epoch 244/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.1945 - val_loss: 0.2603\n",
      "Epoch 245/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.1963 - val_loss: 0.2621\n",
      "Epoch 246/1000\n",
      "59/61 [============================>.] - ETA: 0s - loss: 0.1943Restoring model weights from the end of the best epoch: 211.\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.1943 - val_loss: 0.2513\n",
      "Epoch 246: early stopping\n",
      "7/7 [==============================] - 1s 10ms/step\n",
      "0.20971175097714087\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fde849e5b7b646c8bc37308aa231da53",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.038 MB of 0.038 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch/epoch</td><td>▁▁▁▁▁▂▂▂▃▃▃▃▃▃▄▄▄▄▄▄▄▄▅▅▅▅▅▆▆▆▆▇▇▇▇▇████</td></tr><tr><td>epoch/learning_rate</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>epoch/loss</td><td>█▅▄▂▃▂▂▃▂▂▂▂▁▁▁▁▁▁▂▁▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>epoch/val_loss</td><td>█▇▄▄▄▃▃▃▃▂▃▂▃▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▂▁▁▁▁▁</td></tr><tr><td>rmase_prediction</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch/epoch</td><td>245</td></tr><tr><td>epoch/learning_rate</td><td>0.00049</td></tr><tr><td>epoch/loss</td><td>0.19431</td></tr><tr><td>epoch/val_loss</td><td>0.25133</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">test_7</strong> at: <a href='https://wandb.ai/uu13234-none/sgnate_skate-keras/runs/1ffwoq97' target=\"_blank\">https://wandb.ai/uu13234-none/sgnate_skate-keras/runs/1ffwoq97</a><br/> View project at: <a href='https://wandb.ai/uu13234-none/sgnate_skate-keras' target=\"_blank\">https://wandb.ai/uu13234-none/sgnate_skate-keras</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20241104_151859-1ffwoq97\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.18.3"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\sato\\Desktop\\python\\SIGNATE\\スケートボードの挙動予測\\code-analysis\\wandb\\run-20241104_152634-q3qyjtrd</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/uu13234-none/sgnate_skate-keras/runs/q3qyjtrd' target=\"_blank\">test_8</a></strong> to <a href='https://wandb.ai/uu13234-none/sgnate_skate-keras' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/uu13234-none/sgnate_skate-keras' target=\"_blank\">https://wandb.ai/uu13234-none/sgnate_skate-keras</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/uu13234-none/sgnate_skate-keras/runs/q3qyjtrd' target=\"_blank\">https://wandb.ai/uu13234-none/sgnate_skate-keras/runs/q3qyjtrd</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "61/61 [==============================] - 10s 70ms/step - loss: 1.5126 - val_loss: 1.2610\n",
      "Epoch 2/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 1.0726 - val_loss: 0.9425\n",
      "Epoch 3/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.9105 - val_loss: 0.8264\n",
      "Epoch 4/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.8251 - val_loss: 0.7599\n",
      "Epoch 5/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.7709 - val_loss: 0.7232\n",
      "Epoch 6/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.7326 - val_loss: 0.7493\n",
      "Epoch 7/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.7015 - val_loss: 0.7181\n",
      "Epoch 8/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.6707 - val_loss: 0.7542\n",
      "Epoch 9/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.6980 - val_loss: 0.6622\n",
      "Epoch 10/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.6657 - val_loss: 0.6307\n",
      "Epoch 11/1000\n",
      "61/61 [==============================] - 2s 30ms/step - loss: 0.6041 - val_loss: 0.5684\n",
      "Epoch 12/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.6291 - val_loss: 0.5884\n",
      "Epoch 13/1000\n",
      "61/61 [==============================] - 2s 32ms/step - loss: 0.5717 - val_loss: 0.5426\n",
      "Epoch 14/1000\n",
      "61/61 [==============================] - 2s 28ms/step - loss: 0.5646 - val_loss: 0.5841\n",
      "Epoch 15/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.5261 - val_loss: 0.5198\n",
      "Epoch 16/1000\n",
      "61/61 [==============================] - 2s 28ms/step - loss: 0.5085 - val_loss: 0.5043\n",
      "Epoch 17/1000\n",
      "61/61 [==============================] - 2s 28ms/step - loss: 0.5055 - val_loss: 0.5514\n",
      "Epoch 18/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.5000 - val_loss: 0.5018\n",
      "Epoch 19/1000\n",
      "61/61 [==============================] - 2s 28ms/step - loss: 0.4854 - val_loss: 0.5342\n",
      "Epoch 20/1000\n",
      "61/61 [==============================] - 2s 28ms/step - loss: 0.5176 - val_loss: 0.5809\n",
      "Epoch 21/1000\n",
      "61/61 [==============================] - 2s 28ms/step - loss: 0.4918 - val_loss: 0.5630\n",
      "Epoch 22/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.4777 - val_loss: 0.5898\n",
      "Epoch 23/1000\n",
      "61/61 [==============================] - 2s 28ms/step - loss: 0.4694 - val_loss: 0.5287\n",
      "Epoch 24/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.4322 - val_loss: 0.4825\n",
      "Epoch 25/1000\n",
      "61/61 [==============================] - 2s 28ms/step - loss: 0.4148 - val_loss: 0.4831\n",
      "Epoch 26/1000\n",
      "61/61 [==============================] - 2s 28ms/step - loss: 0.4049 - val_loss: 0.5036\n",
      "Epoch 27/1000\n",
      "61/61 [==============================] - 2s 28ms/step - loss: 0.3996 - val_loss: 0.4762\n",
      "Epoch 28/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.3892 - val_loss: 0.4586\n",
      "Epoch 29/1000\n",
      "61/61 [==============================] - 2s 28ms/step - loss: 0.5078 - val_loss: 0.5512\n",
      "Epoch 30/1000\n",
      "61/61 [==============================] - 2s 28ms/step - loss: 0.4517 - val_loss: 0.5200\n",
      "Epoch 31/1000\n",
      "61/61 [==============================] - 2s 28ms/step - loss: 0.3923 - val_loss: 0.4670\n",
      "Epoch 32/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.3817 - val_loss: 0.4455\n",
      "Epoch 33/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.3772 - val_loss: 0.4597\n",
      "Epoch 34/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.3615 - val_loss: 0.4481\n",
      "Epoch 35/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.3540 - val_loss: 0.4418\n",
      "Epoch 36/1000\n",
      "61/61 [==============================] - 2s 28ms/step - loss: 0.3552 - val_loss: 0.5038\n",
      "Epoch 37/1000\n",
      "61/61 [==============================] - 2s 28ms/step - loss: 0.3724 - val_loss: 0.5905\n",
      "Epoch 38/1000\n",
      "61/61 [==============================] - 2s 28ms/step - loss: 0.3929 - val_loss: 0.5003\n",
      "Epoch 39/1000\n",
      "61/61 [==============================] - 2s 28ms/step - loss: 0.4160 - val_loss: 0.4912\n",
      "Epoch 40/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.3640 - val_loss: 0.4497\n",
      "Epoch 41/1000\n",
      "61/61 [==============================] - 2s 28ms/step - loss: 0.3756 - val_loss: 0.5288\n",
      "Epoch 42/1000\n",
      "61/61 [==============================] - 2s 28ms/step - loss: 0.4919 - val_loss: 0.6255\n",
      "Epoch 43/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.4401 - val_loss: 0.4971\n",
      "Epoch 44/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.4230 - val_loss: 0.5456\n",
      "Epoch 45/1000\n",
      "61/61 [==============================] - 2s 28ms/step - loss: 0.3976 - val_loss: 0.4964\n",
      "Epoch 46/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.3814 - val_loss: 0.5183\n",
      "Epoch 47/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.3741 - val_loss: 0.4950\n",
      "Epoch 48/1000\n",
      "61/61 [==============================] - 2s 28ms/step - loss: 0.3378 - val_loss: 0.4518\n",
      "Epoch 49/1000\n",
      "61/61 [==============================] - 2s 28ms/step - loss: 0.3272 - val_loss: 0.4290\n",
      "Epoch 50/1000\n",
      "61/61 [==============================] - 2s 28ms/step - loss: 0.3272 - val_loss: 0.4145\n",
      "Epoch 51/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.3166 - val_loss: 0.4247\n",
      "Epoch 52/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.3181 - val_loss: 0.4053\n",
      "Epoch 53/1000\n",
      "61/61 [==============================] - 2s 28ms/step - loss: 0.3028 - val_loss: 0.4029\n",
      "Epoch 54/1000\n",
      "61/61 [==============================] - 2s 28ms/step - loss: 0.3062 - val_loss: 0.4479\n",
      "Epoch 55/1000\n",
      "61/61 [==============================] - 2s 28ms/step - loss: 0.3025 - val_loss: 0.4045\n",
      "Epoch 56/1000\n",
      "61/61 [==============================] - 2s 28ms/step - loss: 0.3001 - val_loss: 0.4071\n",
      "Epoch 57/1000\n",
      "61/61 [==============================] - 2s 28ms/step - loss: 0.2943 - val_loss: 0.3887\n",
      "Epoch 58/1000\n",
      "61/61 [==============================] - 2s 28ms/step - loss: 0.2874 - val_loss: 0.4009\n",
      "Epoch 59/1000\n",
      "61/61 [==============================] - 2s 27ms/step - loss: 0.2884 - val_loss: 0.3976\n",
      "Epoch 60/1000\n",
      "61/61 [==============================] - 2s 28ms/step - loss: 0.2921 - val_loss: 0.4012\n",
      "Epoch 61/1000\n",
      "61/61 [==============================] - 2s 28ms/step - loss: 0.2866 - val_loss: 0.3833\n",
      "Epoch 62/1000\n",
      "61/61 [==============================] - 2s 28ms/step - loss: 0.2789 - val_loss: 0.3848\n",
      "Epoch 63/1000\n",
      "61/61 [==============================] - 2s 28ms/step - loss: 0.2807 - val_loss: 0.3776\n",
      "Epoch 64/1000\n",
      "61/61 [==============================] - 2s 28ms/step - loss: 0.2780 - val_loss: 0.3824\n",
      "Epoch 65/1000\n",
      "61/61 [==============================] - 2s 28ms/step - loss: 0.2767 - val_loss: 0.3840\n",
      "Epoch 66/1000\n",
      "61/61 [==============================] - 2s 28ms/step - loss: 0.2758 - val_loss: 0.3805\n",
      "Epoch 67/1000\n",
      "61/61 [==============================] - 2s 28ms/step - loss: 0.2719 - val_loss: 0.3803\n",
      "Epoch 68/1000\n",
      "61/61 [==============================] - 2s 27ms/step - loss: 0.2688 - val_loss: 0.3818\n",
      "Epoch 69/1000\n",
      "61/61 [==============================] - 2s 28ms/step - loss: 0.2731 - val_loss: 0.3740\n",
      "Epoch 70/1000\n",
      "61/61 [==============================] - 2s 28ms/step - loss: 0.2692 - val_loss: 0.3695\n",
      "Epoch 71/1000\n",
      "61/61 [==============================] - 2s 28ms/step - loss: 0.2704 - val_loss: 0.3666\n",
      "Epoch 72/1000\n",
      "61/61 [==============================] - 2s 27ms/step - loss: 0.2662 - val_loss: 0.3770\n",
      "Epoch 73/1000\n",
      "61/61 [==============================] - 2s 27ms/step - loss: 0.2674 - val_loss: 0.3652\n",
      "Epoch 74/1000\n",
      "61/61 [==============================] - 2s 28ms/step - loss: 0.2700 - val_loss: 0.3703\n",
      "Epoch 75/1000\n",
      "61/61 [==============================] - 2s 27ms/step - loss: 0.2630 - val_loss: 0.3726\n",
      "Epoch 76/1000\n",
      "61/61 [==============================] - 2s 27ms/step - loss: 0.2628 - val_loss: 0.3646\n",
      "Epoch 77/1000\n",
      "61/61 [==============================] - 2s 27ms/step - loss: 0.2587 - val_loss: 0.3650\n",
      "Epoch 78/1000\n",
      "61/61 [==============================] - 2s 27ms/step - loss: 0.2595 - val_loss: 0.3596\n",
      "Epoch 79/1000\n",
      "61/61 [==============================] - 2s 27ms/step - loss: 0.2569 - val_loss: 0.3655\n",
      "Epoch 80/1000\n",
      "61/61 [==============================] - 2s 27ms/step - loss: 0.2568 - val_loss: 0.3698\n",
      "Epoch 81/1000\n",
      "61/61 [==============================] - 2s 27ms/step - loss: 0.2574 - val_loss: 0.3736\n",
      "Epoch 82/1000\n",
      "61/61 [==============================] - 2s 27ms/step - loss: 0.2569 - val_loss: 0.3629\n",
      "Epoch 83/1000\n",
      "61/61 [==============================] - 2s 27ms/step - loss: 0.2559 - val_loss: 0.3648\n",
      "Epoch 84/1000\n",
      "61/61 [==============================] - 2s 27ms/step - loss: 0.2535 - val_loss: 0.3594\n",
      "Epoch 85/1000\n",
      "61/61 [==============================] - 2s 27ms/step - loss: 0.2533 - val_loss: 0.3599\n",
      "Epoch 86/1000\n",
      "61/61 [==============================] - 2s 27ms/step - loss: 0.2568 - val_loss: 0.3607\n",
      "Epoch 87/1000\n",
      "61/61 [==============================] - 2s 28ms/step - loss: 0.2514 - val_loss: 0.3639\n",
      "Epoch 88/1000\n",
      "61/61 [==============================] - 2s 28ms/step - loss: 0.2510 - val_loss: 0.3569\n",
      "Epoch 89/1000\n",
      "61/61 [==============================] - 2s 27ms/step - loss: 0.2476 - val_loss: 0.3596\n",
      "Epoch 90/1000\n",
      "61/61 [==============================] - 2s 27ms/step - loss: 0.2481 - val_loss: 0.3587\n",
      "Epoch 91/1000\n",
      "61/61 [==============================] - 2s 28ms/step - loss: 0.2501 - val_loss: 0.3475\n",
      "Epoch 92/1000\n",
      "61/61 [==============================] - 2s 27ms/step - loss: 0.2460 - val_loss: 0.3458\n",
      "Epoch 93/1000\n",
      "61/61 [==============================] - 2s 28ms/step - loss: 0.2557 - val_loss: 0.3866\n",
      "Epoch 94/1000\n",
      "61/61 [==============================] - 2s 28ms/step - loss: 0.2612 - val_loss: 0.3756\n",
      "Epoch 95/1000\n",
      "61/61 [==============================] - 2s 28ms/step - loss: 0.2516 - val_loss: 0.3630\n",
      "Epoch 96/1000\n",
      "61/61 [==============================] - 2s 28ms/step - loss: 0.2471 - val_loss: 0.3469\n",
      "Epoch 97/1000\n",
      "61/61 [==============================] - 2s 28ms/step - loss: 0.2439 - val_loss: 0.3411\n",
      "Epoch 98/1000\n",
      "61/61 [==============================] - 2s 28ms/step - loss: 0.2415 - val_loss: 0.3305\n",
      "Epoch 99/1000\n",
      "61/61 [==============================] - 2s 28ms/step - loss: 0.2411 - val_loss: 0.3544\n",
      "Epoch 100/1000\n",
      "61/61 [==============================] - 2s 28ms/step - loss: 0.2438 - val_loss: 0.3568\n",
      "Epoch 101/1000\n",
      "61/61 [==============================] - 2s 28ms/step - loss: 0.2381 - val_loss: 0.3390\n",
      "Epoch 102/1000\n",
      "61/61 [==============================] - 2s 28ms/step - loss: 0.2406 - val_loss: 0.3491\n",
      "Epoch 103/1000\n",
      "61/61 [==============================] - 2s 28ms/step - loss: 0.2393 - val_loss: 0.3348\n",
      "Epoch 104/1000\n",
      "61/61 [==============================] - 2s 27ms/step - loss: 0.2388 - val_loss: 0.3376\n",
      "Epoch 105/1000\n",
      "61/61 [==============================] - 2s 28ms/step - loss: 0.2362 - val_loss: 0.3254\n",
      "Epoch 106/1000\n",
      "61/61 [==============================] - 2s 27ms/step - loss: 0.2356 - val_loss: 0.3402\n",
      "Epoch 107/1000\n",
      "61/61 [==============================] - 2s 28ms/step - loss: 0.2355 - val_loss: 0.3287\n",
      "Epoch 108/1000\n",
      "61/61 [==============================] - 2s 28ms/step - loss: 0.2319 - val_loss: 0.3237\n",
      "Epoch 109/1000\n",
      "61/61 [==============================] - 2s 28ms/step - loss: 0.2323 - val_loss: 0.3257\n",
      "Epoch 110/1000\n",
      "61/61 [==============================] - 2s 28ms/step - loss: 0.2319 - val_loss: 0.3266\n",
      "Epoch 111/1000\n",
      "61/61 [==============================] - 2s 28ms/step - loss: 0.2304 - val_loss: 0.3191\n",
      "Epoch 112/1000\n",
      "61/61 [==============================] - 2s 28ms/step - loss: 0.2310 - val_loss: 0.3186\n",
      "Epoch 113/1000\n",
      "61/61 [==============================] - 2s 28ms/step - loss: 0.2317 - val_loss: 0.3351\n",
      "Epoch 114/1000\n",
      "61/61 [==============================] - 2s 28ms/step - loss: 0.2303 - val_loss: 0.3119\n",
      "Epoch 115/1000\n",
      "61/61 [==============================] - 2s 27ms/step - loss: 0.2308 - val_loss: 0.3255\n",
      "Epoch 116/1000\n",
      "61/61 [==============================] - 2s 28ms/step - loss: 0.2327 - val_loss: 0.3215\n",
      "Epoch 117/1000\n",
      "61/61 [==============================] - 2s 28ms/step - loss: 0.2319 - val_loss: 0.3353\n",
      "Epoch 118/1000\n",
      "61/61 [==============================] - 2s 28ms/step - loss: 0.2291 - val_loss: 0.3306\n",
      "Epoch 119/1000\n",
      "61/61 [==============================] - 2s 28ms/step - loss: 0.2303 - val_loss: 0.3292\n",
      "Epoch 120/1000\n",
      "61/61 [==============================] - 2s 28ms/step - loss: 0.2284 - val_loss: 0.3318\n",
      "Epoch 121/1000\n",
      "61/61 [==============================] - 2s 28ms/step - loss: 0.2288 - val_loss: 0.3247\n",
      "Epoch 122/1000\n",
      "61/61 [==============================] - 2s 28ms/step - loss: 0.2273 - val_loss: 0.3222\n",
      "Epoch 123/1000\n",
      "61/61 [==============================] - 2s 28ms/step - loss: 0.2290 - val_loss: 0.3264\n",
      "Epoch 124/1000\n",
      "61/61 [==============================] - 2s 28ms/step - loss: 0.2276 - val_loss: 0.3312\n",
      "Epoch 125/1000\n",
      "61/61 [==============================] - 2s 28ms/step - loss: 0.2278 - val_loss: 0.3141\n",
      "Epoch 126/1000\n",
      "61/61 [==============================] - 2s 28ms/step - loss: 0.2373 - val_loss: 0.3645\n",
      "Epoch 127/1000\n",
      "61/61 [==============================] - 2s 28ms/step - loss: 0.2689 - val_loss: 0.4322\n",
      "Epoch 128/1000\n",
      "61/61 [==============================] - 2s 28ms/step - loss: 0.5358 - val_loss: 0.8637\n",
      "Epoch 129/1000\n",
      "61/61 [==============================] - 2s 28ms/step - loss: 0.6005 - val_loss: 0.5356\n",
      "Epoch 130/1000\n",
      "61/61 [==============================] - 2s 28ms/step - loss: 0.4343 - val_loss: 0.5290\n",
      "Epoch 131/1000\n",
      "61/61 [==============================] - 2s 28ms/step - loss: 0.3739 - val_loss: 0.4434\n",
      "Epoch 132/1000\n",
      "61/61 [==============================] - 2s 28ms/step - loss: 0.3847 - val_loss: 0.5828\n",
      "Epoch 133/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.4141 - val_loss: 0.4577\n",
      "Epoch 134/1000\n",
      "61/61 [==============================] - 2s 28ms/step - loss: 0.3309 - val_loss: 0.4358\n",
      "Epoch 135/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.3078 - val_loss: 0.4440\n",
      "Epoch 136/1000\n",
      "61/61 [==============================] - 2s 28ms/step - loss: 0.2904 - val_loss: 0.4338\n",
      "Epoch 137/1000\n",
      "61/61 [==============================] - 2s 28ms/step - loss: 0.2836 - val_loss: 0.4134\n",
      "Epoch 138/1000\n",
      "61/61 [==============================] - 2s 28ms/step - loss: 0.2637 - val_loss: 0.4071\n",
      "Epoch 139/1000\n",
      "61/61 [==============================] - 2s 28ms/step - loss: 0.2590 - val_loss: 0.3867\n",
      "Epoch 140/1000\n",
      "61/61 [==============================] - 2s 28ms/step - loss: 0.2568 - val_loss: 0.3848\n",
      "Epoch 141/1000\n",
      "61/61 [==============================] - 2s 28ms/step - loss: 0.2482 - val_loss: 0.3832\n",
      "Epoch 142/1000\n",
      "61/61 [==============================] - 2s 28ms/step - loss: 0.2431 - val_loss: 0.3680\n",
      "Epoch 143/1000\n",
      "61/61 [==============================] - 2s 28ms/step - loss: 0.2426 - val_loss: 0.3622\n",
      "Epoch 144/1000\n",
      "61/61 [==============================] - 2s 28ms/step - loss: 0.2423 - val_loss: 0.3842\n",
      "Epoch 145/1000\n",
      "61/61 [==============================] - 2s 28ms/step - loss: 0.2416 - val_loss: 0.3718\n",
      "Epoch 146/1000\n",
      "61/61 [==============================] - 2s 28ms/step - loss: 0.2355 - val_loss: 0.3453\n",
      "Epoch 147/1000\n",
      "61/61 [==============================] - 2s 28ms/step - loss: 0.2361 - val_loss: 0.3533\n",
      "Epoch 148/1000\n",
      "61/61 [==============================] - 2s 28ms/step - loss: 0.2311 - val_loss: 0.3573\n",
      "Epoch 149/1000\n",
      "61/61 [==============================] - ETA: 0s - loss: 0.2331Restoring model weights from the end of the best epoch: 114.\n",
      "61/61 [==============================] - 2s 27ms/step - loss: 0.2331 - val_loss: 0.3474\n",
      "Epoch 149: early stopping\n",
      "7/7 [==============================] - 1s 9ms/step\n",
      "0.25310046886251036\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "556d71558f8e4a64bc4a554b2070a83a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.025 MB of 0.025 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch/epoch</td><td>▁▁▁▁▁▁▂▂▂▂▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇████</td></tr><tr><td>epoch/learning_rate</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>epoch/loss</td><td>█▄▄▄▃▂▂▃▂▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▃▂▂▁▁</td></tr><tr><td>epoch/val_loss</td><td>█▇▇▅▄▄▄▄▄▃▄▄▄▃▃▂▂▂▂▂▂▂▂▂▂▂▁▂▁▁▁▁▁▁▃▂▂▂▂▁</td></tr><tr><td>rmase_prediction</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch/epoch</td><td>148</td></tr><tr><td>epoch/learning_rate</td><td>0.00049</td></tr><tr><td>epoch/loss</td><td>0.23314</td></tr><tr><td>epoch/val_loss</td><td>0.34741</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">test_8</strong> at: <a href='https://wandb.ai/uu13234-none/sgnate_skate-keras/runs/q3qyjtrd' target=\"_blank\">https://wandb.ai/uu13234-none/sgnate_skate-keras/runs/q3qyjtrd</a><br/> View project at: <a href='https://wandb.ai/uu13234-none/sgnate_skate-keras' target=\"_blank\">https://wandb.ai/uu13234-none/sgnate_skate-keras</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20241104_152634-q3qyjtrd\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.18.3"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\sato\\Desktop\\python\\SIGNATE\\スケートボードの挙動予測\\code-analysis\\wandb\\run-20241104_153103-55olrfy4</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/uu13234-none/sgnate_skate-keras/runs/55olrfy4' target=\"_blank\">test_9</a></strong> to <a href='https://wandb.ai/uu13234-none/sgnate_skate-keras' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/uu13234-none/sgnate_skate-keras' target=\"_blank\">https://wandb.ai/uu13234-none/sgnate_skate-keras</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/uu13234-none/sgnate_skate-keras/runs/55olrfy4' target=\"_blank\">https://wandb.ai/uu13234-none/sgnate_skate-keras/runs/55olrfy4</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      " 5/61 [=>............................] - ETA: 3s - loss: 2.3438WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0345s vs `on_train_batch_end` time: 0.0390s). Check your callbacks.\n",
      "61/61 [==============================] - 9s 55ms/step - loss: 1.5226 - val_loss: 1.2082\n",
      "Epoch 2/1000\n",
      "61/61 [==============================] - 2s 28ms/step - loss: 1.0325 - val_loss: 0.9618\n",
      "Epoch 3/1000\n",
      "61/61 [==============================] - 2s 28ms/step - loss: 0.9024 - val_loss: 0.8646\n",
      "Epoch 4/1000\n",
      "61/61 [==============================] - 2s 28ms/step - loss: 0.8087 - val_loss: 0.8381\n",
      "Epoch 5/1000\n",
      "61/61 [==============================] - 2s 27ms/step - loss: 0.7769 - val_loss: 0.7620\n",
      "Epoch 6/1000\n",
      "61/61 [==============================] - 2s 28ms/step - loss: 0.7481 - val_loss: 0.8019\n",
      "Epoch 7/1000\n",
      "61/61 [==============================] - 2s 28ms/step - loss: 0.6941 - val_loss: 0.6117\n",
      "Epoch 8/1000\n",
      "61/61 [==============================] - 2s 28ms/step - loss: 0.6459 - val_loss: 0.7369\n",
      "Epoch 9/1000\n",
      "61/61 [==============================] - 2s 28ms/step - loss: 0.6770 - val_loss: 0.6925\n",
      "Epoch 10/1000\n",
      "61/61 [==============================] - 2s 28ms/step - loss: 0.6301 - val_loss: 0.6336\n",
      "Epoch 11/1000\n",
      "61/61 [==============================] - 2s 28ms/step - loss: 0.6056 - val_loss: 0.6559\n",
      "Epoch 12/1000\n",
      "61/61 [==============================] - 2s 28ms/step - loss: 0.5884 - val_loss: 0.6554\n",
      "Epoch 13/1000\n",
      "61/61 [==============================] - 2s 28ms/step - loss: 0.6084 - val_loss: 0.6732\n",
      "Epoch 14/1000\n",
      "61/61 [==============================] - 2s 28ms/step - loss: 0.5350 - val_loss: 0.5962\n",
      "Epoch 15/1000\n",
      "61/61 [==============================] - 2s 27ms/step - loss: 0.5242 - val_loss: 0.5332\n",
      "Epoch 16/1000\n",
      "61/61 [==============================] - 2s 28ms/step - loss: 0.4985 - val_loss: 0.5313\n",
      "Epoch 17/1000\n",
      "61/61 [==============================] - 2s 28ms/step - loss: 0.4986 - val_loss: 0.4975\n",
      "Epoch 18/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.4695 - val_loss: 0.5542\n",
      "Epoch 19/1000\n",
      "61/61 [==============================] - 2s 28ms/step - loss: 0.4645 - val_loss: 0.5229\n",
      "Epoch 20/1000\n",
      "61/61 [==============================] - 2s 28ms/step - loss: 0.4532 - val_loss: 0.5284\n",
      "Epoch 21/1000\n",
      "61/61 [==============================] - 2s 28ms/step - loss: 0.4407 - val_loss: 0.5121\n",
      "Epoch 22/1000\n",
      "61/61 [==============================] - 2s 28ms/step - loss: 0.4414 - val_loss: 0.5607\n",
      "Epoch 23/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.4244 - val_loss: 0.4771\n",
      "Epoch 24/1000\n",
      "61/61 [==============================] - 2s 28ms/step - loss: 0.4588 - val_loss: 0.5611\n",
      "Epoch 25/1000\n",
      "61/61 [==============================] - 2s 28ms/step - loss: 0.4474 - val_loss: 0.4771\n",
      "Epoch 26/1000\n",
      "61/61 [==============================] - 2s 28ms/step - loss: 0.4116 - val_loss: 0.4697\n",
      "Epoch 27/1000\n",
      "61/61 [==============================] - 2s 28ms/step - loss: 0.4588 - val_loss: 0.5663\n",
      "Epoch 28/1000\n",
      "61/61 [==============================] - 2s 28ms/step - loss: 0.4660 - val_loss: 0.6143\n",
      "Epoch 29/1000\n",
      "61/61 [==============================] - 2s 28ms/step - loss: 0.4606 - val_loss: 0.6050\n",
      "Epoch 30/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.5787 - val_loss: 0.6858\n",
      "Epoch 31/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.4785 - val_loss: 0.5876\n",
      "Epoch 32/1000\n",
      "61/61 [==============================] - 2s 28ms/step - loss: 0.4222 - val_loss: 0.5159\n",
      "Epoch 33/1000\n",
      "61/61 [==============================] - 2s 28ms/step - loss: 0.5006 - val_loss: 0.6175\n",
      "Epoch 34/1000\n",
      "61/61 [==============================] - 2s 28ms/step - loss: 0.4533 - val_loss: 0.5254\n",
      "Epoch 35/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.4575 - val_loss: 0.5162\n",
      "Epoch 36/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.4232 - val_loss: 0.4884\n",
      "Epoch 37/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.3815 - val_loss: 0.4735\n",
      "Epoch 38/1000\n",
      "61/61 [==============================] - 2s 28ms/step - loss: 0.3711 - val_loss: 0.4458\n",
      "Epoch 39/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.3578 - val_loss: 0.4305\n",
      "Epoch 40/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.3445 - val_loss: 0.4218\n",
      "Epoch 41/1000\n",
      "61/61 [==============================] - 2s 28ms/step - loss: 0.3428 - val_loss: 0.4289\n",
      "Epoch 42/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.3396 - val_loss: 0.4094\n",
      "Epoch 43/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.3312 - val_loss: 0.3932\n",
      "Epoch 44/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.3242 - val_loss: 0.3802\n",
      "Epoch 45/1000\n",
      "61/61 [==============================] - 2s 28ms/step - loss: 0.3342 - val_loss: 0.5270\n",
      "Epoch 46/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.3895 - val_loss: 0.5468\n",
      "Epoch 47/1000\n",
      "61/61 [==============================] - 2s 28ms/step - loss: 0.3612 - val_loss: 0.4443\n",
      "Epoch 48/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.3545 - val_loss: 0.4704\n",
      "Epoch 49/1000\n",
      "61/61 [==============================] - 2s 28ms/step - loss: 0.3355 - val_loss: 0.4221\n",
      "Epoch 50/1000\n",
      "61/61 [==============================] - 2s 28ms/step - loss: 0.3212 - val_loss: 0.3786\n",
      "Epoch 51/1000\n",
      "61/61 [==============================] - 2s 28ms/step - loss: 0.3140 - val_loss: 0.3851\n",
      "Epoch 52/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.3076 - val_loss: 0.3630\n",
      "Epoch 53/1000\n",
      "61/61 [==============================] - 2s 28ms/step - loss: 0.3101 - val_loss: 0.3824\n",
      "Epoch 54/1000\n",
      "61/61 [==============================] - 2s 28ms/step - loss: 0.3051 - val_loss: 0.3652\n",
      "Epoch 55/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.3014 - val_loss: 0.3721\n",
      "Epoch 56/1000\n",
      "61/61 [==============================] - 2s 28ms/step - loss: 0.2981 - val_loss: 0.3558\n",
      "Epoch 57/1000\n",
      "61/61 [==============================] - 2s 28ms/step - loss: 0.2938 - val_loss: 0.3687\n",
      "Epoch 58/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.2881 - val_loss: 0.3565\n",
      "Epoch 59/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.2876 - val_loss: 0.3545\n",
      "Epoch 60/1000\n",
      "61/61 [==============================] - 2s 33ms/step - loss: 0.2899 - val_loss: 0.3539\n",
      "Epoch 61/1000\n",
      "61/61 [==============================] - 3s 50ms/step - loss: 0.2830 - val_loss: 0.3542\n",
      "Epoch 62/1000\n",
      "61/61 [==============================] - 2s 28ms/step - loss: 0.2797 - val_loss: 0.3462\n",
      "Epoch 63/1000\n",
      "61/61 [==============================] - 2s 28ms/step - loss: 0.2808 - val_loss: 0.3967\n",
      "Epoch 64/1000\n",
      "61/61 [==============================] - 2s 28ms/step - loss: 0.3385 - val_loss: 0.4434\n",
      "Epoch 65/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.3079 - val_loss: 0.3593\n",
      "Epoch 66/1000\n",
      "61/61 [==============================] - 2s 28ms/step - loss: 0.3106 - val_loss: 0.3985\n",
      "Epoch 67/1000\n",
      "61/61 [==============================] - 2s 28ms/step - loss: 0.3130 - val_loss: 0.3717\n",
      "Epoch 68/1000\n",
      "61/61 [==============================] - 2s 28ms/step - loss: 0.2883 - val_loss: 0.3613\n",
      "Epoch 69/1000\n",
      "61/61 [==============================] - 2s 28ms/step - loss: 0.2800 - val_loss: 0.3476\n",
      "Epoch 70/1000\n",
      "61/61 [==============================] - 2s 28ms/step - loss: 0.2728 - val_loss: 0.3346\n",
      "Epoch 71/1000\n",
      "61/61 [==============================] - 2s 28ms/step - loss: 0.2735 - val_loss: 0.3493\n",
      "Epoch 72/1000\n",
      "61/61 [==============================] - 2s 28ms/step - loss: 0.2708 - val_loss: 0.3389\n",
      "Epoch 73/1000\n",
      "61/61 [==============================] - 2s 28ms/step - loss: 0.2714 - val_loss: 0.3675\n",
      "Epoch 74/1000\n",
      "61/61 [==============================] - 2s 28ms/step - loss: 0.2710 - val_loss: 0.3275\n",
      "Epoch 75/1000\n",
      "61/61 [==============================] - 2s 28ms/step - loss: 0.2664 - val_loss: 0.3553\n",
      "Epoch 76/1000\n",
      "61/61 [==============================] - 2s 28ms/step - loss: 0.2650 - val_loss: 0.3426\n",
      "Epoch 77/1000\n",
      "61/61 [==============================] - 2s 28ms/step - loss: 0.2643 - val_loss: 0.3237\n",
      "Epoch 78/1000\n",
      "61/61 [==============================] - 2s 28ms/step - loss: 0.3004 - val_loss: 0.3545\n",
      "Epoch 79/1000\n",
      "61/61 [==============================] - 2s 27ms/step - loss: 0.2695 - val_loss: 0.3325\n",
      "Epoch 80/1000\n",
      "61/61 [==============================] - 2s 28ms/step - loss: 0.2595 - val_loss: 0.3247\n",
      "Epoch 81/1000\n",
      "61/61 [==============================] - 2s 27ms/step - loss: 0.2600 - val_loss: 0.3293\n",
      "Epoch 82/1000\n",
      "61/61 [==============================] - 2s 28ms/step - loss: 0.2588 - val_loss: 0.3227\n",
      "Epoch 83/1000\n",
      "61/61 [==============================] - 2s 27ms/step - loss: 0.2587 - val_loss: 0.3247\n",
      "Epoch 84/1000\n",
      "61/61 [==============================] - 2s 28ms/step - loss: 0.2752 - val_loss: 0.3422\n",
      "Epoch 85/1000\n",
      "61/61 [==============================] - 2s 28ms/step - loss: 0.2615 - val_loss: 0.4037\n",
      "Epoch 86/1000\n",
      "61/61 [==============================] - 2s 28ms/step - loss: 0.3376 - val_loss: 0.4453\n",
      "Epoch 87/1000\n",
      "61/61 [==============================] - 2s 28ms/step - loss: 0.2847 - val_loss: 0.3386\n",
      "Epoch 88/1000\n",
      "61/61 [==============================] - 2s 28ms/step - loss: 0.2665 - val_loss: 0.3664\n",
      "Epoch 89/1000\n",
      "61/61 [==============================] - 2s 28ms/step - loss: 0.2687 - val_loss: 0.3261\n",
      "Epoch 90/1000\n",
      "61/61 [==============================] - 2s 28ms/step - loss: 0.2599 - val_loss: 0.3306\n",
      "Epoch 91/1000\n",
      "61/61 [==============================] - 2s 28ms/step - loss: 0.2604 - val_loss: 0.4230\n",
      "Epoch 92/1000\n",
      "61/61 [==============================] - 2s 28ms/step - loss: 0.3140 - val_loss: 0.3896\n",
      "Epoch 93/1000\n",
      "61/61 [==============================] - 2s 28ms/step - loss: 0.2794 - val_loss: 0.3331\n",
      "Epoch 94/1000\n",
      "61/61 [==============================] - 2s 28ms/step - loss: 0.2646 - val_loss: 0.3186\n",
      "Epoch 95/1000\n",
      "61/61 [==============================] - 2s 28ms/step - loss: 0.2557 - val_loss: 0.3218\n",
      "Epoch 96/1000\n",
      "61/61 [==============================] - 2s 28ms/step - loss: 0.2494 - val_loss: 0.3028\n",
      "Epoch 97/1000\n",
      "61/61 [==============================] - 2s 28ms/step - loss: 0.2444 - val_loss: 0.3035\n",
      "Epoch 98/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.2519 - val_loss: 0.3242\n",
      "Epoch 99/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.2472 - val_loss: 0.3125\n",
      "Epoch 100/1000\n",
      "61/61 [==============================] - 2s 28ms/step - loss: 0.2447 - val_loss: 0.3037\n",
      "Epoch 101/1000\n",
      "61/61 [==============================] - 2s 28ms/step - loss: 0.2439 - val_loss: 0.2990\n",
      "Epoch 102/1000\n",
      "61/61 [==============================] - 2s 27ms/step - loss: 0.2414 - val_loss: 0.3047\n",
      "Epoch 103/1000\n",
      "61/61 [==============================] - 2s 28ms/step - loss: 0.2391 - val_loss: 0.2986\n",
      "Epoch 104/1000\n",
      "61/61 [==============================] - 2s 28ms/step - loss: 0.2408 - val_loss: 0.3055\n",
      "Epoch 105/1000\n",
      "61/61 [==============================] - 2s 28ms/step - loss: 0.2391 - val_loss: 0.3034\n",
      "Epoch 106/1000\n",
      "61/61 [==============================] - 2s 28ms/step - loss: 0.2385 - val_loss: 0.3002\n",
      "Epoch 107/1000\n",
      "61/61 [==============================] - 2s 28ms/step - loss: 0.2346 - val_loss: 0.2845\n",
      "Epoch 108/1000\n",
      "61/61 [==============================] - 2s 28ms/step - loss: 0.2343 - val_loss: 0.2889\n",
      "Epoch 109/1000\n",
      "61/61 [==============================] - 2s 28ms/step - loss: 0.2365 - val_loss: 0.2872\n",
      "Epoch 110/1000\n",
      "61/61 [==============================] - 2s 27ms/step - loss: 0.2352 - val_loss: 0.2877\n",
      "Epoch 111/1000\n",
      "61/61 [==============================] - 2s 27ms/step - loss: 0.2349 - val_loss: 0.2943\n",
      "Epoch 112/1000\n",
      "61/61 [==============================] - 2s 28ms/step - loss: 0.2350 - val_loss: 0.2911\n",
      "Epoch 113/1000\n",
      "61/61 [==============================] - 2s 28ms/step - loss: 0.2340 - val_loss: 0.2906\n",
      "Epoch 114/1000\n",
      "61/61 [==============================] - 2s 28ms/step - loss: 0.2311 - val_loss: 0.2948\n",
      "Epoch 115/1000\n",
      "61/61 [==============================] - 2s 28ms/step - loss: 0.2304 - val_loss: 0.2934\n",
      "Epoch 116/1000\n",
      "61/61 [==============================] - 2s 28ms/step - loss: 0.2316 - val_loss: 0.2933\n",
      "Epoch 117/1000\n",
      "61/61 [==============================] - 2s 28ms/step - loss: 0.2306 - val_loss: 0.2910\n",
      "Epoch 118/1000\n",
      "61/61 [==============================] - 2s 28ms/step - loss: 0.2301 - val_loss: 0.2833\n",
      "Epoch 119/1000\n",
      "61/61 [==============================] - 2s 28ms/step - loss: 0.2299 - val_loss: 0.2819\n",
      "Epoch 120/1000\n",
      "61/61 [==============================] - 2s 28ms/step - loss: 0.2295 - val_loss: 0.2800\n",
      "Epoch 121/1000\n",
      "61/61 [==============================] - 2s 28ms/step - loss: 0.2294 - val_loss: 0.2946\n",
      "Epoch 122/1000\n",
      "61/61 [==============================] - 2s 28ms/step - loss: 0.2275 - val_loss: 0.2834\n",
      "Epoch 123/1000\n",
      "61/61 [==============================] - 2s 28ms/step - loss: 0.2282 - val_loss: 0.2921\n",
      "Epoch 124/1000\n",
      "61/61 [==============================] - 2s 28ms/step - loss: 0.2276 - val_loss: 0.2756\n",
      "Epoch 125/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.2254 - val_loss: 0.2779\n",
      "Epoch 126/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.2226 - val_loss: 0.2830\n",
      "Epoch 127/1000\n",
      "61/61 [==============================] - 2s 28ms/step - loss: 0.2251 - val_loss: 0.2778\n",
      "Epoch 128/1000\n",
      "61/61 [==============================] - 2s 28ms/step - loss: 0.2246 - val_loss: 0.2816\n",
      "Epoch 129/1000\n",
      "61/61 [==============================] - 2s 28ms/step - loss: 0.2251 - val_loss: 0.2809\n",
      "Epoch 130/1000\n",
      "61/61 [==============================] - 2s 28ms/step - loss: 0.2233 - val_loss: 0.2766\n",
      "Epoch 131/1000\n",
      "61/61 [==============================] - 2s 28ms/step - loss: 0.2227 - val_loss: 0.2803\n",
      "Epoch 132/1000\n",
      "61/61 [==============================] - 2s 28ms/step - loss: 0.2231 - val_loss: 0.2761\n",
      "Epoch 133/1000\n",
      "61/61 [==============================] - 2s 28ms/step - loss: 0.2235 - val_loss: 0.2882\n",
      "Epoch 134/1000\n",
      "61/61 [==============================] - 2s 28ms/step - loss: 0.2245 - val_loss: 0.2686\n",
      "Epoch 135/1000\n",
      "61/61 [==============================] - 2s 28ms/step - loss: 0.2204 - val_loss: 0.2707\n",
      "Epoch 136/1000\n",
      "61/61 [==============================] - 2s 28ms/step - loss: 0.2222 - val_loss: 0.2712\n",
      "Epoch 137/1000\n",
      "61/61 [==============================] - 2s 28ms/step - loss: 0.2201 - val_loss: 0.2657\n",
      "Epoch 138/1000\n",
      "61/61 [==============================] - 2s 28ms/step - loss: 0.2173 - val_loss: 0.2698\n",
      "Epoch 139/1000\n",
      "61/61 [==============================] - 2s 28ms/step - loss: 0.2203 - val_loss: 0.2727\n",
      "Epoch 140/1000\n",
      "61/61 [==============================] - 2s 28ms/step - loss: 0.2188 - val_loss: 0.2803\n",
      "Epoch 141/1000\n",
      "61/61 [==============================] - 2s 28ms/step - loss: 0.2168 - val_loss: 0.2656\n",
      "Epoch 142/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.2176 - val_loss: 0.2694\n",
      "Epoch 143/1000\n",
      "61/61 [==============================] - 2s 28ms/step - loss: 0.2181 - val_loss: 0.2664\n",
      "Epoch 144/1000\n",
      "61/61 [==============================] - 2s 28ms/step - loss: 0.2212 - val_loss: 0.2713\n",
      "Epoch 145/1000\n",
      "61/61 [==============================] - 2s 28ms/step - loss: 0.2199 - val_loss: 0.2717\n",
      "Epoch 146/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.2177 - val_loss: 0.2694\n",
      "Epoch 147/1000\n",
      "61/61 [==============================] - 2s 28ms/step - loss: 0.2182 - val_loss: 0.2722\n",
      "Epoch 148/1000\n",
      "61/61 [==============================] - 2s 28ms/step - loss: 0.2171 - val_loss: 0.2646\n",
      "Epoch 149/1000\n",
      "61/61 [==============================] - 2s 28ms/step - loss: 0.2150 - val_loss: 0.2625\n",
      "Epoch 150/1000\n",
      "61/61 [==============================] - 2s 28ms/step - loss: 0.2156 - val_loss: 0.2743\n",
      "Epoch 151/1000\n",
      "61/61 [==============================] - 2s 28ms/step - loss: 0.2171 - val_loss: 0.2679\n",
      "Epoch 152/1000\n",
      "61/61 [==============================] - 2s 28ms/step - loss: 0.2154 - val_loss: 0.2705\n",
      "Epoch 153/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.2155 - val_loss: 0.2624\n",
      "Epoch 154/1000\n",
      "61/61 [==============================] - 2s 28ms/step - loss: 0.2144 - val_loss: 0.2689\n",
      "Epoch 155/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.2149 - val_loss: 0.2621\n",
      "Epoch 156/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.2129 - val_loss: 0.2567\n",
      "Epoch 157/1000\n",
      "61/61 [==============================] - 2s 28ms/step - loss: 0.2111 - val_loss: 0.2607\n",
      "Epoch 158/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.2124 - val_loss: 0.2695\n",
      "Epoch 159/1000\n",
      "61/61 [==============================] - 2s 28ms/step - loss: 0.2123 - val_loss: 0.2829\n",
      "Epoch 160/1000\n",
      "61/61 [==============================] - 2s 28ms/step - loss: 0.2244 - val_loss: 0.3065\n",
      "Epoch 161/1000\n",
      "61/61 [==============================] - 2s 28ms/step - loss: 0.2512 - val_loss: 0.3145\n",
      "Epoch 162/1000\n",
      "61/61 [==============================] - 2s 28ms/step - loss: 0.2292 - val_loss: 0.2639\n",
      "Epoch 163/1000\n",
      "61/61 [==============================] - 2s 28ms/step - loss: 0.2160 - val_loss: 0.2642\n",
      "Epoch 164/1000\n",
      "61/61 [==============================] - 2s 28ms/step - loss: 0.2121 - val_loss: 0.2498\n",
      "Epoch 165/1000\n",
      "61/61 [==============================] - 2s 28ms/step - loss: 0.2096 - val_loss: 0.2547\n",
      "Epoch 166/1000\n",
      "61/61 [==============================] - 2s 28ms/step - loss: 0.2092 - val_loss: 0.2531\n",
      "Epoch 167/1000\n",
      "61/61 [==============================] - 2s 28ms/step - loss: 0.2085 - val_loss: 0.2459\n",
      "Epoch 168/1000\n",
      "61/61 [==============================] - 2s 28ms/step - loss: 0.2082 - val_loss: 0.2518\n",
      "Epoch 169/1000\n",
      "61/61 [==============================] - 2s 28ms/step - loss: 0.2079 - val_loss: 0.2492\n",
      "Epoch 170/1000\n",
      "61/61 [==============================] - 2s 28ms/step - loss: 0.2067 - val_loss: 0.2514\n",
      "Epoch 171/1000\n",
      "61/61 [==============================] - 2s 28ms/step - loss: 0.2079 - val_loss: 0.2465\n",
      "Epoch 172/1000\n",
      "61/61 [==============================] - 2s 28ms/step - loss: 0.2068 - val_loss: 0.2508\n",
      "Epoch 173/1000\n",
      "61/61 [==============================] - 2s 28ms/step - loss: 0.2082 - val_loss: 0.2546\n",
      "Epoch 174/1000\n",
      "61/61 [==============================] - 2s 28ms/step - loss: 0.2085 - val_loss: 0.2523\n",
      "Epoch 175/1000\n",
      "61/61 [==============================] - 2s 28ms/step - loss: 0.2153 - val_loss: 0.2595\n",
      "Epoch 176/1000\n",
      "61/61 [==============================] - 2s 28ms/step - loss: 0.2106 - val_loss: 0.2543\n",
      "Epoch 177/1000\n",
      "61/61 [==============================] - 2s 28ms/step - loss: 0.2046 - val_loss: 0.2490\n",
      "Epoch 178/1000\n",
      "61/61 [==============================] - 2s 28ms/step - loss: 0.2034 - val_loss: 0.2457\n",
      "Epoch 179/1000\n",
      "61/61 [==============================] - 2s 28ms/step - loss: 0.2050 - val_loss: 0.2448\n",
      "Epoch 180/1000\n",
      "61/61 [==============================] - 2s 27ms/step - loss: 0.2052 - val_loss: 0.2554\n",
      "Epoch 181/1000\n",
      "61/61 [==============================] - 2s 27ms/step - loss: 0.2067 - val_loss: 0.3007\n",
      "Epoch 182/1000\n",
      "61/61 [==============================] - 2s 28ms/step - loss: 0.2068 - val_loss: 0.2523\n",
      "Epoch 183/1000\n",
      "61/61 [==============================] - 2s 28ms/step - loss: 0.2052 - val_loss: 0.2440\n",
      "Epoch 184/1000\n",
      "61/61 [==============================] - 2s 28ms/step - loss: 0.2039 - val_loss: 0.2502\n",
      "Epoch 185/1000\n",
      "61/61 [==============================] - 2s 28ms/step - loss: 0.2035 - val_loss: 0.2502\n",
      "Epoch 186/1000\n",
      "61/61 [==============================] - 2s 28ms/step - loss: 0.2028 - val_loss: 0.2478\n",
      "Epoch 187/1000\n",
      "61/61 [==============================] - 2s 28ms/step - loss: 0.2026 - val_loss: 0.2513\n",
      "Epoch 188/1000\n",
      "61/61 [==============================] - 2s 28ms/step - loss: 0.2022 - val_loss: 0.2545\n",
      "Epoch 189/1000\n",
      "61/61 [==============================] - 2s 28ms/step - loss: 0.2019 - val_loss: 0.2466\n",
      "Epoch 190/1000\n",
      "61/61 [==============================] - 2s 28ms/step - loss: 0.2045 - val_loss: 0.2462\n",
      "Epoch 191/1000\n",
      "61/61 [==============================] - 2s 28ms/step - loss: 0.2044 - val_loss: 0.2511\n",
      "Epoch 192/1000\n",
      "61/61 [==============================] - 2s 28ms/step - loss: 0.2042 - val_loss: 0.2497\n",
      "Epoch 193/1000\n",
      "61/61 [==============================] - 2s 28ms/step - loss: 0.2012 - val_loss: 0.2455\n",
      "Epoch 194/1000\n",
      "61/61 [==============================] - 2s 28ms/step - loss: 0.2008 - val_loss: 0.2363\n",
      "Epoch 195/1000\n",
      "61/61 [==============================] - 2s 28ms/step - loss: 0.2008 - val_loss: 0.2409\n",
      "Epoch 196/1000\n",
      "61/61 [==============================] - 2s 28ms/step - loss: 0.2008 - val_loss: 0.2809\n",
      "Epoch 197/1000\n",
      "61/61 [==============================] - 2s 28ms/step - loss: 0.2011 - val_loss: 0.2619\n",
      "Epoch 198/1000\n",
      "61/61 [==============================] - 2s 28ms/step - loss: 0.2001 - val_loss: 0.2545\n",
      "Epoch 199/1000\n",
      "61/61 [==============================] - 2s 28ms/step - loss: 0.1997 - val_loss: 0.2467\n",
      "Epoch 200/1000\n",
      "61/61 [==============================] - 2s 28ms/step - loss: 0.2021 - val_loss: 0.2797\n",
      "Epoch 201/1000\n",
      "61/61 [==============================] - 2s 28ms/step - loss: 0.1989 - val_loss: 0.2405\n",
      "Epoch 202/1000\n",
      "61/61 [==============================] - 2s 28ms/step - loss: 0.1974 - val_loss: 0.2513\n",
      "Epoch 203/1000\n",
      "61/61 [==============================] - 2s 28ms/step - loss: 0.1999 - val_loss: 0.2398\n",
      "Epoch 204/1000\n",
      "61/61 [==============================] - 2s 28ms/step - loss: 0.1973 - val_loss: 0.2397\n",
      "Epoch 205/1000\n",
      "61/61 [==============================] - 2s 27ms/step - loss: 0.1994 - val_loss: 0.2420\n",
      "Epoch 206/1000\n",
      "61/61 [==============================] - 2s 28ms/step - loss: 0.1981 - val_loss: 0.2474\n",
      "Epoch 207/1000\n",
      "61/61 [==============================] - 2s 28ms/step - loss: 0.1982 - val_loss: 0.2373\n",
      "Epoch 208/1000\n",
      "61/61 [==============================] - 2s 28ms/step - loss: 0.2012 - val_loss: 0.2678\n",
      "Epoch 209/1000\n",
      "61/61 [==============================] - 2s 28ms/step - loss: 0.2058 - val_loss: 0.3221\n",
      "Epoch 210/1000\n",
      "61/61 [==============================] - 2s 28ms/step - loss: 0.2423 - val_loss: 0.3536\n",
      "Epoch 211/1000\n",
      "61/61 [==============================] - 2s 28ms/step - loss: 0.2240 - val_loss: 0.2792\n",
      "Epoch 212/1000\n",
      "61/61 [==============================] - 2s 28ms/step - loss: 0.2099 - val_loss: 0.2583\n",
      "Epoch 213/1000\n",
      "61/61 [==============================] - 2s 28ms/step - loss: 0.2005 - val_loss: 0.2476\n",
      "Epoch 214/1000\n",
      "61/61 [==============================] - 2s 28ms/step - loss: 0.1998 - val_loss: 0.2406\n",
      "Epoch 215/1000\n",
      "61/61 [==============================] - 2s 28ms/step - loss: 0.1971 - val_loss: 0.2373\n",
      "Epoch 216/1000\n",
      "61/61 [==============================] - 2s 28ms/step - loss: 0.1958 - val_loss: 0.2421\n",
      "Epoch 217/1000\n",
      "61/61 [==============================] - 2s 28ms/step - loss: 0.1948 - val_loss: 0.2426\n",
      "Epoch 218/1000\n",
      "61/61 [==============================] - 2s 28ms/step - loss: 0.1958 - val_loss: 0.2362\n",
      "Epoch 219/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.1952 - val_loss: 0.2388\n",
      "Epoch 220/1000\n",
      "61/61 [==============================] - 2s 28ms/step - loss: 0.1949 - val_loss: 0.2348\n",
      "Epoch 221/1000\n",
      "61/61 [==============================] - 2s 28ms/step - loss: 0.1955 - val_loss: 0.2291\n",
      "Epoch 222/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.1946 - val_loss: 0.2378\n",
      "Epoch 223/1000\n",
      "61/61 [==============================] - 2s 28ms/step - loss: 0.1939 - val_loss: 0.2354\n",
      "Epoch 224/1000\n",
      "61/61 [==============================] - 2s 28ms/step - loss: 0.1933 - val_loss: 0.2363\n",
      "Epoch 225/1000\n",
      "61/61 [==============================] - 2s 28ms/step - loss: 0.1929 - val_loss: 0.2318\n",
      "Epoch 226/1000\n",
      "61/61 [==============================] - 2s 28ms/step - loss: 0.1939 - val_loss: 0.2286\n",
      "Epoch 227/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.1939 - val_loss: 0.2384\n",
      "Epoch 228/1000\n",
      "61/61 [==============================] - 2s 28ms/step - loss: 0.1925 - val_loss: 0.2299\n",
      "Epoch 229/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.1908 - val_loss: 0.2301\n",
      "Epoch 230/1000\n",
      "61/61 [==============================] - 2s 28ms/step - loss: 0.1912 - val_loss: 0.2353\n",
      "Epoch 231/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.1923 - val_loss: 0.2314\n",
      "Epoch 232/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.1911 - val_loss: 0.2293\n",
      "Epoch 233/1000\n",
      "61/61 [==============================] - 2s 28ms/step - loss: 0.1918 - val_loss: 0.2399\n",
      "Epoch 234/1000\n",
      "61/61 [==============================] - 2s 28ms/step - loss: 0.1927 - val_loss: 0.2350\n",
      "Epoch 235/1000\n",
      "61/61 [==============================] - 2s 28ms/step - loss: 0.1942 - val_loss: 0.2314\n",
      "Epoch 236/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.1920 - val_loss: 0.2289\n",
      "Epoch 237/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.1918 - val_loss: 0.2263\n",
      "Epoch 238/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.1924 - val_loss: 0.2248\n",
      "Epoch 239/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.1927 - val_loss: 0.2390\n",
      "Epoch 240/1000\n",
      "61/61 [==============================] - 2s 28ms/step - loss: 0.1901 - val_loss: 0.2216\n",
      "Epoch 241/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.1906 - val_loss: 0.2301\n",
      "Epoch 242/1000\n",
      "61/61 [==============================] - 2s 28ms/step - loss: 0.1913 - val_loss: 0.2251\n",
      "Epoch 243/1000\n",
      "61/61 [==============================] - 2s 28ms/step - loss: 0.1914 - val_loss: 0.2306\n",
      "Epoch 244/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.1908 - val_loss: 0.2305\n",
      "Epoch 245/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.1910 - val_loss: 0.2333\n",
      "Epoch 246/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.1910 - val_loss: 0.2260\n",
      "Epoch 247/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.1894 - val_loss: 0.2302\n",
      "Epoch 248/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.1905 - val_loss: 0.2245\n",
      "Epoch 249/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.1900 - val_loss: 0.2239\n",
      "Epoch 250/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.1898 - val_loss: 0.2235\n",
      "Epoch 251/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.1892 - val_loss: 0.2252\n",
      "Epoch 252/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.1901 - val_loss: 0.2304\n",
      "Epoch 253/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.1905 - val_loss: 0.2357\n",
      "Epoch 254/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.1904 - val_loss: 0.2257\n",
      "Epoch 255/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.1898 - val_loss: 0.2335\n",
      "Epoch 256/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.1886 - val_loss: 0.2275\n",
      "Epoch 257/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.1892 - val_loss: 0.2294\n",
      "Epoch 258/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.2058 - val_loss: 0.2433\n",
      "Epoch 259/1000\n",
      "61/61 [==============================] - 2s 28ms/step - loss: 0.2019 - val_loss: 0.2271\n",
      "Epoch 260/1000\n",
      "61/61 [==============================] - 2s 28ms/step - loss: 0.1941 - val_loss: 0.2272\n",
      "Epoch 261/1000\n",
      "61/61 [==============================] - 2s 28ms/step - loss: 0.1906 - val_loss: 0.2162\n",
      "Epoch 262/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.1887 - val_loss: 0.2165\n",
      "Epoch 263/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.1881 - val_loss: 0.2153\n",
      "Epoch 264/1000\n",
      "61/61 [==============================] - 2s 28ms/step - loss: 0.1906 - val_loss: 0.2234\n",
      "Epoch 265/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.1882 - val_loss: 0.2160\n",
      "Epoch 266/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.1870 - val_loss: 0.2179\n",
      "Epoch 267/1000\n",
      "61/61 [==============================] - 2s 28ms/step - loss: 0.1869 - val_loss: 0.2184\n",
      "Epoch 268/1000\n",
      "61/61 [==============================] - 2s 27ms/step - loss: 0.1864 - val_loss: 0.2254\n",
      "Epoch 269/1000\n",
      "61/61 [==============================] - 2s 28ms/step - loss: 0.1870 - val_loss: 0.2198\n",
      "Epoch 270/1000\n",
      "61/61 [==============================] - 2s 28ms/step - loss: 0.1867 - val_loss: 0.2194\n",
      "Epoch 271/1000\n",
      "61/61 [==============================] - 2s 28ms/step - loss: 0.1873 - val_loss: 0.2150\n",
      "Epoch 272/1000\n",
      "61/61 [==============================] - 2s 28ms/step - loss: 0.1853 - val_loss: 0.2232\n",
      "Epoch 273/1000\n",
      "61/61 [==============================] - 2s 28ms/step - loss: 0.1861 - val_loss: 0.2252\n",
      "Epoch 274/1000\n",
      "61/61 [==============================] - 2s 28ms/step - loss: 0.1862 - val_loss: 0.2159\n",
      "Epoch 275/1000\n",
      "61/61 [==============================] - 2s 28ms/step - loss: 0.1862 - val_loss: 0.2212\n",
      "Epoch 276/1000\n",
      "61/61 [==============================] - 2s 28ms/step - loss: 0.1867 - val_loss: 0.2173\n",
      "Epoch 277/1000\n",
      "61/61 [==============================] - 2s 28ms/step - loss: 0.1919 - val_loss: 0.2284\n",
      "Epoch 278/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.1879 - val_loss: 0.2209\n",
      "Epoch 279/1000\n",
      "61/61 [==============================] - 2s 28ms/step - loss: 0.1855 - val_loss: 0.2140\n",
      "Epoch 280/1000\n",
      "61/61 [==============================] - 2s 28ms/step - loss: 0.1858 - val_loss: 0.2195\n",
      "Epoch 281/1000\n",
      "61/61 [==============================] - 2s 27ms/step - loss: 0.1864 - val_loss: 0.2221\n",
      "Epoch 282/1000\n",
      "61/61 [==============================] - 2s 28ms/step - loss: 0.1858 - val_loss: 0.2229\n",
      "Epoch 283/1000\n",
      "61/61 [==============================] - 2s 28ms/step - loss: 0.1847 - val_loss: 0.2167\n",
      "Epoch 284/1000\n",
      "61/61 [==============================] - 2s 28ms/step - loss: 0.1856 - val_loss: 0.2150\n",
      "Epoch 285/1000\n",
      "61/61 [==============================] - 2s 28ms/step - loss: 0.1852 - val_loss: 0.2183\n",
      "Epoch 286/1000\n",
      "61/61 [==============================] - 2s 28ms/step - loss: 0.1849 - val_loss: 0.2317\n",
      "Epoch 287/1000\n",
      "61/61 [==============================] - 2s 28ms/step - loss: 0.1843 - val_loss: 0.2175\n",
      "Epoch 288/1000\n",
      "61/61 [==============================] - 2s 28ms/step - loss: 0.1837 - val_loss: 0.2256\n",
      "Epoch 289/1000\n",
      "61/61 [==============================] - 2s 28ms/step - loss: 0.1836 - val_loss: 0.2211\n",
      "Epoch 290/1000\n",
      "61/61 [==============================] - 2s 27ms/step - loss: 0.2185 - val_loss: 0.3915\n",
      "Epoch 291/1000\n",
      "61/61 [==============================] - 2s 27ms/step - loss: 0.2739 - val_loss: 0.3398\n",
      "Epoch 292/1000\n",
      "61/61 [==============================] - 2s 28ms/step - loss: 0.2279 - val_loss: 0.2732\n",
      "Epoch 293/1000\n",
      "61/61 [==============================] - 2s 28ms/step - loss: 0.2096 - val_loss: 0.2534\n",
      "Epoch 294/1000\n",
      "61/61 [==============================] - 2s 28ms/step - loss: 0.2010 - val_loss: 0.2474\n",
      "Epoch 295/1000\n",
      "61/61 [==============================] - 2s 29ms/step - loss: 0.1936 - val_loss: 0.2330\n",
      "Epoch 296/1000\n",
      "61/61 [==============================] - 2s 28ms/step - loss: 0.1900 - val_loss: 0.2423\n",
      "Epoch 297/1000\n",
      "61/61 [==============================] - 2s 28ms/step - loss: 0.1876 - val_loss: 0.2334\n",
      "Epoch 298/1000\n",
      "61/61 [==============================] - 2s 28ms/step - loss: 0.1874 - val_loss: 0.2332\n",
      "Epoch 299/1000\n",
      "61/61 [==============================] - 2s 28ms/step - loss: 0.1869 - val_loss: 0.2321\n",
      "Epoch 300/1000\n",
      "61/61 [==============================] - 2s 28ms/step - loss: 0.1856 - val_loss: 0.2299\n",
      "Epoch 301/1000\n",
      "61/61 [==============================] - 2s 28ms/step - loss: 0.1870 - val_loss: 0.2322\n",
      "Epoch 302/1000\n",
      "61/61 [==============================] - 2s 27ms/step - loss: 0.1864 - val_loss: 0.2324\n",
      "Epoch 303/1000\n",
      "61/61 [==============================] - 2s 27ms/step - loss: 0.1849 - val_loss: 0.2391\n",
      "Epoch 304/1000\n",
      "61/61 [==============================] - 2s 28ms/step - loss: 0.1839 - val_loss: 0.2291\n",
      "Epoch 305/1000\n",
      "61/61 [==============================] - 2s 27ms/step - loss: 0.1835 - val_loss: 0.2326\n",
      "Epoch 306/1000\n",
      "61/61 [==============================] - 2s 27ms/step - loss: 0.1827 - val_loss: 0.2245\n",
      "Epoch 307/1000\n",
      "61/61 [==============================] - 2s 27ms/step - loss: 0.1823 - val_loss: 0.2370\n",
      "Epoch 308/1000\n",
      "61/61 [==============================] - 2s 27ms/step - loss: 0.1825 - val_loss: 0.2329\n",
      "Epoch 309/1000\n",
      "61/61 [==============================] - 2s 27ms/step - loss: 0.1828 - val_loss: 0.2217\n",
      "Epoch 310/1000\n",
      "61/61 [==============================] - 2s 28ms/step - loss: 0.1815 - val_loss: 0.2316\n",
      "Epoch 311/1000\n",
      "61/61 [==============================] - 2s 28ms/step - loss: 0.1822 - val_loss: 0.2330\n",
      "Epoch 312/1000\n",
      "61/61 [==============================] - 2s 28ms/step - loss: 0.1819 - val_loss: 0.2269\n",
      "Epoch 313/1000\n",
      "61/61 [==============================] - 2s 28ms/step - loss: 0.1813 - val_loss: 0.2209\n",
      "Epoch 314/1000\n",
      "60/61 [============================>.] - ETA: 0s - loss: 0.1812Restoring model weights from the end of the best epoch: 279.\n",
      "61/61 [==============================] - 2s 28ms/step - loss: 0.1813 - val_loss: 0.2285\n",
      "Epoch 314: early stopping\n",
      "7/7 [==============================] - 1s 10ms/step\n",
      "0.17459210196213723\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "856a0b33a1ce4114a3782f0a960670d2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.048 MB of 0.048 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch/epoch</td><td>▁▁▁▂▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▅▅▆▆▆▆▇▇▇▇▇▇█</td></tr><tr><td>epoch/learning_rate</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>epoch/loss</td><td>█▆▆▆▅▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▁▁▁▁</td></tr><tr><td>epoch/val_loss</td><td>█▅▄▄▄▃▃▄▃▃▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>rmase_prediction</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch/epoch</td><td>313</td></tr><tr><td>epoch/learning_rate</td><td>0.00049</td></tr><tr><td>epoch/loss</td><td>0.18135</td></tr><tr><td>epoch/val_loss</td><td>0.22853</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">test_9</strong> at: <a href='https://wandb.ai/uu13234-none/sgnate_skate-keras/runs/55olrfy4' target=\"_blank\">https://wandb.ai/uu13234-none/sgnate_skate-keras/runs/55olrfy4</a><br/> View project at: <a href='https://wandb.ai/uu13234-none/sgnate_skate-keras' target=\"_blank\">https://wandb.ai/uu13234-none/sgnate_skate-keras</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20241104_153103-55olrfy4\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_list = train_model(train_X, y, user_id_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "予測"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(model_list, test_X):\n",
    "    preds_test = []\n",
    "    for model in model_list:\n",
    "        pred_test = model.predict(test_X)\n",
    "        preds_test.append(pred_test)\n",
    "\n",
    "    pred_test = np.mean(preds_test, axis=0) \n",
    "    #予測値の反転\n",
    "    pred_test[:, :, 0] = pred_test[:, :, 0] * -1\n",
    "    pred_test[:, :, 1] = pred_test[:, :, 1] * -1\n",
    "\n",
    "    return pred_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40/40 [==============================] - 1s 15ms/step\n",
      "40/40 [==============================] - 0s 11ms/step\n",
      "40/40 [==============================] - 0s 11ms/step\n",
      "40/40 [==============================] - 0s 11ms/step\n",
      "40/40 [==============================] - 0s 11ms/step\n",
      "40/40 [==============================] - 0s 11ms/step\n",
      "40/40 [==============================] - 0s 11ms/step\n",
      "40/40 [==============================] - 0s 11ms/step\n",
      "40/40 [==============================] - 0s 11ms/step\n",
      "40/40 [==============================] - 0s 11ms/step\n"
     ]
    }
   ],
   "source": [
    "pred_test = predict(model_list, test_X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "提出用ファイルを作成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# サンプル提出ファイルを確認します\n",
    "with open(r\"C:\\Users\\sato\\Desktop\\python\\SIGNATE\\スケートボードの挙動予測\\input\\sample_submit.json\") as r:\n",
    "    sample_submit = json.load(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User sub1 predictions shape: (319, 30, 3)\n",
      "User sub2 predictions shape: (300, 30, 3)\n",
      "User sub3 predictions shape: (320, 30, 3)\n",
      "User sub4 predictions shape: (320, 30, 3)\n"
     ]
    }
   ],
   "source": [
    "# 提出用データの作成 (vel_x, vel_y, vel_z の形式に整形)\n",
    "user_id_sub = sample_submit.keys()\n",
    "trial_user = [319, 300, 320, 320]  # 各ユーザーのトライアル数\n",
    "\n",
    "test_index_start = 0\n",
    "test_index_end = 0\n",
    "\n",
    "for i, user_id in enumerate(user_id_sub):\n",
    "    sub_dict = {}\n",
    "    trial_num = trial_user[i]\n",
    "    test_index_start = test_index_end\n",
    "    test_index_end += trial_num\n",
    "\n",
    "    # テストデータの予測結果から各ユーザーごとのデータを抽出\n",
    "    sub_pred = pred_test[test_index_start:test_index_end]#.reshape(-1, 30, 3)\n",
    "    print(f\"User {user_id} predictions shape: {sub_pred.shape}\")  # (trial_num, 30, 3) の形になることを確認\n",
    "\n",
    "     # 各トライアルの予測データを辞書形式に整形しつつ、RMSEを計算\n",
    "    for trial in range(trial_num):\n",
    "        trial_ = trial + 1\n",
    "        sub_dict[f\"trial{trial_}\"] = sub_pred[trial].tolist()  # 各トライアルのデータをリスト形式に変換\n",
    "\n",
    "# 提出用辞書に保存\n",
    "    sample_submit[f\"sub{i+1}\"] = sub_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 提出ファイルとして保存します\n",
    "with open(r\"C:\\Users\\sato\\Desktop\\python\\SIGNATE\\スケートボードの挙動予測\\submission\\submission_.json\", \"w\") as f:\n",
    "    json.dump(sample_submit, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "TPU",
  "colab": {
   "gpuType": "V28",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "tf-gpu-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
