{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 943,
     "status": "ok",
     "timestamp": 1729996600732,
     "user": {
      "displayName": "佐藤信吾",
      "userId": "11983907688732050177"
     },
     "user_tz": -540
    },
    "id": "DvzwKEcGKOw_"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import gc\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import scipy.io as sio\n",
    "from scipy.signal import resample\n",
    "import warnings\n",
    "\n",
    "# Weights and Biases related imports\n",
    "#import wandb\n",
    "#from wandb.integration.keras import WandbMetricsLogger\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "\n",
    "# 警告を無視する設定\n",
    "warnings.simplefilter(\"ignore\")\n",
    "\n",
    "# Pandasの表示設定\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "# Jupyter Notebookでのグラフ表示を有効にする\n",
    "#%matplotlib inline\n",
    "\n",
    "# Weights and Biasesにログイン\n",
    "#wandb.login()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "前処理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 筋電図データの整流化\n",
    "def rectify_signal(emg_data):\n",
    "    \"\"\"EMGデータを整流化（負の値を正に変換）\"\"\"\n",
    "    return np.abs(emg_data)\n",
    "\n",
    "# 筋電位データの対数変換関数\n",
    "def log_transform_emg(emg_data, epsilon=1e-6):\n",
    "    \"\"\"整流化されたEMGデータに対して対数変換を適用\"\"\"\n",
    "    return np.log(emg_data + epsilon)\n",
    "\n",
    "# x方向が常に正または負のデータを抽出\n",
    "def extract_positive_x_trials(velocity_x):\n",
    "    positive_x_trials = []\n",
    "    for i in range(velocity_x.shape[0]):\n",
    "        if np.all(velocity_x[i] > 0) or np.all(velocity_x[i] < 0):\n",
    "            positive_x_trials.append(i)\n",
    "    return positive_x_trials\n",
    "\n",
    "# 筋電位データの左右を反転して学習データに追加\n",
    "def add_reversed_emg_data(trial_user, x_velocity, emg_data, y_data):\n",
    "    added_user_list = []\n",
    "    reversed_emg_data = []\n",
    "    y_add_list = []\n",
    "    \n",
    "    # 各ユーザーごとに処理\n",
    "    user_trial_ranges = np.cumsum([0] + trial_user)\n",
    "    right_leg_muscles = [1, 3, 5, 7, 9, 11, 13, 15]\n",
    "    left_leg_muscles = [0, 2, 4, 6, 8, 10, 12, 14]\n",
    "\n",
    "    for user_idx, (start, end) in enumerate(zip(user_trial_ranges[:-1], user_trial_ranges[1:])):\n",
    "        user_velocity_x = x_velocity[start:end]\n",
    "        user_emg_data = emg_data[start:end]\n",
    "        user_y_data = y_data[start:end]\n",
    "\n",
    "        positive_x_trials = extract_positive_x_trials(user_velocity_x)\n",
    "\n",
    "        for i in positive_x_trials:\n",
    "            trial_emg = user_emg_data[i].copy()\n",
    "            y_add = user_y_data[i].copy()\n",
    "\n",
    "            # 筋電位データの左右を反転\n",
    "            trial_emg[:, right_leg_muscles], trial_emg[:, left_leg_muscles] = trial_emg[:, left_leg_muscles], trial_emg[:, right_leg_muscles]\n",
    "            \n",
    "            reversed_emg_data.append(trial_emg)\n",
    "            y_add_list.append(y_add)\n",
    "            added_user_list.append(f'00{user_idx + 1}')  # ユーザーIDを追加\n",
    "\n",
    "    reversed_emg_data = np.array(reversed_emg_data)\n",
    "    y_add_data = np.array(y_add_list)\n",
    "\n",
    "    new_emg_data = np.concatenate([emg_data, reversed_emg_data], axis=0)\n",
    "    new_y_data = np.concatenate([y_data, y_add_data], axis=0)\n",
    "\n",
    "    return new_emg_data, added_user_list, new_y_data\n",
    "\n",
    "# 学習用データの取得\n",
    "def get_train_data(train_path, user_ids, trial_user):\n",
    "    train_data = sio.loadmat(train_path)\n",
    "    X_list, y_list, user_id_list = [], [], []\n",
    "    user_id_encoder = OneHotEncoder(sparse_output=False)\n",
    "    user_id_encoder.fit(user_ids.reshape(-1, 1))\n",
    "\n",
    "    for user_id in user_ids:\n",
    "        x_array = train_data[user_id][0][0][0].transpose(0, 2, 1)\n",
    "        y_array = train_data[user_id][0][0][1].transpose(0, 2, 1)\n",
    "        num_trials = x_array.shape[0]\n",
    "        \n",
    "        user_id_encoded = user_id_encoder.transform(np.array([[user_id]] * num_trials))\n",
    "        user_id_list.extend([[user_id]] * num_trials)\n",
    "\n",
    "        for trial in range(num_trials):\n",
    "            rectified_x = rectify_signal(x_array[trial])\n",
    "            log_transformed_x = log_transform_emg(rectified_x)\n",
    "            new_x_array = np.hstack([log_transformed_x, np.repeat(user_id_encoded[trial][np.newaxis, :], 1000, axis=0)])\n",
    "            X_list.append(new_x_array[np.newaxis, :])\n",
    "\n",
    "        y_list.append(y_array)\n",
    "        del x_array, y_array\n",
    "        gc.collect()\n",
    "\n",
    "    X = np.concatenate(X_list, axis=0)\n",
    "    y = np.concatenate(y_list, axis=0)\n",
    "\n",
    "    print(X.shape)\n",
    "\n",
    "    # 標準化\n",
    "    X_scaled, scaler_list = standardize_by_user(X, trial_user)\n",
    "    x_velocity = y[:,:,0]\n",
    "    new_emg_data, added_user_list, y_add_data = add_reversed_emg_data(trial_user, x_velocity, X_scaled, y)\n",
    "\n",
    "    # user_id_listに追加されたデータのuser_idを追加\n",
    "    user_id_list_flat = [str(item[0]) if isinstance(item, np.ndarray) else str(item) for sublist in user_id_list for item in sublist]\n",
    "    user_id_list_flat.extend(added_user_list)\n",
    "    user_id_list_array = np.array(user_id_list_flat)\n",
    "\n",
    "    return new_emg_data, y_add_data, user_id_list_array, scaler_list\n",
    "\n",
    "# ユーザーごとの標準化\n",
    "def standardize_by_user(emg_data, trial_user):\n",
    "    scaler_list = []\n",
    "    start = 0\n",
    "    for num_trials in trial_user:\n",
    "        end = start + num_trials# * 1000\n",
    "        scaler = StandardScaler()\n",
    "        emg_data[start:end, :, :16] = scaler.fit_transform(emg_data[start:end, :, :16].reshape(-1, 16)).reshape(num_trials, 1000, 16)\n",
    "        scaler_list.append(scaler)\n",
    "        start = end\n",
    "    return emg_data[:, :-10], scaler_list\n",
    "\n",
    "# 評価用データの取得\n",
    "def get_test_data(test_path, user_ids, trial_user, scaler_list):\n",
    "    test_data = sio.loadmat(test_path)\n",
    "    X_list, user_id_list = [], []\n",
    "    user_id_encoder = OneHotEncoder(sparse_output=False)\n",
    "    user_id_encoder.fit(user_ids.reshape(-1, 1))\n",
    "\n",
    "    for user_id in user_ids:\n",
    "        x_array = test_data[user_id][0][0][0].transpose(0, 2, 1)\n",
    "        num_trials = x_array.shape[0]\n",
    "        \n",
    "        user_id_encoded = user_id_encoder.transform(np.array([[user_id]] * num_trials))\n",
    "        user_id_list.extend([[user_id]] * num_trials)\n",
    "\n",
    "        for trial in range(num_trials):\n",
    "            rectified_x = rectify_signal(x_array[trial])\n",
    "            log_transformed_x = log_transform_emg(rectified_x)\n",
    "            new_x_array = np.hstack([log_transformed_x, np.repeat(user_id_encoded[trial][np.newaxis, :], 1000, axis=0)])\n",
    "            X_list.append(new_x_array[np.newaxis, :])\n",
    "\n",
    "        del x_array\n",
    "        gc.collect()\n",
    "\n",
    "    X = np.concatenate(X_list, axis=0)\n",
    "\n",
    "    # ユーザーごとに標準化\n",
    "    X_scaled = np.zeros_like(X)\n",
    "    start = 0\n",
    "    for user_idx, num_trials in enumerate(trial_user):\n",
    "        end = start + num_trials\n",
    "        X_scaled[start:end, :, :16] = scaler_list[user_idx].transform(X[start:end, :, :16].reshape(-1, 16)).reshape(num_trials, 1000, 16)\n",
    "        start = end\n",
    "\n",
    "    return X_scaled[:, :-10]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1259, 1000, 20)\n"
     ]
    }
   ],
   "source": [
    "train_path = r'C:\\Users\\sato\\Desktop\\python\\SIGNATE\\スケートボードの挙動予測\\input/train.mat'\n",
    "test_path = r'C:\\Users\\sato\\Desktop\\python\\SIGNATE\\スケートボードの挙動予測\\input/test.mat'\n",
    "user_ids = np.array([\"0001\", \"0002\", \"0003\", \"0004\"])\n",
    "trial_user = [319, 300, 320, 320] \n",
    "\n",
    "train_X, y, user_id_list, scaler_list = get_train_data(train_path, user_ids, trial_user)\n",
    "test_X = get_test_data(test_path, user_ids, trial_user, scaler_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "学習"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Conv1D, LSTM, Dense, Dropout, Bidirectional, Input, TimeDistributed, Attention, AveragePooling1D, BatchNormalization, MaxPooling1D\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras import backend as K\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import root_mean_squared_error\n",
    "#import wandb\n",
    "#from wandb.integration.keras import WandbMetricsLogger\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model():\n",
    "    # モデル定義\n",
    "    input_layer = Input(shape=(990, 20))\n",
    "\n",
    "    # 畳み込み層\n",
    "    x = Conv1D(filters=224, kernel_size=50, activation='relu', padding='same')(input_layer)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = AveragePooling1D(pool_size=4)(x)\n",
    "    x = Conv1D(filters=128, kernel_size=10, activation='relu', padding='same')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = AveragePooling1D(pool_size=4)(x)\n",
    "    x = MaxPooling1D(pool_size=2)(x)\n",
    "\n",
    "    # LSTM + Attention層\n",
    "    x = Bidirectional(LSTM(96, return_sequences=True))(x)\n",
    "    x = Dropout(rate=0.3)(x)\n",
    "\n",
    "    # Attention層\n",
    "    attention_out = Attention()([x, x]) \n",
    "\n",
    "    # LSTM層と出力層\n",
    "    x = Bidirectional(LSTM(64, return_sequences=True))(attention_out)\n",
    "    x = Dropout(rate=0.2)(x)\n",
    "\n",
    "    # 出力層\n",
    "    output_layer = TimeDistributed(Dense(3))(x)\n",
    "\n",
    "    # モデルの構築\n",
    "    model = Model(inputs=input_layer, outputs=output_layer)\n",
    "\n",
    "    return model\n",
    "\n",
    "def rmse_3d_loss(y_true, y_pred):\n",
    "    return K.sqrt(K.sum(K.square(y_true - y_pred), axis=-1))\n",
    "\n",
    "def train_model(X_train, y_train, user_id_list, num_folds=10):\n",
    "    kf = StratifiedKFold(n_splits=num_folds, shuffle=True, random_state=0)\n",
    "    model_list = []\n",
    "  \n",
    "    for i, (train_idx, val_idx) in enumerate(kf.split(X_train, user_id_list.astype('str'))):\n",
    "        #run = wandb.init(\n",
    "        #    project = \"sgnate_skate-keras\",\n",
    "        #    name = f'test_{i}',\n",
    "        #    tags = [f'test_up']\n",
    "        #    #config = configs\n",
    "        #)\n",
    "        #wandb.define_metric('rmase_prediction', summary='mean')\n",
    "        train_X, val_X = X_train[train_idx], X_train[val_idx]\n",
    "        train_y, val_y = y_train[train_idx], y_train[val_idx]\n",
    "        \n",
    "        model = create_model()\n",
    "        model.compile(optimizer=Adam(learning_rate=0.0004926459300637485), loss=rmse_3d_loss) #過去コンペで使用したlearning_rateを使用\n",
    "        early_stopping = EarlyStopping(patience=35, restore_best_weights=True, verbose=1)\n",
    "        \n",
    "        #model.fit(train_X, train_y, validation_data=(val_X, val_y), epochs=1000, batch_size=32, callbacks=[early_stopping, WandbMetricsLogger()])\n",
    "        model.fit(train_X, train_y, validation_data=(val_X, val_y), epochs=1000, batch_size=32, callbacks=[early_stopping])\n",
    "        #model.save(f'model_fold_{i+1}.h5')\n",
    "        model_list.append(model)\n",
    "\n",
    "        pred = model.predict(val_X)\n",
    "        score = root_mean_squared_error(val_y.reshape(-1, 1), pred.reshape(-1, 1))\n",
    "        print(score)\n",
    "        #wandb.log({'rmase_prediction': score})\n",
    "        \n",
    "        #run.finish()\n",
    "\n",
    "    return model_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_list = train_model(train_X, y, user_id_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "予測"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(model_list, test_X):\n",
    "    preds_test = []\n",
    "    for model in model_list:\n",
    "        pred_test = model.predict(test_X)\n",
    "        preds_test.append(pred_test)\n",
    "\n",
    "    pred_test = np.mean(preds_test, axis=0) \n",
    "    #予測値の反転\n",
    "    pred_test[:, :, 0] = pred_test[:, :, 0] * -1\n",
    "    pred_test[:, :, 1] = pred_test[:, :, 1] * -1\n",
    "\n",
    "    return pred_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40/40 [==============================] - 1s 15ms/step\n",
      "40/40 [==============================] - 0s 11ms/step\n",
      "40/40 [==============================] - 0s 11ms/step\n",
      "40/40 [==============================] - 0s 11ms/step\n",
      "40/40 [==============================] - 0s 11ms/step\n",
      "40/40 [==============================] - 0s 11ms/step\n",
      "40/40 [==============================] - 0s 11ms/step\n",
      "40/40 [==============================] - 0s 11ms/step\n",
      "40/40 [==============================] - 0s 11ms/step\n",
      "40/40 [==============================] - 0s 11ms/step\n"
     ]
    }
   ],
   "source": [
    "pred_test = predict(model_list, test_X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "提出用ファイルを作成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# サンプル提出ファイルを確認します\n",
    "with open(r\"C:\\Users\\sato\\Desktop\\python\\SIGNATE\\スケートボードの挙動予測\\input\\sample_submit.json\") as r:\n",
    "    sample_submit = json.load(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User sub1 predictions shape: (319, 30, 3)\n",
      "User sub2 predictions shape: (300, 30, 3)\n",
      "User sub3 predictions shape: (320, 30, 3)\n",
      "User sub4 predictions shape: (320, 30, 3)\n"
     ]
    }
   ],
   "source": [
    "# 提出用データの作成 (vel_x, vel_y, vel_z の形式に整形)\n",
    "user_id_sub = sample_submit.keys()\n",
    "trial_user = [319, 300, 320, 320]  # 各ユーザーのトライアル数\n",
    "\n",
    "test_index_start = 0\n",
    "test_index_end = 0\n",
    "\n",
    "for i, user_id in enumerate(user_id_sub):\n",
    "    sub_dict = {}\n",
    "    trial_num = trial_user[i]\n",
    "    test_index_start = test_index_end\n",
    "    test_index_end += trial_num\n",
    "\n",
    "    # テストデータの予測結果から各ユーザーごとのデータを抽出\n",
    "    sub_pred = pred_test[test_index_start:test_index_end]#.reshape(-1, 30, 3)\n",
    "    print(f\"User {user_id} predictions shape: {sub_pred.shape}\")  # (trial_num, 30, 3) の形になることを確認\n",
    "\n",
    "     # 各トライアルの予測データを辞書形式に整形しつつ、RMSEを計算\n",
    "    for trial in range(trial_num):\n",
    "        trial_ = trial + 1\n",
    "        sub_dict[f\"trial{trial_}\"] = sub_pred[trial].tolist()  # 各トライアルのデータをリスト形式に変換\n",
    "\n",
    "# 提出用辞書に保存\n",
    "    sample_submit[f\"sub{i+1}\"] = sub_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 提出ファイルとして保存します\n",
    "with open(r\"C:\\Users\\sato\\Desktop\\python\\SIGNATE\\スケートボードの挙動予測\\submission\\submission_.json\", \"w\") as f:\n",
    "    json.dump(sample_submit, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "TPU",
  "colab": {
   "gpuType": "V28",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "tf-gpu-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
